{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from agents.evn_mvo import StockPortfolioEnv\n",
    "from agents.mvo_agent import MarkowitzAgent\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from feature_engineer import FeatureEngineer\n",
    "from models import DRLAgent\n",
    "from portfolio_optimization_env import PortfolioOptimizationEnv\n",
    "import sys\n",
    "import scienceplots\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "plt.style.use('science')\n",
    "\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    ")\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n",
    "def DRL_prediction(model, environment,time_window, deterministic=True):\n",
    "    \"\"\"make a prediction and get results\"\"\"\n",
    "    test_env, test_obs = environment.get_sb_env()\n",
    "    account_memory = None  # This help avoid unnecessary list creation\n",
    "    actions_memory = None  # optimize memory consumption\n",
    "    # state_memory=[] #add memory pool to store states\n",
    "\n",
    "    test_env.reset()\n",
    "    max_steps = len(environment._df.index.unique()) - (time_window) - 1\n",
    "\n",
    "    for i in range(len(environment._df.index.unique())):\n",
    "        action, _states = model.predict(test_obs, deterministic=deterministic)\n",
    "        test_obs, rewards, dones, info = test_env.step(action)\n",
    "        if i == max_steps:  \n",
    "            date_list = environment._date_memory\n",
    "            portfolio_return = environment._portfolio_return_memory\n",
    "            df_account_value = pd.DataFrame(\n",
    "                {\"date\": date_list, \"daily_return\": portfolio_return,'account' :  environment._asset_memory[\"final\"],'weights':environment._final_weights}\n",
    "            )\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = environment._actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            tiks = environment._tic_list\n",
    "            df_actions.columns = np.insert(tiks,0,'POS')\n",
    "            df_actions.index = df_date.date\n",
    "            account_memory = df_account_value\n",
    "            actions_memory = df_actions\n",
    "\n",
    "        if dones[0]:\n",
    "            print(\"hit end!\")\n",
    "            break\n",
    "    return account_memory, actions_memory\n",
    "TRAIN_START_DATE = '2015-01-01'\n",
    "TRAIN_END_DATE = '2020-12-31'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = '2024-12-31'\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "df_dow =read_csv('./data/dow.csv')\n",
    "df_nasdaq =read_csv('./data/nasdaq.csv')\n",
    "df_hsi = read_csv('./data/hsi.csv')\n",
    "df_dax = read_csv('./data/dax.csv')\n",
    "df_sp500 = read_csv('./data/sp500.csv')\n",
    "def mvo_data(data, INDICATORS, TEST_START_DATE, TEST_END_DATE):\n",
    "    final_result = []\n",
    "    df = data.sort_values(['date', 'tic'], ignore_index=True).copy()\n",
    "    df.index = df.date.factorize()[0]\n",
    "    cov_list = []\n",
    "    mu = []\n",
    "    # look back is one year\n",
    "    lookback = 252\n",
    "    for i in range(lookback, len(df.index.unique())):\n",
    "        data_lookback = df.loc[i-lookback:i, :]\n",
    "        price_lookback = data_lookback.pivot_table(\n",
    "            index='date', columns='tic', values='close')\n",
    "        return_lookback = price_lookback.pct_change().dropna()\n",
    "        covs = return_lookback.cov().values\n",
    "        mu.append(expected_returns.mean_historical_return(price_lookback))\n",
    "        cov_list.append(covs)\n",
    "    df_cov = pd.DataFrame(\n",
    "        {'time': df.date.unique()[lookback:], 'cov_list': cov_list, 'returns': mu})\n",
    "    df = df.merge(df_cov, left_on='date', right_on='time')\n",
    "\n",
    "    test_df = data_split(\n",
    "        df,\n",
    "        start=TEST_START_DATE,\n",
    "        end=TEST_END_DATE\n",
    "    )\n",
    "    return test_df\n",
    "def mvo(data, solver='OSQP',window=1, rf=0.02, pct=0.001,objective='min_variance'):\n",
    "    result = {}\n",
    "    stock_dimension = len(data.tic.unique())\n",
    "    state_space = stock_dimension\n",
    "    env_kwargs = {\n",
    "        \"hmax\": 100,\n",
    "        \"initial_amount\": 50_000,\n",
    "        \"transaction_cost_pct\": pct,\n",
    "        \"state_space\": state_space,\n",
    "        \"stock_dim\": stock_dimension,\n",
    "        \"tech_indicator_list\": INDICATORS,\n",
    "        \"action_space\": stock_dimension,\n",
    "        \"reward_scaling\": 1e-4,\n",
    "        \"window\":window\n",
    "\n",
    "    }\n",
    "    e_test_gym = StockPortfolioEnv(df=data, **env_kwargs)\n",
    "    agent = MarkowitzAgent(e_test_gym, rf=rf,objective=objective,cost=pct)\n",
    "    mvo_min_variance = agent.prediction(e_test_gym)\n",
    "    mvo_min_variance[\"method\"] = \"markowitz\"\n",
    "    mvo_min_variance.columns = ['date', 'account', 'return', 'method']\n",
    "    result[\"test\"] = mvo_min_variance\n",
    "    result[\"name\"] = 'Min Variance Portfolio'\n",
    "    return result\n",
    "def train_model(train_data,test_data,transaction_fee=0.001,use_sharpe=False,use_dsr=False,use_sortino=False,model_name='a2c'\n",
    "                ,iterations = 100_000,save=True,load=False,tag='tag',features=[\"close\",\"log_return\"],t=5,args=None,indicators =None,starting_capital = 50_000):\n",
    "\n",
    "    env_kwargs = {\n",
    "        \"initial_amount\": starting_capital, \n",
    "        \"normalize_df\":None,\n",
    "        \"features\" :features,\n",
    "        'comission_fee_pct':transaction_fee,\n",
    "        'time_window':t,\n",
    "        'use_sharpe':use_sharpe,\n",
    "        'use_sortino':use_sortino,\n",
    "        'use_differentail_sharpe_ratio':use_dsr,\n",
    "        \n",
    "    }\n",
    "    train_environment = PortfolioOptimizationEnv(df = train_data, **env_kwargs)\n",
    "    env_kwargs = {\n",
    "        \"initial_amount\": starting_capital, \n",
    "        \"normalize_df\":None,\n",
    "        'comission_fee_pct':transaction_fee,\n",
    "        \"features\" :features,\n",
    "        'time_window':t,\n",
    "        'use_sharpe':use_sharpe,\n",
    "        'use_sortino':use_sortino,\n",
    "        'use_differentail_sharpe_ratio':use_dsr,\n",
    "    }\n",
    "\n",
    "    test_environment = PortfolioOptimizationEnv(df = test_data, **env_kwargs)\n",
    "    agent = DRLAgent(env = train_environment)\n",
    "    model_agent = agent.get_model(model_name,\n",
    "                                model_kwargs = args)\n",
    "\n",
    "    \n",
    "    if not load:\n",
    "        model = agent.train_model(model=model_agent, \n",
    "                                    tb_log_name='./tensorboard_log/',\n",
    "                                    total_timesteps=iterations)\n",
    "    else:\n",
    "        print('loading model')\n",
    "        model = model_agent.load('./data/trained_models_2025/'+str(model_name)+'_'+str(iterations)+'_' + tag,env =train_environment)\n",
    "    if save and not load:\n",
    "        model.save('./data/trained_models/'+str(model_name)+'_'+str(iterations)+'_' + tag )\n",
    "    metrics_df_dax = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": train_environment._date_memory,\n",
    "            \"actions\": train_environment._actions_memory,\n",
    "            \"weights\": train_environment._final_weights,\n",
    "            \"returns\": train_environment._portfolio_return_memory,\n",
    "            \"rewards\": train_environment._portfolio_reward_memory,\n",
    "            \"portfolio_values\": train_environment._asset_memory[\"final\"],\n",
    "        }\n",
    "    )\n",
    "    ppo_predictions = DRL_prediction(model, test_environment,t)\n",
    "    results = {'train': metrics_df_dax,'test':ppo_predictions, 'model': model_agent}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added user defined features\n",
      "Stock Dimension: 29, State Space: 88\n"
     ]
    }
   ],
   "source": [
    "INDICATORS = [\n",
    "    \"close_5_ema\",\n",
    "]\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = True)\n",
    "\n",
    "processed_dax = fe.preprocess_data(df_dow[df_dow[\"date\"] > TRAIN_START_DATE])\n",
    "data = processed_dax.copy()\n",
    "data = data.fillna(0)\n",
    "data = data.replace(np.inf,0)\n",
    "train_data = data_split(data, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(data, TEST_START_DATE, TEST_END_DATE)\n",
    "stock_dimension = len(train_data.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:50000\n",
      "end_total_asset:64257.34964295229\n",
      "Sharpe:  0.48671568955330713\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.2851469928590458\n",
      "=================================\n",
      "begin_total_asset:50000\n",
      "end_total_asset:71759.94598022965\n",
      "Sharpe:  0.7508747349482665\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.435198919604593\n"
     ]
    }
   ],
   "source": [
    "covs= mvo_data(processed_dax,INDICATORS,TEST_START_DATE,TEST_END_DATE)\n",
    "max_sharpe_portfolio = mvo(covs,objective='sharpe',pct=0.001,rf=0)\n",
    "min_variance_portfolio = mvo(covs,pct=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:50000\n",
      "end_total_asset:60540.00877666292\n",
      "Sharpe:  0.38274829128545473\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.2108001755332585\n",
      "=================================\n",
      "begin_total_asset:50000\n",
      "end_total_asset:65060.43746910945\n",
      "Sharpe:  0.6107592425422126\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.301208749382189\n"
     ]
    }
   ],
   "source": [
    "covs= mvo_data(processed_dax,INDICATORS,TEST_START_DATE,TEST_END_DATE)\n",
    "max_sharpe_portfolio = mvo(covs,objective='sharpe',pct=0,rf=0)\n",
    "min_variance_portfolio = mvo(covs,pct=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "=================================\n",
      "Episode:1\n",
      "Initial portfolio value:50000\n",
      "Final portfolio value: 53097.80859375\n",
      "Final accumulative portfolio value: 1.061956171875\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.51e+03    |\n",
      "|    ep_rew_mean     | 0.0609      |\n",
      "| time/              |             |\n",
      "|    fps             | 47          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 43          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.00266615 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Episode:2\n",
      "Initial portfolio value:50000\n",
      "Final portfolio value: 55362.41796875\n",
      "Final accumulative portfolio value: 1.107248359375\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | 0.0819       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065384684 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -1.66        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.469       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    reward               | -0.008919561 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000837     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Episode:3\n",
      "Initial portfolio value:50000\n",
      "Final portfolio value: 55273.3828125\n",
      "Final accumulative portfolio value: 1.10546765625\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "iterations = 100_000\n",
    "result_ppo = train_model(train_data,test_data,transaction_fee=0.001,iterations=iterations,model_name='ppo',save=True,tag='dow30')\n",
    "result_ddpg = train_model(train_data,test_data,transaction_fee=0.001,iterations=iterations,model_name='ddpg',save=True,tag='dow30')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
