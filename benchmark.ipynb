{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from finrl.config_tickers import DOW_30_TICKER,NAS_100_TICKER,HSI_50_TICKER,DAX_30_TICKER,SP_500_TICKER\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from stock_env import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,trx_plot\n",
    "from feature_engineer import FeatureEngineer\n",
    "from models import DRLAgent\n",
    "from portfolio_optimization_env import PortfolioOptimizationEnv\n",
    "from pprint import pprint\n",
    "import scienceplots\n",
    "import sys\n",
    "from agents.evn_mvo import StockPortfolioEnv\n",
    "from agents.mvo_agent import MarkowitzAgent\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "import quantstats as qs\n",
    "plt.style.use('science')\n",
    "import os\n",
    "from utils import benchmark\n",
    "\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n",
    "def DRL_prediction(model, environment,time_window, deterministic=True):\n",
    "    \"\"\"make a prediction and get results\"\"\"\n",
    "    test_env, test_obs = environment.get_sb_env()\n",
    "    account_memory = None  # This help avoid unnecessary list creation\n",
    "    actions_memory = None  # optimize memory consumption\n",
    "    # state_memory=[] #add memory pool to store states\n",
    "\n",
    "    test_env.reset()\n",
    "    max_steps = len(environment._df.index.unique()) - time_window - 1\n",
    "\n",
    "    for i in range(len(environment._df.index.unique())):\n",
    "        action, _states = model.predict(test_obs, deterministic=deterministic)\n",
    "        # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "        # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "        test_obs, rewards, dones, info = test_env.step(action)\n",
    "        if i == max_steps:  # more descriptive condition for early termination to clarify the logic\n",
    "            date_list = environment._date_memory\n",
    "            portfolio_return = environment._portfolio_return_memory\n",
    "            # print(len(date_list))\n",
    "            # print(len(asset_list))\n",
    "            df_account_value = pd.DataFrame(\n",
    "                {\"date\": date_list, \"daily_return\": portfolio_return,'account' :  environment._asset_memory[\"final\"],'weights':environment._final_weights}\n",
    "            )\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = environment._actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            tiks = environment._tic_list\n",
    "            df_actions.columns = np.insert(tiks,0,'POS')\n",
    "            df_actions.index = df_date.date\n",
    "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "            account_memory = df_account_value\n",
    "            actions_memory = df_actions\n",
    "        # add current state to state memory\n",
    "        # state_memory=test_env.env_method(method_name=\"save_state_memory\")\n",
    "\n",
    "        if dones[0]:\n",
    "            print(\"hit end!\")\n",
    "            break\n",
    "    return account_memory, actions_memory,test_obs\n",
    "DATA_START_DATE = '1999-01-01'\n",
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2020-01-01'\n",
    "TEST_START_DATE = '2023-01-01'\n",
    "TEST_END_DATE = '2024-10-01'\n",
    "from pandas import read_csv\n",
    "from agents.evn_mvo import StockPortfolioEnv\n",
    "from agents.mvo_agent import MarkowitzAgent\n",
    "\n",
    "df_dow =read_csv('./data/dow.csv')\n",
    "df_nasdaq =read_csv('./data/nasdaq.csv')\n",
    "df_hsi = read_csv('./data/hsi.csv')\n",
    "df_dax = read_csv('./data/dax.csv')\n",
    "df_sp500 = read_csv('./data/sp500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INDICATORS = [\n",
    "    \"close_5_ema\",\n",
    "]\n",
    "fe = FeatureEngineer(use_technical_indicator=False,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature =True)\n",
    "\n",
    "processed = fe.preprocess_data(df_dax)\n",
    "processed = processed.fillna(0)\n",
    "processed= processed.replace(np.inf,0)\n",
    "train_data= data_split(processed, DATA_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(processed, TEST_START_DATE, TEST_END_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2020-01-01'\n",
    "TEST_START_DATE = '2020-01-01'\n",
    "TEST_END_DATE = '2024-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= data_split(processed, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(processed, TEST_START_DATE, TEST_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recession_result = benchmark(train_data,test_data,50_000,1,['close','return'],INDICATORS,save=True,tag='return_vector_log_return_reward_recession',reward_sortino=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_16\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    fps             | 20            |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 99            |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0059424336 |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008619024 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -37         |\n",
      "|    explained_variance   | -0.00368    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.349      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 0.003127287 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0702      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1040239.3125\n",
      "Final accumulative portfolio value: 1.0402393125\n",
      "Maximum DrawDown: -0.5903791920898076\n",
      "Sharpe ratio: 0.09772986502810768\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -19.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008502876  |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.1        |\n",
      "|    explained_variance   | -0.162       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.371       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    reward               | -0.012028862 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00913      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -19.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076851267 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.2        |\n",
      "|    explained_variance   | 0.0086       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.367       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    reward               | 0.0006231579 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0806       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1121783.375\n",
      "Final accumulative portfolio value: 1.121783375\n",
      "Maximum DrawDown: -0.5774704667214694\n",
      "Sharpe ratio: 0.11955704865671786\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -18.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 511          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009472007  |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.3        |\n",
      "|    explained_variance   | -0.261       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.402       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    reward               | -0.001700609 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00607      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -18.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 614          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00701057   |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.5        |\n",
      "|    explained_variance   | 0.0221       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.378       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    reward               | -0.011867204 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0583       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -18.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009113592 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -37.6       |\n",
      "|    explained_variance   | -0.0846     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.392      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 0.00665965  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1204534.375\n",
      "Final accumulative portfolio value: 1.204534375\n",
      "Maximum DrawDown: -0.536029581660487\n",
      "Sharpe ratio: 0.14020226950879014\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -14          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010324301  |\n",
      "|    clip_fraction        | 0.0704       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.6        |\n",
      "|    explained_variance   | -0.0529      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.401       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    reward               | -0.007853465 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00743      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -14           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 923           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007634743   |\n",
      "|    clip_fraction        | 0.054         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -37.7         |\n",
      "|    explained_variance   | 0.00799       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.348        |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0158       |\n",
      "|    reward               | 0.00081691996 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.201         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 989325.0625\n",
      "Final accumulative portfolio value: 0.9893250625\n",
      "Maximum DrawDown: -0.5898155784476056\n",
      "Sharpe ratio: 0.08308782405609824\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1026         |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007627108  |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.7        |\n",
      "|    explained_variance   | -0.562       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.373       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    reward               | -0.006937761 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00522      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1126         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010375079  |\n",
      "|    clip_fraction        | 0.0901       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -37.8        |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.34        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    reward               | -0.008542491 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.115        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -20.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 20           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1227         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009799873  |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38          |\n",
      "|    explained_variance   | -0.0729      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.386       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    reward               | 0.0047916374 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0241       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1069567.875\n",
      "Final accumulative portfolio value: 1.069567875\n",
      "Maximum DrawDown: -0.5796475672906731\n",
      "Sharpe ratio: 0.10561349206293992\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -22.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1331         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009020905  |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38          |\n",
      "|    explained_variance   | -0.2         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.385       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    reward               | -0.015834706 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00331      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -22.8         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 1441          |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0101379175  |\n",
      "|    clip_fraction        | 0.0803        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -38.1         |\n",
      "|    explained_variance   | 0.00807       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.294        |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.0172       |\n",
      "|    reward               | -0.0012103929 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.224         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 851729.5\n",
      "Final accumulative portfolio value: 0.8517295\n",
      "Maximum DrawDown: -0.6484243891896486\n",
      "Sharpe ratio: 0.038847358822950685\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -31.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1550         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009976929  |\n",
      "|    clip_fraction        | 0.0777       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38.1        |\n",
      "|    explained_variance   | -0.262       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.399       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    reward               | -0.027623972 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00871      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -31.9         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 1655          |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009284733   |\n",
      "|    clip_fraction        | 0.0817        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -38.2         |\n",
      "|    explained_variance   | 0.0134        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.361        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0198       |\n",
      "|    reward               | -0.0068878275 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.177         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -31.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013164822 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -38.3       |\n",
      "|    explained_variance   | -0.0709     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.383      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | 0.001483062 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0287      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 880328.0625\n",
      "Final accumulative portfolio value: 0.8803280625\n",
      "Maximum DrawDown: -0.6249610942321857\n",
      "Sharpe ratio: 0.04875062567866523\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -35.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1875         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009072309  |\n",
      "|    clip_fraction        | 0.0731       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38.3        |\n",
      "|    explained_variance   | -0.205       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.403       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | -0.010017419 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00376      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -35.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1982         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089404285 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38.4        |\n",
      "|    explained_variance   | 0.0174       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.358       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    reward               | 0.0026750981 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.114        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 930960.625\n",
      "Final accumulative portfolio value: 0.930960625\n",
      "Maximum DrawDown: -0.6056880629570371\n",
      "Sharpe ratio: 0.0651994582090437\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -35.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2092         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01119518   |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38.5        |\n",
      "|    explained_variance   | -0.314       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.399       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0209      |\n",
      "|    reward               | -0.026918419 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00811      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -35.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 2198          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009483615   |\n",
      "|    clip_fraction        | 0.0938        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -38.5         |\n",
      "|    explained_variance   | 0.0171        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.372        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0213       |\n",
      "|    reward               | -0.0028785113 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.106         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -35.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2305         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010711914  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -38.6        |\n",
      "|    explained_variance   | -0.174       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.388       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    reward               | 0.0058357916 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.0119       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1103980.875\n",
      "Final accumulative portfolio value: 1.103980875\n",
      "Maximum DrawDown: -0.5778094378294085\n",
      "Sharpe ratio: 0.11504795624723255\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -34.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 2412          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009965924   |\n",
      "|    clip_fraction        | 0.102         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -38.7         |\n",
      "|    explained_variance   | -0.187        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.396        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0167       |\n",
      "|    reward               | -0.0034755233 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.00346       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -34.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2520        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009603658 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -38.9       |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.385      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | 0.00443383  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1018631.0625\n",
      "Final accumulative portfolio value: 1.0186310625\n",
      "Maximum DrawDown: -0.567745811888496\n",
      "Sharpe ratio: 0.09129853978360217\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -33.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2630         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108059235 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39          |\n",
      "|    explained_variance   | -0.3         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.405       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0195      |\n",
      "|    reward               | -0.025181357 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00859      |\n",
      "------------------------------------------\n",
      "Logging to ./data/tb\\ppo_17\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 19           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 106          |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.003821221 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109720975 |\n",
      "|    clip_fraction        | 0.0922       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.2        |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.388       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0197      |\n",
      "|    reward               | 0.004285798  |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.0731       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1092819.875\n",
      "Final accumulative portfolio value: 1.092819875\n",
      "Maximum DrawDown: -0.5785290722836127\n",
      "Sharpe ratio: 0.11190905097503975\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -8.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 324          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011103724  |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.3        |\n",
      "|    explained_variance   | -0.272       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.422       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0207      |\n",
      "|    reward               | -0.012378838 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.00928      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -8.69         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 428           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010663973   |\n",
      "|    clip_fraction        | 0.0918        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -39.4         |\n",
      "|    explained_variance   | 0.0185        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.371        |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.0204       |\n",
      "|    reward               | -3.326743e-05 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 0.108         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1036370.9375\n",
      "Final accumulative portfolio value: 1.0363709375\n",
      "Maximum DrawDown: -0.5816763122322459\n",
      "Sharpe ratio: 0.09618321674208019\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -16.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009369722  |\n",
      "|    clip_fraction        | 0.0812       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.5        |\n",
      "|    explained_variance   | -0.373       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.43        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    reward               | -0.013170221 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.00619      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -16.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010020614 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -39.6       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.314      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -0.0162287  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -16.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010364328  |\n",
      "|    clip_fraction        | 0.086        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.7        |\n",
      "|    explained_variance   | -0.0914      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.408       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    reward               | 0.0023428905 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.0262       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 957281.75\n",
      "Final accumulative portfolio value: 0.95728175\n",
      "Maximum DrawDown: -0.5992142151317412\n",
      "Sharpe ratio: 0.07291749059404354\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -24.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 859           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012195009   |\n",
      "|    clip_fraction        | 0.113         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -39.7         |\n",
      "|    explained_variance   | -0.108        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.44         |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.0202       |\n",
      "|    reward               | -0.0061581223 |\n",
      "|    std                  | 1.12          |\n",
      "|    value_loss           | 0.00777       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -24.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010568803  |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.8        |\n",
      "|    explained_variance   | 0.0179       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.396       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    reward               | 0.0027926627 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.092        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1104397.5\n",
      "Final accumulative portfolio value: 1.1043975\n",
      "Maximum DrawDown: -0.5560254325479161\n",
      "Sharpe ratio: 0.11486260407538722\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -23.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 1076         |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009510563  |\n",
      "|    clip_fraction        | 0.0812       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.8        |\n",
      "|    explained_variance   | -0.348       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.424       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    reward               | -0.012810297 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.00512      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -23.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1184         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009796508  |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -39.9        |\n",
      "|    explained_variance   | 0.0171       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.35        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0204      |\n",
      "|    reward               | -0.011650144 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.151        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -23.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1292         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011293103  |\n",
      "|    clip_fraction        | 0.0949       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40          |\n",
      "|    explained_variance   | -0.0623      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.422       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    reward               | 0.0022813084 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.0314       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 923056.9375\n",
      "Final accumulative portfolio value: 0.9230569375\n",
      "Maximum DrawDown: -0.6261897341933238\n",
      "Sharpe ratio: 0.06310460065376271\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -29.3         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 1405          |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009076135   |\n",
      "|    clip_fraction        | 0.0739        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.1         |\n",
      "|    explained_variance   | -0.164        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.433        |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.0144       |\n",
      "|    reward               | -0.0015636923 |\n",
      "|    std                  | 1.13          |\n",
      "|    value_loss           | 0.00439       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -29.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1514         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091603305 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.1        |\n",
      "|    explained_variance   | 0.0198       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.372       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    reward               | 0.0025086855 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1018282.8125\n",
      "Final accumulative portfolio value: 1.0182828125\n",
      "Maximum DrawDown: -0.5554520952945348\n",
      "Sharpe ratio: 0.09169454209371403\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -27.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1646         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011245633  |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.3        |\n",
      "|    explained_variance   | -0.468       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.427       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    reward               | -0.019421207 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.00508      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -27.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1758        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011425186 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.4       |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.374      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | -0.00711177 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -27.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1872        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010593526 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.5       |\n",
      "|    explained_variance   | -0.0868     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.39       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 0.001006683 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0199      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 829985.75\n",
      "Final accumulative portfolio value: 0.82998575\n",
      "Maximum DrawDown: -0.6207653127872464\n",
      "Sharpe ratio: 0.032212521282064976\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -30.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1997         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009355321  |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.5        |\n",
      "|    explained_variance   | -0.199       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.419       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    reward               | -0.015086446 |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 0.00321      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -30.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2112         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008309043  |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.385       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    reward               | 0.0013624562 |\n",
      "|    std                  | 1.16         |\n",
      "|    value_loss           | 0.1          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 940132.8125\n",
      "Final accumulative portfolio value: 0.9401328125\n",
      "Maximum DrawDown: -0.6434074695070862\n",
      "Sharpe ratio: 0.06812510959754131\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -33         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2231        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009975373 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.7       |\n",
      "|    explained_variance   | -0.184      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | -0.03786424 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -33           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 2345          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00908363    |\n",
      "|    clip_fraction        | 0.0715        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.8         |\n",
      "|    explained_variance   | 0.0118        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.371        |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.0178       |\n",
      "|    reward               | -0.0024935207 |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 0.155         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -33         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2459        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009417752 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.8       |\n",
      "|    explained_variance   | -0.11       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.419      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.004935086 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.0197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1037821.625\n",
      "Final accumulative portfolio value: 1.037821625\n",
      "Maximum DrawDown: -0.5903858504354043\n",
      "Sharpe ratio: 0.0969728006193701\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | -34.5         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 2575          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009401444   |\n",
      "|    clip_fraction        | 0.0741        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.9         |\n",
      "|    explained_variance   | -0.257        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.452        |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.0142       |\n",
      "|    reward               | -0.0057320977 |\n",
      "|    std                  | 1.17          |\n",
      "|    value_loss           | 0.00343       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | -34.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2689        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507384 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41         |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.347      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 0.005136625 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1042901.9375\n",
      "Final accumulative portfolio value: 1.0429019375\n",
      "Maximum DrawDown: -0.572169697768615\n",
      "Sharpe ratio: 0.09809071731781896\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | -34.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2805         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011867353  |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41          |\n",
      "|    explained_variance   | -0.224       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.417       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0205      |\n",
      "|    reward               | -0.018893309 |\n",
      "|    std                  | 1.17         |\n",
      "|    value_loss           | 0.00938      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1447160.25\n",
      "Final accumulative portfolio value: 1.44716025\n",
      "Maximum DrawDown: -0.31634201171773624\n",
      "Sharpe ratio: 0.4977212107377383\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_14\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | -3.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | -0.021735968 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000279     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38          |\n",
      "|    explained_variance | 0.282        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | 0.55         |\n",
      "|    reward             | -0.011753926 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.000242     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 300           |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 1500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.9         |\n",
      "|    explained_variance | -2.06         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.559         |\n",
      "|    reward             | -0.0068502766 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000214      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 112           |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40           |\n",
      "|    explained_variance | -1.97         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 0.293         |\n",
      "|    reward             | -0.0031811825 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 8.32e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | -1.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.281       |\n",
      "|    reward             | -0.00473084 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.000108    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -0.48        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.249        |\n",
      "|    reward             | -0.002347316 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 3.57e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44        |\n",
      "|    explained_variance | -2.72      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -0.594     |\n",
      "|    reward             | 0.00294523 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 0.000208   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.6        |\n",
      "|    explained_variance | -1.18e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.0813      |\n",
      "|    reward             | 0.0029647716 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 2.03e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.2        |\n",
      "|    explained_variance | -3.48        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.382        |\n",
      "|    reward             | 0.0041813715 |\n",
      "|    std                | 1.49         |\n",
      "|    value_loss         | 6.8e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.9        |\n",
      "|    explained_variance | -37          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0655       |\n",
      "|    reward             | 0.0052208295 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 1.54e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1001586.9375\n",
      "Final accumulative portfolio value: 1.0015869375\n",
      "Maximum DrawDown: -0.5953786457626197\n",
      "Sharpe ratio: 0.08636468760034152\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.5        |\n",
      "|    explained_variance | -2.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -1.94        |\n",
      "|    reward             | -0.023326743 |\n",
      "|    std                | 1.62         |\n",
      "|    value_loss         | 0.00166      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50          |\n",
      "|    explained_variance | -0.508       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.756        |\n",
      "|    reward             | -0.020632911 |\n",
      "|    std                | 1.66         |\n",
      "|    value_loss         | 0.000295     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.8        |\n",
      "|    explained_variance | -0.415       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | -0.013786828 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 5.73e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 397          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.9        |\n",
      "|    explained_variance | -11.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.128        |\n",
      "|    reward             | -0.008130861 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 1.12e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53          |\n",
      "|    explained_variance | -0.25        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0133      |\n",
      "|    reward             | -0.012568781 |\n",
      "|    std                | 1.86         |\n",
      "|    value_loss         | 1.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 456          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.4        |\n",
      "|    explained_variance | -11.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.008836032 |\n",
      "|    std                | 1.96         |\n",
      "|    value_loss         | 1.91e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.7        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 484          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.9        |\n",
      "|    explained_variance | -84.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.0483      |\n",
      "|    reward             | -0.002719798 |\n",
      "|    std                | 2.08         |\n",
      "|    value_loss         | 4.93e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.7         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 513           |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.6         |\n",
      "|    explained_variance | -1.13         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.111        |\n",
      "|    reward             | -0.0029054144 |\n",
      "|    std                | 2.22          |\n",
      "|    value_loss         | 6.29e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.7         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 541           |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.3         |\n",
      "|    explained_variance | -2.42         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.0362        |\n",
      "|    reward             | -0.0012786436 |\n",
      "|    std                | 2.37          |\n",
      "|    value_loss         | 8.27e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.7         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 570           |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -61.1         |\n",
      "|    explained_variance | -3.16         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.0477        |\n",
      "|    reward             | -0.0014352399 |\n",
      "|    std                | 2.54          |\n",
      "|    value_loss         | 9.04e-07      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 735936.8125\n",
      "Final accumulative portfolio value: 0.7359368125\n",
      "Maximum DrawDown: -0.6545198807440152\n",
      "Sharpe ratio: -0.002797205964190209\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 601          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.9        |\n",
      "|    explained_variance | 0.202        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -2.28        |\n",
      "|    reward             | -0.036898132 |\n",
      "|    std                | 2.61         |\n",
      "|    value_loss         | 0.00281      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 630          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.6        |\n",
      "|    explained_variance | -0.601       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 0.716        |\n",
      "|    reward             | -0.019460637 |\n",
      "|    std                | 2.69         |\n",
      "|    value_loss         | 0.000215     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -52.3       |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 658         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.5       |\n",
      "|    explained_variance | -6.25       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.0421      |\n",
      "|    reward             | -0.01080634 |\n",
      "|    std                | 2.78        |\n",
      "|    value_loss         | 3.89e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 688          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.7        |\n",
      "|    explained_variance | -16.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.004814539 |\n",
      "|    std                | 2.92         |\n",
      "|    value_loss         | 1.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 719          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66          |\n",
      "|    explained_variance | -4.9         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 0.856        |\n",
      "|    reward             | -0.007973516 |\n",
      "|    std                | 3.07         |\n",
      "|    value_loss         | 0.000259     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.3        |\n",
      "|    explained_variance | -2.65        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | -0.199       |\n",
      "|    reward             | -0.005466634 |\n",
      "|    std                | 3.22         |\n",
      "|    value_loss         | 3.11e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -52.3          |\n",
      "| time/                 |                |\n",
      "|    fps                | 17             |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 777            |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.8          |\n",
      "|    explained_variance | -37.5          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2699           |\n",
      "|    policy_loss        | -0.288         |\n",
      "|    reward             | -0.00071629975 |\n",
      "|    std                | 3.41           |\n",
      "|    value_loss         | 2.69e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -52.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.4        |\n",
      "|    explained_variance | -1.87        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.122       |\n",
      "|    reward             | -0.001047265 |\n",
      "|    std                | 3.63         |\n",
      "|    value_loss         | 4.42e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -52.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 839           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.1         |\n",
      "|    explained_variance | -94.6         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.0165       |\n",
      "|    reward             | 0.00023567023 |\n",
      "|    std                | 3.88          |\n",
      "|    value_loss         | 6.53e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -52.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 870           |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.9         |\n",
      "|    explained_variance | -4.62         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.137         |\n",
      "|    reward             | 0.00094466755 |\n",
      "|    std                | 4.16          |\n",
      "|    value_loss         | 7.85e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 841874.625\n",
      "Final accumulative portfolio value: 0.841874625\n",
      "Maximum DrawDown: -0.5948439243874901\n",
      "Sharpe ratio: 0.03601897867381985\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 902          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.8        |\n",
      "|    explained_variance | -3.24        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.123       |\n",
      "|    reward             | -0.016329952 |\n",
      "|    std                | 4.31         |\n",
      "|    value_loss         | 6.69e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 931          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.6        |\n",
      "|    explained_variance | -1.59        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.593        |\n",
      "|    reward             | -0.022223603 |\n",
      "|    std                | 4.44         |\n",
      "|    value_loss         | 8.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 961          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.5        |\n",
      "|    explained_variance | -0.574       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.536        |\n",
      "|    reward             | -0.011139691 |\n",
      "|    std                | 4.59         |\n",
      "|    value_loss         | 6.21e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49           |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 990           |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -77.7         |\n",
      "|    explained_variance | -8.19         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | 0.281         |\n",
      "|    reward             | -0.0066008405 |\n",
      "|    std                | 4.82          |\n",
      "|    value_loss         | 3.1e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 1019         |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79          |\n",
      "|    explained_variance | 0.167        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | -0.011345053 |\n",
      "|    std                | 5.06         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 1047         |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -80.3        |\n",
      "|    explained_variance | -18.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | -0.00776     |\n",
      "|    reward             | -0.005440649 |\n",
      "|    std                | 5.32         |\n",
      "|    value_loss         | 5.78e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49           |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 1078          |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81.9         |\n",
      "|    explained_variance | -19.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | 0.386         |\n",
      "|    reward             | -0.0013784512 |\n",
      "|    std                | 5.65          |\n",
      "|    value_loss         | 2.86e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49           |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 1107          |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -83.5         |\n",
      "|    explained_variance | -0.606        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | -0.103        |\n",
      "|    reward             | 0.00016853826 |\n",
      "|    std                | 6.02          |\n",
      "|    value_loss         | 2.03e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49           |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 1136          |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -85.2         |\n",
      "|    explained_variance | -219          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 0.177         |\n",
      "|    reward             | -0.0006354667 |\n",
      "|    std                | 6.43          |\n",
      "|    value_loss         | 4.8e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49          |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 1165         |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -87          |\n",
      "|    explained_variance | -1.3         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.077        |\n",
      "|    reward             | 0.0008572833 |\n",
      "|    std                | 6.88         |\n",
      "|    value_loss         | 1.42e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 797676.625\n",
      "Final accumulative portfolio value: 0.797676625\n",
      "Maximum DrawDown: -0.6160380276403856\n",
      "Sharpe ratio: 0.02061944058646649\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 1197         |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -88          |\n",
      "|    explained_variance | -0.176       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 2.92         |\n",
      "|    reward             | -0.020172039 |\n",
      "|    std                | 7.14         |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 1225         |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -88.7        |\n",
      "|    explained_variance | -0.748       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 2.64         |\n",
      "|    reward             | -0.027983205 |\n",
      "|    std                | 7.33         |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 1253         |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -89.5        |\n",
      "|    explained_variance | -21.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | -0.021157352 |\n",
      "|    std                | 7.58         |\n",
      "|    value_loss         | 7.38e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 1283          |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -90.7         |\n",
      "|    explained_variance | -7.94         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.444         |\n",
      "|    reward             | -0.0111143375 |\n",
      "|    std                | 7.94          |\n",
      "|    value_loss         | 4.63e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -50.1       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 1324        |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92.1       |\n",
      "|    explained_variance | -1.21       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.403       |\n",
      "|    reward             | -0.01568631 |\n",
      "|    std                | 8.36        |\n",
      "|    value_loss         | 8.76e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 1357         |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -93.2        |\n",
      "|    explained_variance | -0.217       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.153        |\n",
      "|    reward             | -0.007053842 |\n",
      "|    std                | 8.74         |\n",
      "|    value_loss         | 4.62e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 1392          |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -94.7         |\n",
      "|    explained_variance | -5.15         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | 0.0851        |\n",
      "|    reward             | -0.0024056928 |\n",
      "|    std                | 9.23          |\n",
      "|    value_loss         | 1.22e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -50.1          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 4800           |\n",
      "|    time_elapsed       | 1423           |\n",
      "|    total_timesteps    | 24000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -96.2          |\n",
      "|    explained_variance | -311           |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4799           |\n",
      "|    policy_loss        | 0.0101         |\n",
      "|    reward             | -5.5926863e-05 |\n",
      "|    std                | 9.82           |\n",
      "|    value_loss         | 7.36e-06       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -50.1          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 4900           |\n",
      "|    time_elapsed       | 1458           |\n",
      "|    total_timesteps    | 24500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -97.9          |\n",
      "|    explained_variance | -112           |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4899           |\n",
      "|    policy_loss        | 0.187          |\n",
      "|    reward             | -0.00016892249 |\n",
      "|    std                | 10.5           |\n",
      "|    value_loss         | 4.46e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 1487         |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -99.7        |\n",
      "|    explained_variance | -5.79        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | -0.186       |\n",
      "|    reward             | 0.0013387323 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 5.11e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 860441.875\n",
      "Final accumulative portfolio value: 0.860441875\n",
      "Maximum DrawDown: -0.642535783026571\n",
      "Sharpe ratio: 0.042960294997326245\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.03e+03  |\n",
      "|    ep_rew_mean        | -53.3     |\n",
      "| time/                 |           |\n",
      "|    fps                | 16        |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 1520      |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -101      |\n",
      "|    explained_variance | -0.054    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 3.39      |\n",
      "|    reward             | 0.0201855 |\n",
      "|    std                | 11.6      |\n",
      "|    value_loss         | 0.00124   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 1551         |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -101         |\n",
      "|    explained_variance | -0.78        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | 0.618        |\n",
      "|    reward             | -0.012414965 |\n",
      "|    std                | 12           |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -53.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5300          |\n",
      "|    time_elapsed       | 1580          |\n",
      "|    total_timesteps    | 26500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -102          |\n",
      "|    explained_variance | 0.496         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5299          |\n",
      "|    policy_loss        | -0.0614       |\n",
      "|    reward             | -0.0055883466 |\n",
      "|    std                | 12.4          |\n",
      "|    value_loss         | 4.62e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 1609         |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -103         |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.503        |\n",
      "|    reward             | 0.0021346882 |\n",
      "|    std                | 13           |\n",
      "|    value_loss         | 2.48e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 1639         |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -105         |\n",
      "|    explained_variance | -14.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.594       |\n",
      "|    reward             | -0.010683787 |\n",
      "|    std                | 13.7         |\n",
      "|    value_loss         | 7.54e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 1667         |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -106         |\n",
      "|    explained_variance | -20.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | 0.0444       |\n",
      "|    reward             | 0.0005084248 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 7.1e-06      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | -53.3      |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 1696       |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -108       |\n",
      "|    explained_variance | -1.15      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -0.596     |\n",
      "|    reward             | 0.00357836 |\n",
      "|    std                | 15.3       |\n",
      "|    value_loss         | 3.23e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 1725         |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -109         |\n",
      "|    explained_variance | -5.3         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.00184      |\n",
      "|    reward             | 0.0054588406 |\n",
      "|    std                | 16.3         |\n",
      "|    value_loss         | 1.94e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -53.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 1755         |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -111         |\n",
      "|    explained_variance | -4.12        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.133       |\n",
      "|    reward             | 0.0040151784 |\n",
      "|    std                | 17.4         |\n",
      "|    value_loss         | 1.73e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -53.3       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1783        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -59.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.145       |\n",
      "|    reward             | 0.004897734 |\n",
      "|    std                | 18.6        |\n",
      "|    value_loss         | 2.02e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1008352.0625\n",
      "Final accumulative portfolio value: 1.0083520625\n",
      "Maximum DrawDown: -0.5831930952274214\n",
      "Sharpe ratio: 0.0881863571776322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 1814         |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -114         |\n",
      "|    explained_variance | 0.0182       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -7.59        |\n",
      "|    reward             | -0.043821447 |\n",
      "|    std                | 19.4         |\n",
      "|    value_loss         | 0.0056       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -44.9       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1844        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -115        |\n",
      "|    explained_variance | -2.77       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 0.811       |\n",
      "|    reward             | -0.03837485 |\n",
      "|    std                | 19.9        |\n",
      "|    value_loss         | 0.000276    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -44.9       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1876        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -115        |\n",
      "|    explained_variance | -3.21       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.0714      |\n",
      "|    reward             | -0.01478311 |\n",
      "|    std                | 20.6        |\n",
      "|    value_loss         | 1.65e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 1906         |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -117         |\n",
      "|    explained_variance | -0.75        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.723       |\n",
      "|    reward             | -0.012322299 |\n",
      "|    std                | 21.5         |\n",
      "|    value_loss         | 4.78e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 1937         |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -118         |\n",
      "|    explained_variance | -1.24        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -3.03        |\n",
      "|    reward             | -0.020295242 |\n",
      "|    std                | 22.6         |\n",
      "|    value_loss         | 0.000868     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 1967         |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -119         |\n",
      "|    explained_variance | -3.72        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | -0.005059892 |\n",
      "|    std                | 23.8         |\n",
      "|    value_loss         | 4.63e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 2002         |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | -9.27        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.216        |\n",
      "|    reward             | -0.003192954 |\n",
      "|    std                | 25.3         |\n",
      "|    value_loss         | 4.03e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -44.9        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 2031         |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -122         |\n",
      "|    explained_variance | -481         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.0755       |\n",
      "|    reward             | 9.919334e-05 |\n",
      "|    std                | 26.9         |\n",
      "|    value_loss         | 2.68e-06     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -44.9          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 6900           |\n",
      "|    time_elapsed       | 2061           |\n",
      "|    total_timesteps    | 34500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -124           |\n",
      "|    explained_variance | -0.986         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6899           |\n",
      "|    policy_loss        | 0.126          |\n",
      "|    reward             | -0.00034616637 |\n",
      "|    std                | 28.8           |\n",
      "|    value_loss         | 1.41e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -44.9         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7000          |\n",
      "|    time_elapsed       | 2090          |\n",
      "|    total_timesteps    | 35000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -126          |\n",
      "|    explained_variance | -4.03         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6999          |\n",
      "|    policy_loss        | 0.702         |\n",
      "|    reward             | 0.00029898714 |\n",
      "|    std                | 30.9          |\n",
      "|    value_loss         | 6.27e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 794031.8125\n",
      "Final accumulative portfolio value: 0.7940318125\n",
      "Maximum DrawDown: -0.6373603718632463\n",
      "Sharpe ratio: 0.020394630328767864\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -47.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 2124         |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -127         |\n",
      "|    explained_variance | -2.82        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 2.32         |\n",
      "|    reward             | -0.018159753 |\n",
      "|    std                | 32.3         |\n",
      "|    value_loss         | 0.000705     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -47.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 2154        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -128        |\n",
      "|    explained_variance | -1.6        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -0.955      |\n",
      "|    reward             | -0.04025205 |\n",
      "|    std                | 33.2        |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -47.5         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 2185          |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -129          |\n",
      "|    explained_variance | -2.4          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | 0.623         |\n",
      "|    reward             | -0.0139193265 |\n",
      "|    std                | 34.4          |\n",
      "|    value_loss         | 3.22e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -47.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 2215         |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -130         |\n",
      "|    explained_variance | -103         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.386        |\n",
      "|    reward             | -0.009475532 |\n",
      "|    std                | 36.1         |\n",
      "|    value_loss         | 1.16e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -47.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 2247         |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -131         |\n",
      "|    explained_variance | -100         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -4.33        |\n",
      "|    reward             | -0.022204084 |\n",
      "|    std                | 38.1         |\n",
      "|    value_loss         | 0.00138      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -47.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 2277         |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -133         |\n",
      "|    explained_variance | -2.93        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.705        |\n",
      "|    reward             | -0.006835982 |\n",
      "|    std                | 40           |\n",
      "|    value_loss         | 3.52e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -47.5         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 2309          |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -134          |\n",
      "|    explained_variance | -0.989        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | 0.0394        |\n",
      "|    reward             | -0.0047979443 |\n",
      "|    std                | 42.4          |\n",
      "|    value_loss         | 9.19e-07      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -47.5          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 7800           |\n",
      "|    time_elapsed       | 2341           |\n",
      "|    total_timesteps    | 39000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -136           |\n",
      "|    explained_variance | -2.29          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7799           |\n",
      "|    policy_loss        | -0.207         |\n",
      "|    reward             | -0.00059918856 |\n",
      "|    std                | 45.2           |\n",
      "|    value_loss         | 3.42e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -47.5         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 2374          |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -138          |\n",
      "|    explained_variance | -7.54         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | 0.115         |\n",
      "|    reward             | -0.0011131673 |\n",
      "|    std                | 48.4          |\n",
      "|    value_loss         | 8.05e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -47.5         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 2404          |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -139          |\n",
      "|    explained_variance | -79.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | 0.278         |\n",
      "|    reward             | 0.00024537405 |\n",
      "|    std                | 51.8          |\n",
      "|    value_loss         | 5.95e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 846106.625\n",
      "Final accumulative portfolio value: 0.846106625\n",
      "Maximum DrawDown: -0.6539216414414101\n",
      "Sharpe ratio: 0.03717328548205755\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.1       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 2436        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | -1.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -5.41       |\n",
      "|    reward             | -0.02728824 |\n",
      "|    std                | 54.3        |\n",
      "|    value_loss         | 0.00196     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 2465         |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -141         |\n",
      "|    explained_variance | -6.04        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -1.99        |\n",
      "|    reward             | -0.034695473 |\n",
      "|    std                | 55.8         |\n",
      "|    value_loss         | 0.000235     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 2495         |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -142         |\n",
      "|    explained_variance | -0.694       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.887        |\n",
      "|    reward             | -0.013831853 |\n",
      "|    std                | 57.8         |\n",
      "|    value_loss         | 5.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 2525         |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -144         |\n",
      "|    explained_variance | -1.12        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.737        |\n",
      "|    reward             | -0.007574584 |\n",
      "|    std                | 60.6         |\n",
      "|    value_loss         | 2.87e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.1       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 2559        |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | -92.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -2.82       |\n",
      "|    reward             | -0.01393323 |\n",
      "|    std                | 64.1        |\n",
      "|    value_loss         | 0.000486    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8600          |\n",
      "|    time_elapsed       | 2587          |\n",
      "|    total_timesteps    | 43000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -146          |\n",
      "|    explained_variance | -7.71         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8599          |\n",
      "|    policy_loss        | 0.543         |\n",
      "|    reward             | -0.0054205945 |\n",
      "|    std                | 67.3          |\n",
      "|    value_loss         | 1.72e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 2616          |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -148          |\n",
      "|    explained_variance | -41.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | -0.00659      |\n",
      "|    reward             | -0.0038546212 |\n",
      "|    std                | 71.3          |\n",
      "|    value_loss         | 1.08e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.1       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2646        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | -0.687      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 0.408       |\n",
      "|    reward             | 0.001279488 |\n",
      "|    std                | 76          |\n",
      "|    value_loss         | 9.38e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 2675         |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -151         |\n",
      "|    explained_variance | -24.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 0.0556       |\n",
      "|    reward             | -0.000722862 |\n",
      "|    std                | 81.3         |\n",
      "|    value_loss         | 8.68e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 2705         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -153         |\n",
      "|    explained_variance | -138         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | -0.0281      |\n",
      "|    reward             | 0.0010554243 |\n",
      "|    std                | 87.1         |\n",
      "|    value_loss         | 1.22e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 808535.5\n",
      "Final accumulative portfolio value: 0.8085355\n",
      "Maximum DrawDown: -0.6052500124510265\n",
      "Sharpe ratio: 0.024853074066955246\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 2739         |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -154         |\n",
      "|    explained_variance | -0.29        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 1.86         |\n",
      "|    reward             | -0.012794799 |\n",
      "|    std                | 91.6         |\n",
      "|    value_loss         | 0.000426     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 2770         |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -155         |\n",
      "|    explained_variance | -3.1         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 3.28         |\n",
      "|    reward             | -0.033794127 |\n",
      "|    std                | 94.3         |\n",
      "|    value_loss         | 0.000622     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 2802         |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -156         |\n",
      "|    explained_variance | -32.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.863        |\n",
      "|    reward             | -0.013595342 |\n",
      "|    std                | 97.6         |\n",
      "|    value_loss         | 3.53e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9400          |\n",
      "|    time_elapsed       | 2836          |\n",
      "|    total_timesteps    | 47000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -157          |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9399          |\n",
      "|    policy_loss        | 0.546         |\n",
      "|    reward             | -0.0064797997 |\n",
      "|    std                | 102           |\n",
      "|    value_loss         | 1.29e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 2865         |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -159         |\n",
      "|    explained_variance | -6.94e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 22.6         |\n",
      "|    reward             | -0.016310792 |\n",
      "|    std                | 108          |\n",
      "|    value_loss         | 0.0433       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 2894         |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -160         |\n",
      "|    explained_variance | -13.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.355        |\n",
      "|    reward             | -0.008874997 |\n",
      "|    std                | 113          |\n",
      "|    value_loss         | 1.79e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 2925         |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -161         |\n",
      "|    explained_variance | -42          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.0486      |\n",
      "|    reward             | -0.004176604 |\n",
      "|    std                | 119          |\n",
      "|    value_loss         | 6.05e-07     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 2958          |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -163          |\n",
      "|    explained_variance | -1.06         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | -0.401        |\n",
      "|    reward             | -0.0013092178 |\n",
      "|    std                | 126           |\n",
      "|    value_loss         | 7.54e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 2991          |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -164          |\n",
      "|    explained_variance | -5.12         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | -0.0586       |\n",
      "|    reward             | -0.0020209155 |\n",
      "|    std                | 135           |\n",
      "|    value_loss         | 3.35e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 3023         |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -166         |\n",
      "|    explained_variance | -44.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 0.223        |\n",
      "|    reward             | 0.0014169913 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 1.83e-06     |\n",
      "----------------------------------------\n",
      "Logging to ./data/tb\\a2c_15\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -167       |\n",
      "|    explained_variance | -1.12      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10099      |\n",
      "|    policy_loss        | 2.46       |\n",
      "|    reward             | -0.0197443 |\n",
      "|    std                | 149        |\n",
      "|    value_loss         | 0.000301   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -168         |\n",
      "|    explained_variance | 0.422        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | 1.71         |\n",
      "|    reward             | -0.010495399 |\n",
      "|    std                | 154          |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -169         |\n",
      "|    explained_variance | -1.84        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | 0.613        |\n",
      "|    reward             | -0.003936441 |\n",
      "|    std                | 160          |\n",
      "|    value_loss         | 1.79e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 121           |\n",
      "|    total_timesteps    | 2000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -170          |\n",
      "|    explained_variance | 0.578         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10399         |\n",
      "|    policy_loss        | 0.52          |\n",
      "|    reward             | -0.0017989331 |\n",
      "|    std                | 169           |\n",
      "|    value_loss         | 1.04e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -171         |\n",
      "|    explained_variance | -2.84        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10499        |\n",
      "|    policy_loss        | -0.0204      |\n",
      "|    reward             | -0.003987789 |\n",
      "|    std                | 177          |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 185           |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -173          |\n",
      "|    explained_variance | -0.438        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10599         |\n",
      "|    policy_loss        | -0.739        |\n",
      "|    reward             | -0.0022387828 |\n",
      "|    std                | 187           |\n",
      "|    value_loss         | 2.26e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -174         |\n",
      "|    explained_variance | -6.15        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | 0.483        |\n",
      "|    reward             | 0.0030922822 |\n",
      "|    std                | 199          |\n",
      "|    value_loss         | 1.09e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -176         |\n",
      "|    explained_variance | -0.362       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | 0.0382       |\n",
      "|    reward             | 0.0025544658 |\n",
      "|    std                | 212          |\n",
      "|    value_loss         | 1.1e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -178         |\n",
      "|    explained_variance | -264         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -0.052       |\n",
      "|    reward             | 0.0039786315 |\n",
      "|    std                | 227          |\n",
      "|    value_loss         | 1.83e-07     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -180       |\n",
      "|    explained_variance | -17.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10999      |\n",
      "|    policy_loss        | 0.115      |\n",
      "|    reward             | 0.00454983 |\n",
      "|    std                | 243        |\n",
      "|    value_loss         | 1.57e-06   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 956777.125\n",
      "Final accumulative portfolio value: 0.956777125\n",
      "Maximum DrawDown: -0.5775280387800181\n",
      "Sharpe ratio: 0.07320175854822261\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -180         |\n",
      "|    explained_variance | 0.195        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -5.84        |\n",
      "|    reward             | -0.023453685 |\n",
      "|    std                | 251          |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 367          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -181         |\n",
      "|    explained_variance | -0.408       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | 2.17         |\n",
      "|    reward             | -0.018709373 |\n",
      "|    std                | 258          |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -182         |\n",
      "|    explained_variance | -1.84        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | -0.944       |\n",
      "|    reward             | -0.012426932 |\n",
      "|    std                | 268          |\n",
      "|    value_loss         | 2.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -184         |\n",
      "|    explained_variance | -4.63        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | 0.399        |\n",
      "|    reward             | -0.007091552 |\n",
      "|    std                | 282          |\n",
      "|    value_loss         | 5.27e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 452          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -185         |\n",
      "|    explained_variance | -2.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | 1.7          |\n",
      "|    reward             | -0.009966495 |\n",
      "|    std                | 297          |\n",
      "|    value_loss         | 9.97e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -31.3        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 481          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -186         |\n",
      "|    explained_variance | 0.587        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 0.289        |\n",
      "|    reward             | -0.008135685 |\n",
      "|    std                | 312          |\n",
      "|    value_loss         | 2.71e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -31.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 510           |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -188          |\n",
      "|    explained_variance | 0.445         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11699         |\n",
      "|    policy_loss        | 0.15          |\n",
      "|    reward             | -0.0021154897 |\n",
      "|    std                | 331           |\n",
      "|    value_loss         | 8.13e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -31.3         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 539           |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -189          |\n",
      "|    explained_variance | -13.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11799         |\n",
      "|    policy_loss        | 0.128         |\n",
      "|    reward             | -0.0024685822 |\n",
      "|    std                | 353           |\n",
      "|    value_loss         | 1e-06         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -31.3          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 1900           |\n",
      "|    time_elapsed       | 568            |\n",
      "|    total_timesteps    | 9500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -191           |\n",
      "|    explained_variance | -1.91          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 11899          |\n",
      "|    policy_loss        | -0.0686        |\n",
      "|    reward             | -0.00038031646 |\n",
      "|    std                | 378            |\n",
      "|    value_loss         | 1.85e-07       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -31.3          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 597            |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -193           |\n",
      "|    explained_variance | -60            |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 11999          |\n",
      "|    policy_loss        | -0.0463        |\n",
      "|    reward             | -0.00025884062 |\n",
      "|    std                | 405            |\n",
      "|    value_loss         | 2.83e-07       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 782531.875\n",
      "Final accumulative portfolio value: 0.782531875\n",
      "Maximum DrawDown: -0.6111691983862355\n",
      "Sharpe ratio: 0.014196012062707326\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -41.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 628          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -194         |\n",
      "|    explained_variance | 0.273        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | -13.9        |\n",
      "|    reward             | -0.025265893 |\n",
      "|    std                | 418          |\n",
      "|    value_loss         | 0.00635      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -41.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 657          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -195         |\n",
      "|    explained_variance | -0.459       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | 1.14         |\n",
      "|    reward             | -0.017010983 |\n",
      "|    std                | 431          |\n",
      "|    value_loss         | 6.08e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -41.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 686          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -196         |\n",
      "|    explained_variance | -0.977       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | 1.45         |\n",
      "|    reward             | -0.007879015 |\n",
      "|    std                | 449          |\n",
      "|    value_loss         | 5.71e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -41.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 715           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -197          |\n",
      "|    explained_variance | -7.2          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12399         |\n",
      "|    policy_loss        | -0.201        |\n",
      "|    reward             | -0.0027379356 |\n",
      "|    std                | 472           |\n",
      "|    value_loss         | 1.78e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -41.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 744           |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -198          |\n",
      "|    explained_variance | -3.7          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12499         |\n",
      "|    policy_loss        | 2.22          |\n",
      "|    reward             | -0.0091170445 |\n",
      "|    std                | 497           |\n",
      "|    value_loss         | 0.000147      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -41.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 773           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -200          |\n",
      "|    explained_variance | -2.14         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | -0.464        |\n",
      "|    reward             | -0.0065757334 |\n",
      "|    std                | 523           |\n",
      "|    value_loss         | 9.08e-06      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -41.6          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 802            |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -201           |\n",
      "|    explained_variance | -3.52          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12699          |\n",
      "|    policy_loss        | -0.4           |\n",
      "|    reward             | -0.00084885594 |\n",
      "|    std                | 555            |\n",
      "|    value_loss         | 6.59e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -41.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 831           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -203          |\n",
      "|    explained_variance | -0.379        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12799         |\n",
      "|    policy_loss        | -0.413        |\n",
      "|    reward             | -0.0005229752 |\n",
      "|    std                | 593           |\n",
      "|    value_loss         | 4.3e-06       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -41.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 860          |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -205         |\n",
      "|    explained_variance | -1.36        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | -0.00947     |\n",
      "|    reward             | 0.0011173288 |\n",
      "|    std                | 634          |\n",
      "|    value_loss         | 1.04e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -41.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 889          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -206         |\n",
      "|    explained_variance | -6.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | 0.163        |\n",
      "|    reward             | 0.0012158431 |\n",
      "|    std                | 679          |\n",
      "|    value_loss         | 1.56e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 847982.6875\n",
      "Final accumulative portfolio value: 0.8479826875\n",
      "Maximum DrawDown: -0.6017298856223405\n",
      "Sharpe ratio: 0.03756246568636948\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 920          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -207         |\n",
      "|    explained_variance | -11.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13099        |\n",
      "|    policy_loss        | -2.9         |\n",
      "|    reward             | -0.019489877 |\n",
      "|    std                | 701          |\n",
      "|    value_loss         | 0.000269     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 949          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -208         |\n",
      "|    explained_variance | -0.52        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 1.18         |\n",
      "|    reward             | -0.023752922 |\n",
      "|    std                | 723          |\n",
      "|    value_loss         | 4.53e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | -40.1      |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 977        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -209       |\n",
      "|    explained_variance | -1.81      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 0.872      |\n",
      "|    reward             | -0.0140609 |\n",
      "|    std                | 751        |\n",
      "|    value_loss         | 2.49e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 1006         |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -210         |\n",
      "|    explained_variance | -10.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | -0.469       |\n",
      "|    reward             | -0.011208414 |\n",
      "|    std                | 788          |\n",
      "|    value_loss         | 1.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 1036         |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -212         |\n",
      "|    explained_variance | -1.76        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 2.52         |\n",
      "|    reward             | -0.013368604 |\n",
      "|    std                | 830          |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 1068          |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -213          |\n",
      "|    explained_variance | -13.8         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13599         |\n",
      "|    policy_loss        | -0.13         |\n",
      "|    reward             | -0.0067745196 |\n",
      "|    std                | 875           |\n",
      "|    value_loss         | 3.01e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 1101          |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -215          |\n",
      "|    explained_variance | 0.682         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | 0.841         |\n",
      "|    reward             | -0.0033047227 |\n",
      "|    std                | 930           |\n",
      "|    value_loss         | 1.58e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -40.1        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 1134         |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -216         |\n",
      "|    explained_variance | -5.37        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | 0.0174       |\n",
      "|    reward             | -0.002070894 |\n",
      "|    std                | 993          |\n",
      "|    value_loss         | 1.72e-07     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 1165          |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -218          |\n",
      "|    explained_variance | -72.8         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | 0.101         |\n",
      "|    reward             | -0.0025471703 |\n",
      "|    std                | 1.06e+03      |\n",
      "|    value_loss         | 1.08e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -40.1         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 1197          |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -220          |\n",
      "|    explained_variance | -4.74         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13999         |\n",
      "|    policy_loss        | 0.171         |\n",
      "|    reward             | -0.0006999035 |\n",
      "|    std                | 1.14e+03      |\n",
      "|    value_loss         | 1.58e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 736920.5625\n",
      "Final accumulative portfolio value: 0.7369205625\n",
      "Maximum DrawDown: -0.6479236585024156\n",
      "Sharpe ratio: -0.0018596783704441645\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 1234         |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -221         |\n",
      "|    explained_variance | -44.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | 5.56         |\n",
      "|    reward             | -0.018596733 |\n",
      "|    std                | 1.19e+03     |\n",
      "|    value_loss         | 0.000671     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 1267         |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -222         |\n",
      "|    explained_variance | -0.513       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | 6.57         |\n",
      "|    reward             | -0.022653406 |\n",
      "|    std                | 1.22e+03     |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 1298         |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -223         |\n",
      "|    explained_variance | -32.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 0.29         |\n",
      "|    reward             | -0.014507732 |\n",
      "|    std                | 1.27e+03     |\n",
      "|    value_loss         | 8.03e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 1329         |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -224         |\n",
      "|    explained_variance | -26.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 0.733        |\n",
      "|    reward             | -0.009663189 |\n",
      "|    std                | 1.34e+03     |\n",
      "|    value_loss         | 1.58e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 1361         |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -225         |\n",
      "|    explained_variance | -2.16        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | -0.415       |\n",
      "|    reward             | -0.014658012 |\n",
      "|    std                | 1.41e+03     |\n",
      "|    value_loss         | 4.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 1392         |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -227         |\n",
      "|    explained_variance | -2.48        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | -0.259       |\n",
      "|    reward             | -0.005205838 |\n",
      "|    std                | 1.48e+03     |\n",
      "|    value_loss         | 2.81e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -46.5         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 1420          |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -228          |\n",
      "|    explained_variance | -5.78         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14699         |\n",
      "|    policy_loss        | -0.209        |\n",
      "|    reward             | -0.0007023107 |\n",
      "|    std                | 1.56e+03      |\n",
      "|    value_loss         | 8.91e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 1448         |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -230         |\n",
      "|    explained_variance | -1.4         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14799        |\n",
      "|    policy_loss        | 0.364        |\n",
      "|    reward             | 0.0012863197 |\n",
      "|    std                | 1.67e+03     |\n",
      "|    value_loss         | 3.01e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 1476         |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -231         |\n",
      "|    explained_variance | -36          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | 0.0593       |\n",
      "|    reward             | 0.0007129167 |\n",
      "|    std                | 1.78e+03     |\n",
      "|    value_loss         | 7.51e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -46.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 1507         |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -233         |\n",
      "|    explained_variance | -28.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14999        |\n",
      "|    policy_loss        | -0.106       |\n",
      "|    reward             | 0.0014778494 |\n",
      "|    std                | 1.91e+03     |\n",
      "|    value_loss         | 4.71e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 860464.6875\n",
      "Final accumulative portfolio value: 0.8604646875\n",
      "Maximum DrawDown: -0.620061311227746\n",
      "Sharpe ratio: 0.04158108522875743\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 1543         |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -234         |\n",
      "|    explained_variance | -0.34        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | 10.1         |\n",
      "|    reward             | -0.014218657 |\n",
      "|    std                | 1.98e+03     |\n",
      "|    value_loss         | 0.00216      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -48.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 1571        |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -235        |\n",
      "|    explained_variance | 0.0667      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | 3.8         |\n",
      "|    reward             | -0.03102442 |\n",
      "|    std                | 2.05e+03    |\n",
      "|    value_loss         | 0.000322    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -48.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1601        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -236        |\n",
      "|    explained_variance | -2.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | -0.01530923 |\n",
      "|    std                | 2.13e+03    |\n",
      "|    value_loss         | 6.81e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 1631          |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -237          |\n",
      "|    explained_variance | 0.456         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15399         |\n",
      "|    policy_loss        | 1.12          |\n",
      "|    reward             | -0.0085999165 |\n",
      "|    std                | 2.24e+03      |\n",
      "|    value_loss         | 2.33e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 1659         |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -239         |\n",
      "|    explained_variance | -3.74        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | 5.83         |\n",
      "|    reward             | -0.015479706 |\n",
      "|    std                | 2.36e+03     |\n",
      "|    value_loss         | 0.000637     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 1688         |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -240         |\n",
      "|    explained_variance | -5.93e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | -0.142       |\n",
      "|    reward             | -0.004731146 |\n",
      "|    std                | 2.48e+03     |\n",
      "|    value_loss         | 7.7e-06      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 1718          |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -242          |\n",
      "|    explained_variance | -3.97         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15699         |\n",
      "|    policy_loss        | 1.3           |\n",
      "|    reward             | -0.0022146537 |\n",
      "|    std                | 2.63e+03      |\n",
      "|    value_loss         | 3.14e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -48.2          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 5800           |\n",
      "|    time_elapsed       | 1747           |\n",
      "|    total_timesteps    | 29000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -243           |\n",
      "|    explained_variance | -104           |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15799          |\n",
      "|    policy_loss        | -0.0173        |\n",
      "|    reward             | -0.00023488149 |\n",
      "|    std                | 2.81e+03       |\n",
      "|    value_loss         | 1.32e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 1776          |\n",
      "|    total_timesteps    | 29500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -245          |\n",
      "|    explained_variance | -4.89         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15899         |\n",
      "|    policy_loss        | -0.0966       |\n",
      "|    reward             | -0.0011978337 |\n",
      "|    std                | 3.01e+03      |\n",
      "|    value_loss         | 2.52e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 1805          |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -247          |\n",
      "|    explained_variance | -260          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15999         |\n",
      "|    policy_loss        | 0.32          |\n",
      "|    reward             | 0.00096293306 |\n",
      "|    std                | 3.22e+03      |\n",
      "|    value_loss         | 3.91e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 821086.5625\n",
      "Final accumulative portfolio value: 0.8210865625\n",
      "Maximum DrawDown: -0.6296920431971891\n",
      "Sharpe ratio: 0.029333430051055417\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 1838         |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -248         |\n",
      "|    explained_variance | -0.513       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | -12.9        |\n",
      "|    reward             | -0.039256033 |\n",
      "|    std                | 3.35e+03     |\n",
      "|    value_loss         | 0.00434      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -50.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1867        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -249        |\n",
      "|    explained_variance | -1.27       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16199       |\n",
      "|    policy_loss        | 2.94        |\n",
      "|    reward             | -0.03204327 |\n",
      "|    std                | 3.44e+03    |\n",
      "|    value_loss         | 0.000248    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 1896         |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -249         |\n",
      "|    explained_variance | -731         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | -0.765       |\n",
      "|    reward             | -0.013607749 |\n",
      "|    std                | 3.56e+03     |\n",
      "|    value_loss         | 2.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 1925         |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -251         |\n",
      "|    explained_variance | -1.51        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16399        |\n",
      "|    policy_loss        | -1.15        |\n",
      "|    reward             | -0.010463331 |\n",
      "|    std                | 3.73e+03     |\n",
      "|    value_loss         | 2.85e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 1954         |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -252         |\n",
      "|    explained_variance | -3.08        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | -0.856       |\n",
      "|    reward             | -0.019428179 |\n",
      "|    std                | 3.93e+03     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 1983          |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -253          |\n",
      "|    explained_variance | -109          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16599         |\n",
      "|    policy_loss        | -0.166        |\n",
      "|    reward             | -0.0030660448 |\n",
      "|    std                | 4.12e+03      |\n",
      "|    value_loss         | 9.84e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 2012          |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -255          |\n",
      "|    explained_variance | -15.1         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16699         |\n",
      "|    policy_loss        | 0.446         |\n",
      "|    reward             | -0.0003058234 |\n",
      "|    std                | 4.36e+03      |\n",
      "|    value_loss         | 4.24e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 2042         |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -256         |\n",
      "|    explained_variance | -3.76        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | 0.479        |\n",
      "|    reward             | 0.0022840244 |\n",
      "|    std                | 4.64e+03     |\n",
      "|    value_loss         | 5.82e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 2071         |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -258         |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.226        |\n",
      "|    reward             | 0.0012447975 |\n",
      "|    std                | 4.96e+03     |\n",
      "|    value_loss         | 1.1e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 2100         |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -260         |\n",
      "|    explained_variance | -6.01        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | 0.0019860722 |\n",
      "|    std                | 5.31e+03     |\n",
      "|    value_loss         | 7.57e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 854110.8125\n",
      "Final accumulative portfolio value: 0.8541108125\n",
      "Maximum DrawDown: -0.6165547784102139\n",
      "Sharpe ratio: 0.03987479626925372\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.4         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 2132          |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -261          |\n",
      "|    explained_variance | -10.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.833         |\n",
      "|    reward             | -0.0051180916 |\n",
      "|    std                | 5.57e+03      |\n",
      "|    value_loss         | 0.000231      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 2161         |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -262         |\n",
      "|    explained_variance | -1.23        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | -3.51        |\n",
      "|    reward             | -0.032600243 |\n",
      "|    std                | 5.75e+03     |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 2191         |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -263         |\n",
      "|    explained_variance | -30.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17299        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | -0.009282052 |\n",
      "|    std                | 5.97e+03     |\n",
      "|    value_loss         | 2.69e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 2220         |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -264         |\n",
      "|    explained_variance | -28.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17399        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | -0.006482267 |\n",
      "|    std                | 6.26e+03     |\n",
      "|    value_loss         | 2.68e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 2249         |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -266         |\n",
      "|    explained_variance | -165         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | -7.17        |\n",
      "|    reward             | -0.017163364 |\n",
      "|    std                | 6.63e+03     |\n",
      "|    value_loss         | 0.000893     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.4         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 2278          |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -267          |\n",
      "|    explained_variance | -2.73         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17599         |\n",
      "|    policy_loss        | 1.7           |\n",
      "|    reward             | -0.0030486255 |\n",
      "|    std                | 6.97e+03      |\n",
      "|    value_loss         | 4.48e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -50.4         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 2308          |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -268          |\n",
      "|    explained_variance | -1.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17699         |\n",
      "|    policy_loss        | -0.0314       |\n",
      "|    reward             | -0.0015744305 |\n",
      "|    std                | 7.38e+03      |\n",
      "|    value_loss         | 1.01e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -50.4       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2338        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -270        |\n",
      "|    explained_variance | -21.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | -0.328      |\n",
      "|    reward             | 0.002438087 |\n",
      "|    std                | 7.88e+03    |\n",
      "|    value_loss         | 5.49e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 2367         |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -272         |\n",
      "|    explained_variance | -5.54        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | 0.135        |\n",
      "|    reward             | 0.0014227434 |\n",
      "|    std                | 8.43e+03     |\n",
      "|    value_loss         | 5.38e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -50.4        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 2397         |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -274         |\n",
      "|    explained_variance | -43.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | 0.644        |\n",
      "|    reward             | 0.0013913721 |\n",
      "|    std                | 9.03e+03     |\n",
      "|    value_loss         | 2.88e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 862659.125\n",
      "Final accumulative portfolio value: 0.862659125\n",
      "Maximum DrawDown: -0.5912050382498306\n",
      "Sharpe ratio: 0.0434744698450963\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 2429         |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -275         |\n",
      "|    explained_variance | -19.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | 2.69         |\n",
      "|    reward             | -0.015966654 |\n",
      "|    std                | 9.47e+03     |\n",
      "|    value_loss         | 0.000363     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -48.6       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 2459        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -276        |\n",
      "|    explained_variance | -9.32       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | -4.1        |\n",
      "|    reward             | -0.03371258 |\n",
      "|    std                | 9.75e+03    |\n",
      "|    value_loss         | 0.000254    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 2488          |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -277          |\n",
      "|    explained_variance | -0.801        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18299         |\n",
      "|    policy_loss        | 1.16          |\n",
      "|    reward             | -0.0111296065 |\n",
      "|    std                | 1.01e+04      |\n",
      "|    value_loss         | 3.33e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 2518         |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -278         |\n",
      "|    explained_variance | -1.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 0.885        |\n",
      "|    reward             | -0.009047818 |\n",
      "|    std                | 1.06e+04     |\n",
      "|    value_loss         | 1.15e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 2547         |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -279         |\n",
      "|    explained_variance | -33.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | -3.93        |\n",
      "|    reward             | -0.017138714 |\n",
      "|    std                | 1.12e+04     |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 2577         |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -281         |\n",
      "|    explained_variance | -53.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18599        |\n",
      "|    policy_loss        | 0.794        |\n",
      "|    reward             | -0.006834019 |\n",
      "|    std                | 1.18e+04     |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 2610         |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -282         |\n",
      "|    explained_variance | -7.37        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | -0.005379802 |\n",
      "|    std                | 1.25e+04     |\n",
      "|    value_loss         | 2.55e-07     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | -48.6          |\n",
      "| time/                 |                |\n",
      "|    fps                | 16             |\n",
      "|    iterations         | 8800           |\n",
      "|    time_elapsed       | 2642           |\n",
      "|    total_timesteps    | 44000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -284           |\n",
      "|    explained_variance | -0.65          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18799          |\n",
      "|    policy_loss        | 0.25           |\n",
      "|    reward             | -0.00022802323 |\n",
      "|    std                | 1.34e+04       |\n",
      "|    value_loss         | 1.9e-06        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -48.6         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 2674          |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -286          |\n",
      "|    explained_variance | -33.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18899         |\n",
      "|    policy_loss        | -0.22         |\n",
      "|    reward             | -0.0013055475 |\n",
      "|    std                | 1.43e+04      |\n",
      "|    value_loss         | 2.65e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -48.6        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 2706         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -287         |\n",
      "|    explained_variance | -200         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | -1.2         |\n",
      "|    reward             | 0.0006126811 |\n",
      "|    std                | 1.54e+04     |\n",
      "|    value_loss         | 0.000173     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 846122.3125\n",
      "Final accumulative portfolio value: 0.8461223125\n",
      "Maximum DrawDown: -0.6294087276719278\n",
      "Sharpe ratio: 0.037551761754955726\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 2741         |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -289         |\n",
      "|    explained_variance | -0.839       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | -4.85        |\n",
      "|    reward             | -0.027921101 |\n",
      "|    std                | 1.61e+04     |\n",
      "|    value_loss         | 0.00031      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2772        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -289        |\n",
      "|    explained_variance | -1.98       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | 5.69        |\n",
      "|    reward             | -0.03652076 |\n",
      "|    std                | 1.66e+04    |\n",
      "|    value_loss         | 0.000472    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 2803        |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -290        |\n",
      "|    explained_variance | -19         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | 2.03        |\n",
      "|    reward             | -0.01652072 |\n",
      "|    std                | 1.72e+04    |\n",
      "|    value_loss         | 5.4e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | -49.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2835        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -292        |\n",
      "|    explained_variance | -0.0729     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | 0.563       |\n",
      "|    reward             | -0.01241768 |\n",
      "|    std                | 1.8e+04     |\n",
      "|    value_loss         | 6.06e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 2865         |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -293         |\n",
      "|    explained_variance | -399         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | 26.5         |\n",
      "|    reward             | -0.019192195 |\n",
      "|    std                | 1.9e+04      |\n",
      "|    value_loss         | 0.0169       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | -49.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 2894         |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -294         |\n",
      "|    explained_variance | -2.51        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | 0.865        |\n",
      "|    reward             | -0.008324871 |\n",
      "|    std                | 1.98e+04     |\n",
      "|    value_loss         | 1.06e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 2922          |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -296          |\n",
      "|    explained_variance | -44.9         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19699         |\n",
      "|    policy_loss        | -0.462        |\n",
      "|    reward             | -0.0048442194 |\n",
      "|    std                | 2.1e+04       |\n",
      "|    value_loss         | 6.64e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 2952          |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -297          |\n",
      "|    explained_variance | -3.7          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | -0.723        |\n",
      "|    reward             | -0.0019245533 |\n",
      "|    std                | 2.23e+04      |\n",
      "|    value_loss         | 8.02e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 2982          |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -299          |\n",
      "|    explained_variance | -3.75         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19899         |\n",
      "|    policy_loss        | -0.185        |\n",
      "|    reward             | -0.0026567858 |\n",
      "|    std                | 2.39e+04      |\n",
      "|    value_loss         | 4.63e-07      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | -49.2         |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 3011          |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -301          |\n",
      "|    explained_variance | -14.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19999         |\n",
      "|    policy_loss        | 0.316         |\n",
      "|    reward             | 2.5910995e-07 |\n",
      "|    std                | 2.56e+04      |\n",
      "|    value_loss         | 1.22e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1522705.0\n",
      "Final accumulative portfolio value: 1.522705\n",
      "Maximum DrawDown: -0.31822802710874387\n",
      "Sharpe ratio: 0.5520410353224033\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "recession_result_sharp = benchmark(train_data,test_data,50_000,1,['close','return'],INDICATORS,save=True,tag='sharpe_return_vector_log_return_reward_recession',reward_sharpe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_21\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 155          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 13           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0027556564 |\n",
      "-------------------------------------\n",
      "Logging to ./data/tb\\ppo_22\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 144         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 14          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.004125893 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1511941.75\n",
      "Final accumulative portfolio value: 1.51194175\n",
      "Maximum DrawDown: -0.3541803321307725\n",
      "Sharpe ratio: 0.5424682601197607\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_18\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 113           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.41         |\n",
      "|    explained_variance | -0.16         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | 0.0277        |\n",
      "|    reward             | -0.0024534138 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 6.84e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 115         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.51       |\n",
      "|    explained_variance | -0.0037     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0283     |\n",
      "|    reward             | 0.033314217 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000167    |\n",
      "---------------------------------------\n",
      "Logging to ./data/tb\\a2c_19\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 130           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.62         |\n",
      "|    explained_variance | -0.223        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 299           |\n",
      "|    policy_loss        | 0.0179        |\n",
      "|    reward             | -0.0017429274 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 7.75e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | -0.0217    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.0477    |\n",
      "|    reward             | 0.02173987 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.000529   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1519790.75\n",
      "Final accumulative portfolio value: 1.51979075\n",
      "Maximum DrawDown: -0.3483283845722652\n",
      "Sharpe ratio: 0.5539260171709461\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "recession_result_log_return = benchmark(train_data,test_data,1000,1,['close','return'],INDICATORS,save=True,tag='log_return_vector_log_return_reward_recession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:50000\n",
      "end_total_asset:59976.84123225947\n",
      "Sharpe:  1.0454785311812973\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.1995368246451894\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1108365.0361304719\n",
      "Sharpe:  0.47609094494754345\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.1083650361304718\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1108365.0361304719\n",
      "Sharpe:  0.47609094494754345\n",
      "=================================\n",
      "Test Finished!\n",
      "episode_return 1.1083650361304718\n"
     ]
    }
   ],
   "source": [
    "from utils import baseline\n",
    "\n",
    "\n",
    "mvo = baseline(processed,INDICATORS,TEST_START_DATE,TEST_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 22           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 90           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.007429121 |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 22            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 183           |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006466236   |\n",
      "|    clip_fraction        | 0.0116        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.26         |\n",
      "|    explained_variance   | -0.00169      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00136      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00273      |\n",
      "|    reward               | -0.0044805584 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.0907        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 443506.0625\n",
      "Final accumulative portfolio value: 0.4435060625\n",
      "Maximum DrawDown: -0.6968805149738166\n",
      "Sharpe ratio: -0.0883522450113362\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -35.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 22           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024910974 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | -0.0173      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0547      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 0.010890644  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00492      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -35.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 373          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054013995 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | 0.00217      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0682       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.0030117112 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 736953.375\n",
      "Final accumulative portfolio value: 0.736953375\n",
      "Maximum DrawDown: -0.6917632758734278\n",
      "Sharpe ratio: 0.036266596775947256\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | 5.05         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 469          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032581256 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.0431      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0371      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | -0.009628576 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.00534      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | 5.05         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 560          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056158905 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.0755       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0161      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -0.009645939 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00765      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | 5.05          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 652           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004164391   |\n",
      "|    clip_fraction        | 0.0124        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.26         |\n",
      "|    explained_variance   | -0.0131       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00229       |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00225      |\n",
      "|    reward               | -0.0032408505 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.112         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 400056.53125\n",
      "Final accumulative portfolio value: 0.40005653125\n",
      "Maximum DrawDown: -0.7153506857147289\n",
      "Sharpe ratio: -0.11691024876087426\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -15.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024965038 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.0156      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0288      |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 0.0044760713 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0101       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -15.8         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 839           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069839205 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.28         |\n",
      "|    explained_variance   | 0.00179       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.219         |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -9.76e-05     |\n",
      "|    reward               | -0.0073133414 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.413         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 393714.96875\n",
      "Final accumulative portfolio value: 0.39371496875\n",
      "Maximum DrawDown: -0.7619359837951342\n",
      "Sharpe ratio: -0.11650192178796581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -11          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036886383 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | -0.014       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.045       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | -0.21763211  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00642      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -11          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1025         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035031666 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | 0.0485       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0479      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | -0.021933971 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0119       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -11          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005612689  |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.28        |\n",
      "|    explained_variance   | -0.00378     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00128      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | -0.010995028 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0731       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 268126.125\n",
      "Final accumulative portfolio value: 0.268126125\n",
      "Maximum DrawDown: -0.8025780696360976\n",
      "Sharpe ratio: -0.19095963060072452\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1212         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036763335 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | -0.0327      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0352      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | 0.0072721    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0135       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1306         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062674223 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | 0.00506      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0435       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 0.0026024769 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.178        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 566775.3125\n",
      "Final accumulative portfolio value: 0.5667753125\n",
      "Maximum DrawDown: -0.6204527136736875\n",
      "Sharpe ratio: -0.020024240029738207\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -17.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1399         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029922817 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | -0.0654      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0417      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    reward               | -0.1412599   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00537      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -17.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1494         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00575456   |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00536      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -0.012028055 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0525       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -17.3         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 1590          |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004983962   |\n",
      "|    clip_fraction        | 0.0213        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.31         |\n",
      "|    explained_variance   | -0.00122      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00171      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | -0.0059065567 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.0769        |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 373611.25\n",
      "Final accumulative portfolio value: 0.37361125\n",
      "Maximum DrawDown: -0.7298525753517229\n",
      "Sharpe ratio: -0.12819759751695967\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -22.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1690         |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019994867 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | -0.0382      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0411      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | -0.006496673 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00762      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -22.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1785         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005546988  |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.29        |\n",
      "|    explained_variance   | 0.00419      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0475       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | -0.001785764 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.181        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 346274.1875\n",
      "Final accumulative portfolio value: 0.3462741875\n",
      "Maximum DrawDown: -0.7713561686811568\n",
      "Sharpe ratio: -0.13821742142184443\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -22.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1880         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042220354 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.0291      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0384      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -0.16028337  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00731      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -22.8         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 1971          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008013004   |\n",
      "|    clip_fraction        | 0.0642        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.26         |\n",
      "|    explained_variance   | 0.0226        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0414        |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.00418      |\n",
      "|    reward               | -0.0014668768 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.129         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -22.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2062         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072191674 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.0198      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.0006880118 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0915       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 697529.375\n",
      "Final accumulative portfolio value: 0.697529375\n",
      "Maximum DrawDown: -0.6709510910727349\n",
      "Sharpe ratio: 0.02128518215772152\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -21.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2158         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004114295  |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | -0.0459      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0541      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -0.028958285 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.00762      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -21.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2252         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013969319 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.3         |\n",
      "|    explained_variance   | 0.00449      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0337       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -0.010341078 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.177        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 357810.0\n",
      "Final accumulative portfolio value: 0.35781\n",
      "Maximum DrawDown: -0.7763883750892591\n",
      "Sharpe ratio: -0.13465882537835971\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -28.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2350         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026685025 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.34        |\n",
      "|    explained_variance   | -0.0271      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.044       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 0.12338363   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0161       |\n",
      "------------------------------------------\n",
      "Logging to ./data/tb\\ppo_24\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 22           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 92           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.018751986 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003343018  |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.36        |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00638     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    reward               | -0.014035783 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0969       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 190406.671875\n",
      "Final accumulative portfolio value: 0.190406671875\n",
      "Maximum DrawDown: -0.8554694743643134\n",
      "Sharpe ratio: -0.2533190536210872\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -95.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 284           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0043183276  |\n",
      "|    clip_fraction        | 0.0216        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.36         |\n",
      "|    explained_variance   | -0.172        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0405       |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | -0.0062700645 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.00543       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -95.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 376           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0064722532  |\n",
      "|    clip_fraction        | 0.0561        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.37         |\n",
      "|    explained_variance   | -0.000663     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.324         |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00432      |\n",
      "|    reward               | -0.0066006137 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.643         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 490269.1875\n",
      "Final accumulative portfolio value: 0.4902691875\n",
      "Maximum DrawDown: -0.8030990010036083\n",
      "Sharpe ratio: -0.05735995436341605\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -52.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 474          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031057775 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | -0.0925      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0537      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000901    |\n",
      "|    reward               | 0.015940893  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00628      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -52.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 566           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0046754153  |\n",
      "|    clip_fraction        | 0.032         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.39         |\n",
      "|    explained_variance   | 0.0789        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0406       |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.00357      |\n",
      "|    reward               | -0.0066679586 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00777       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -52.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 657          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010974186 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | -0.00845     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00596     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000456    |\n",
      "|    reward               | -0.004639618 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0691       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 522365.75\n",
      "Final accumulative portfolio value: 0.52236575\n",
      "Maximum DrawDown: -0.7255829375577465\n",
      "Sharpe ratio: -0.043768526407551106\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -48           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 758           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.003374778   |\n",
      "|    clip_fraction        | 0.0188        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.4          |\n",
      "|    explained_variance   | -0.0427       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0446       |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | -0.0066444464 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00739       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -48          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 849          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005393407  |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.00497      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00139     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -0.005042616 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0942       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 397309.125\n",
      "Final accumulative portfolio value: 0.397309125\n",
      "Maximum DrawDown: -0.738009394383506\n",
      "Sharpe ratio: -0.08782097503992536\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -42.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 944          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047878623 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | -0.0632      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0499      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -0.04731792  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0031       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -42.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1041         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039945953 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.0529       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0299      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | -0.02213627  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.011        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -42.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1138         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004086342  |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | -0.00489     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00124      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | -0.016880516 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.119        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 168614.46875\n",
      "Final accumulative portfolio value: 0.16861446875\n",
      "Maximum DrawDown: -0.8721371220695767\n",
      "Sharpe ratio: -0.28338479028810365\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -56.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1235         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038212663 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | -0.0386      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0436      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | 0.0031302704 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00952      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -56.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1325         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023013726 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.00351      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.149        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000549    |\n",
      "|    reward               | 0.003347993  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.361        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 646315.625\n",
      "Final accumulative portfolio value: 0.646315625\n",
      "Maximum DrawDown: -0.6965845927266738\n",
      "Sharpe ratio: 0.016747930821670115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12e+03    |\n",
      "|    ep_rew_mean          | -42.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004135479 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | -0.0782     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0481     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | 0.17809731  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -42.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 1515          |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0017788585  |\n",
      "|    clip_fraction        | 0.0042        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.41         |\n",
      "|    explained_variance   | 0.0437        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0383       |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | -0.0064660353 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.0104        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -42.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 1610         |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024643347 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.000302     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0692       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    reward               | -0.006633067 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.321        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 343043.125\n",
      "Final accumulative portfolio value: 0.343043125\n",
      "Maximum DrawDown: -0.7759046822432284\n",
      "Sharpe ratio: -0.13239064253639535\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -40.2         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 1702          |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0021881105  |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.41         |\n",
      "|    explained_variance   | -0.0322       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0347       |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000748     |\n",
      "|    reward               | -0.0018971609 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.00549       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -40.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1792         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031189625 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.00406      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0221      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.00485884  |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.0721       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 326963.75\n",
      "Final accumulative portfolio value: 0.32696375\n",
      "Maximum DrawDown: -0.7540910495839803\n",
      "Sharpe ratio: -0.10376629279397266\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.12e+03   |\n",
      "|    ep_rew_mean          | -40        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 1886       |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00491871 |\n",
      "|    clip_fraction        | 0.0285     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.43      |\n",
      "|    explained_variance   | -0.041     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0428    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00238   |\n",
      "|    reward               | 0.04270763 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.00331    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12e+03    |\n",
      "|    ep_rew_mean          | -40         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1976        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006107153 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.043       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0469     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | -0.01666104 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0104      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -40          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2066         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053836014 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | -0.00631     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0214      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -0.0093074   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0537       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 309764.40625\n",
      "Final accumulative portfolio value: 0.30976440625\n",
      "Maximum DrawDown: -0.8113052987860949\n",
      "Sharpe ratio: -0.14546861815456263\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.12e+03     |\n",
      "|    ep_rew_mean          | -45.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 21           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2159         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038114483 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | -0.0192      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0413      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.004882819 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.0123       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.12e+03      |\n",
      "|    ep_rew_mean          | -45.6         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 2249          |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0039249077  |\n",
      "|    clip_fraction        | 0.0246        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.43         |\n",
      "|    explained_variance   | 0.0002        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.358         |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | -0.0062665464 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.562         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 294693.6875\n",
      "Final accumulative portfolio value: 0.2946936875\n",
      "Maximum DrawDown: -0.8300443431301673\n",
      "Sharpe ratio: -0.14230440168810776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12e+03    |\n",
      "|    ep_rew_mean          | -42.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2342        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004062578 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | -0.0618     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0522     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    reward               | 0.17357515  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00375     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1555427.75\n",
      "Final accumulative portfolio value: 1.55542775\n",
      "Maximum DrawDown: -0.35821112499999996\n",
      "Sharpe ratio: 0.564482342830419\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_20\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 22           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.3         |\n",
      "|    explained_variance | -0.159       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.312       |\n",
      "|    reward             | -0.024810482 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.00976      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 22           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.34        |\n",
      "|    explained_variance | -9.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.0413      |\n",
      "|    reward             | -0.020997357 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 22           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.39        |\n",
      "|    explained_variance | -27.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.0158       |\n",
      "|    reward             | -0.021393644 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 4.1e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 91           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.47        |\n",
      "|    explained_variance | -48.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.00372     |\n",
      "|    reward             | -0.018153377 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 6.3e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.57        |\n",
      "|    explained_variance | 0.101        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.0118       |\n",
      "|    reward             | -0.013444567 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 2.18e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.72        |\n",
      "|    explained_variance | -1.84        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.0521      |\n",
      "|    reward             | -0.007801948 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.000149     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 21            |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.89         |\n",
      "|    explained_variance | 0.119         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.00858       |\n",
      "|    reward             | -0.0060929838 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 4.75e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.08        |\n",
      "|    explained_variance | 0.00241      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.0185      |\n",
      "|    reward             | -0.009188922 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 1.57e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 21            |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 204           |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.28         |\n",
      "|    explained_variance | -1.62         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.00628      |\n",
      "|    reward             | -0.0092724105 |\n",
      "|    std                | 1.41          |\n",
      "|    value_loss         | 1.75e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.49        |\n",
      "|    explained_variance | 0.171        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.00222      |\n",
      "|    reward             | -0.013479387 |\n",
      "|    std                | 1.51         |\n",
      "|    value_loss         | 1.99e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 275880.375\n",
      "Final accumulative portfolio value: 0.275880375\n",
      "Maximum DrawDown: -0.8398193505827738\n",
      "Sharpe ratio: -0.19163170817044997\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.6         |\n",
      "|    explained_variance | 0.00332      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.527       |\n",
      "|    reward             | -0.052855913 |\n",
      "|    std                | 1.56         |\n",
      "|    value_loss         | 0.0132       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.64        |\n",
      "|    explained_variance | -0.184       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0707       |\n",
      "|    reward             | -0.047191434 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 0.000173     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -50.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 0.0036      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.00518    |\n",
      "|    reward             | -0.03752168 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 1.58e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 320          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.84        |\n",
      "|    explained_variance | -3.53        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.0115      |\n",
      "|    reward             | -0.033967707 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 5.53e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.99        |\n",
      "|    explained_variance | 0.447        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.0132       |\n",
      "|    reward             | -0.031781405 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 6.48e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -50.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.17       |\n",
      "|    explained_variance | -0.552      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | -0.01891908 |\n",
      "|    std                | 1.89        |\n",
      "|    value_loss         | 8.07e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 388          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.36        |\n",
      "|    explained_variance | -0.362       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.00823     |\n",
      "|    reward             | -0.018623043 |\n",
      "|    std                | 2.02         |\n",
      "|    value_loss         | 1.48e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -50.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.57       |\n",
      "|    explained_variance | -39.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.00535     |\n",
      "|    reward             | -0.01821304 |\n",
      "|    std                | 2.16        |\n",
      "|    value_loss         | 9.3e-07     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -50.2       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 434         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.77       |\n",
      "|    explained_variance | -7.26       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0119     |\n",
      "|    reward             | -0.01983569 |\n",
      "|    std                | 2.32        |\n",
      "|    value_loss         | 4.54e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -50.2        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 457          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.98        |\n",
      "|    explained_variance | -1.8         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 1.66e-05     |\n",
      "|    reward             | -0.023317255 |\n",
      "|    std                | 2.48         |\n",
      "|    value_loss         | 2.38e-08     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 103497.546875\n",
      "Final accumulative portfolio value: 0.103497546875\n",
      "Maximum DrawDown: -0.9202919060277704\n",
      "Sharpe ratio: -0.36578947297871106\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -93.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | -105        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 0.117       |\n",
      "|    reward             | -0.10187575 |\n",
      "|    std                | 2.59        |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -93.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 505         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.19       |\n",
      "|    explained_variance | -2.12       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.0188     |\n",
      "|    reward             | -0.05866505 |\n",
      "|    std                | 2.66        |\n",
      "|    value_loss         | 8.29e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -93.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 528          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.3         |\n",
      "|    explained_variance | -1.94        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -0.0357      |\n",
      "|    reward             | -0.041290928 |\n",
      "|    std                | 2.76         |\n",
      "|    value_loss         | 3.35e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -93.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 552         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.44       |\n",
      "|    explained_variance | 0.556       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.021       |\n",
      "|    reward             | -0.03533592 |\n",
      "|    std                | 2.89        |\n",
      "|    value_loss         | 7.86e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -93.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.62       |\n",
      "|    explained_variance | 0.0188      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 0.0118      |\n",
      "|    reward             | -0.04014933 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 4.83e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -93.5       |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 598         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.8        |\n",
      "|    explained_variance | -0.00735    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 0.0255      |\n",
      "|    reward             | -0.02776996 |\n",
      "|    std                | 3.27        |\n",
      "|    value_loss         | 1.19e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -93.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 621          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8           |\n",
      "|    explained_variance | -0.991       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.0076      |\n",
      "|    reward             | -0.032552365 |\n",
      "|    std                | 3.49         |\n",
      "|    value_loss         | 9.36e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -93.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 644          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.21        |\n",
      "|    explained_variance | -0.43        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.00925      |\n",
      "|    reward             | -0.028031101 |\n",
      "|    std                | 3.74         |\n",
      "|    value_loss         | 1.79e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -93.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 667          |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.42        |\n",
      "|    explained_variance | -35.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.00137      |\n",
      "|    reward             | -0.026694573 |\n",
      "|    std                | 4            |\n",
      "|    value_loss         | 1.12e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -93.5        |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 690          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.62        |\n",
      "|    explained_variance | 0.181        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | -0.0177      |\n",
      "|    reward             | -0.028378181 |\n",
      "|    std                | 4.29         |\n",
      "|    value_loss         | 4.35e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 63823.6484375\n",
      "Final accumulative portfolio value: 0.0638236484375\n",
      "Maximum DrawDown: -0.945568125\n",
      "Sharpe ratio: -0.46695367209248606\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 717          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.79        |\n",
      "|    explained_variance | 0.314        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.593        |\n",
      "|    reward             | 0.0058337604 |\n",
      "|    std                | 4.53         |\n",
      "|    value_loss         | 0.0053       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 740          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.86        |\n",
      "|    explained_variance | 0.554        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | -0.022691533 |\n",
      "|    std                | 4.65         |\n",
      "|    value_loss         | 0.000844     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -130        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 763         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.95       |\n",
      "|    explained_variance | -0.495      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.0817     |\n",
      "|    reward             | -0.02428361 |\n",
      "|    std                | 4.78        |\n",
      "|    value_loss         | 0.00012     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 787          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.07        |\n",
      "|    explained_variance | -35.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.0221      |\n",
      "|    reward             | -0.023347275 |\n",
      "|    std                | 4.98         |\n",
      "|    value_loss         | 5.97e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 809          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.22        |\n",
      "|    explained_variance | -0.408       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -0.00182     |\n",
      "|    reward             | -0.026835896 |\n",
      "|    std                | 5.24         |\n",
      "|    value_loss         | 1.58e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 833          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.4         |\n",
      "|    explained_variance | 0.296        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.0302       |\n",
      "|    reward             | -0.020086274 |\n",
      "|    std                | 5.56         |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 856          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.59        |\n",
      "|    explained_variance | -1.07        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.00449      |\n",
      "|    reward             | -0.013929075 |\n",
      "|    std                | 5.92         |\n",
      "|    value_loss         | 9.27e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 879          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.79        |\n",
      "|    explained_variance | -0.233       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.018       |\n",
      "|    reward             | -0.016629787 |\n",
      "|    std                | 6.33         |\n",
      "|    value_loss         | 3.8e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 902          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10          |\n",
      "|    explained_variance | 0.0196       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.0235       |\n",
      "|    reward             | -0.018928869 |\n",
      "|    std                | 6.78         |\n",
      "|    value_loss         | 5.12e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 925          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | -1.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.00637     |\n",
      "|    reward             | -0.020266682 |\n",
      "|    std                | 7.27         |\n",
      "|    value_loss         | 4.54e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 112903.3515625\n",
      "Final accumulative portfolio value: 0.1129033515625\n",
      "Maximum DrawDown: -0.9087643998969921\n",
      "Sharpe ratio: -0.3743527962050061\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.12e+03   |\n",
      "|    ep_rew_mean        | -122       |\n",
      "| time/                 |            |\n",
      "|    fps                | 21         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 951        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | 0.00616    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 5.7        |\n",
      "|    reward             | 0.21282288 |\n",
      "|    std                | 7.76       |\n",
      "|    value_loss         | 0.364      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.12e+03      |\n",
      "|    ep_rew_mean        | -122          |\n",
      "| time/                 |               |\n",
      "|    fps                | 21            |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 974           |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | -3.53         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -0.0859       |\n",
      "|    reward             | -0.0016039141 |\n",
      "|    std                | 7.83          |\n",
      "|    value_loss         | 0.000118      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.12e+03      |\n",
      "|    ep_rew_mean        | -122          |\n",
      "| time/                 |               |\n",
      "|    fps                | 21            |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 998           |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.5         |\n",
      "|    explained_variance | 0.0585        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | 0.0513        |\n",
      "|    reward             | -0.0083351005 |\n",
      "|    std                | 8.02          |\n",
      "|    value_loss         | 3.7e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 1020         |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.0124       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.00181      |\n",
      "|    reward             | -0.014977425 |\n",
      "|    std                | 8.32         |\n",
      "|    value_loss         | 2.72e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 1044         |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | -1.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | -0.0225      |\n",
      "|    reward             | -0.016431672 |\n",
      "|    std                | 8.75         |\n",
      "|    value_loss         | 5.97e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 1067         |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | -6.29        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.0127       |\n",
      "|    reward             | -0.025975505 |\n",
      "|    std                | 9.27         |\n",
      "|    value_loss         | 2.4e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 1090         |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.559        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.00238     |\n",
      "|    reward             | -0.022913935 |\n",
      "|    std                | 9.88         |\n",
      "|    value_loss         | 3.65e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 1113         |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | -0.189       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.00968      |\n",
      "|    reward             | -0.022360565 |\n",
      "|    std                | 10.6         |\n",
      "|    value_loss         | 9.55e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 1137         |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0.0321       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.0196      |\n",
      "|    reward             | -0.027618477 |\n",
      "|    std                | 11.3         |\n",
      "|    value_loss         | 3.55e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 1160         |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | -0.109       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.0214       |\n",
      "|    reward             | -0.027673593 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 4.61e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -122         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 1183         |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.00851      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | -0.055       |\n",
      "|    reward             | -0.032285877 |\n",
      "|    std                | 13           |\n",
      "|    value_loss         | 2.76e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 41147.08203125\n",
      "Final accumulative portfolio value: 0.04114708203125\n",
      "Maximum DrawDown: -0.9719237717157831\n",
      "Sharpe ratio: -0.4960618500549767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 1210         |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | -0.723       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.457       |\n",
      "|    reward             | -0.054547753 |\n",
      "|    std                | 13.3         |\n",
      "|    value_loss         | 0.00179      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 1233         |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | -0.292       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.257        |\n",
      "|    reward             | -0.039281547 |\n",
      "|    std                | 13.7         |\n",
      "|    value_loss         | 0.000518     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -114        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.0914      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.0465      |\n",
      "|    reward             | -0.04174076 |\n",
      "|    std                | 14.2        |\n",
      "|    value_loss         | 1.8e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -114        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 1279        |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -0.441      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | 0.0718      |\n",
      "|    reward             | -0.03342049 |\n",
      "|    std                | 15          |\n",
      "|    value_loss         | 4.03e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -114        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1302        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | -0.0819     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | 0.00391     |\n",
      "|    reward             | -0.04309161 |\n",
      "|    std                | 15.9        |\n",
      "|    value_loss         | 5e-07       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 1325         |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0.00928      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | -0.0151      |\n",
      "|    reward             | -0.033989623 |\n",
      "|    std                | 16.9         |\n",
      "|    value_loss         | 1.92e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 1348         |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | 0.522        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.0122      |\n",
      "|    reward             | -0.029761704 |\n",
      "|    std                | 18.1         |\n",
      "|    value_loss         | 1.12e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 1372         |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -0.621       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.0044      |\n",
      "|    reward             | -0.020733872 |\n",
      "|    std                | 19.4         |\n",
      "|    value_loss         | 1.32e-07     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -114        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1395        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | -1.77       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.00377     |\n",
      "|    reward             | -0.02226825 |\n",
      "|    std                | 20.8        |\n",
      "|    value_loss         | 1.22e-07    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -114         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 1418         |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | -0.0902      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -0.0531      |\n",
      "|    reward             | -0.024752561 |\n",
      "|    std                | 22.3         |\n",
      "|    value_loss         | 1.83e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 92625.8046875\n",
      "Final accumulative portfolio value: 0.0926258046875\n",
      "Maximum DrawDown: -0.9241686796806838\n",
      "Sharpe ratio: -0.3968030191169857\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -124        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1445        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.106       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 0.435       |\n",
      "|    reward             | -0.05550426 |\n",
      "|    std                | 23.2        |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -124        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1468        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.075       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -0.272      |\n",
      "|    reward             | -0.03510132 |\n",
      "|    std                | 23.8        |\n",
      "|    value_loss         | 0.000496    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -124         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 1490         |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0.333        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.0244      |\n",
      "|    reward             | -0.020349452 |\n",
      "|    std                | 24.8         |\n",
      "|    value_loss         | 3.6e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -124         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 1513         |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | -0.359       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.0271      |\n",
      "|    reward             | -0.024357675 |\n",
      "|    std                | 26.1         |\n",
      "|    value_loss         | 4.19e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -124        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1536        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -2.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.546      |\n",
      "|    reward             | -0.03411623 |\n",
      "|    std                | 27.7        |\n",
      "|    value_loss         | 0.0016      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -124         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 1559         |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -0.0617      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.0657       |\n",
      "|    reward             | -0.020893225 |\n",
      "|    std                | 29.6         |\n",
      "|    value_loss         | 2.65e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -124        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 1582        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | -10.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.0142     |\n",
      "|    reward             | -0.02364711 |\n",
      "|    std                | 31.6        |\n",
      "|    value_loss         | 1.02e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -124        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 1606        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | -1.74       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.0148      |\n",
      "|    reward             | -0.02242189 |\n",
      "|    std                | 33.8        |\n",
      "|    value_loss         | 1.22e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -124         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 1629         |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.607        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.00733      |\n",
      "|    reward             | -0.022268642 |\n",
      "|    std                | 36.2         |\n",
      "|    value_loss         | 2.47e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -124         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 1653         |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | -0.332       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.00679      |\n",
      "|    reward             | -0.024733892 |\n",
      "|    std                | 38.9         |\n",
      "|    value_loss         | 2.85e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 91201.4375\n",
      "Final accumulative portfolio value: 0.0912014375\n",
      "Maximum DrawDown: -0.9227703550704748\n",
      "Sharpe ratio: -0.38592987315499583\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -126        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 1681        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | -4.69       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 0.142       |\n",
      "|    reward             | 0.037617467 |\n",
      "|    std                | 40.8        |\n",
      "|    value_loss         | 0.000597    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 1705         |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.0155       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.59        |\n",
      "|    reward             | -0.019126682 |\n",
      "|    std                | 41.8         |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 1728         |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -0.0166      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -0.109       |\n",
      "|    reward             | -0.020569742 |\n",
      "|    std                | 43.2         |\n",
      "|    value_loss         | 5.98e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 1751         |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.574        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -0.0867      |\n",
      "|    reward             | -0.030356407 |\n",
      "|    std                | 45           |\n",
      "|    value_loss         | 4.14e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -126        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 1774        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0.269       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | -0.0361     |\n",
      "|    reward             | -0.03737003 |\n",
      "|    std                | 47.5        |\n",
      "|    value_loss         | 6.75e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 1797         |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -0.00656     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.00225      |\n",
      "|    reward             | -0.030498838 |\n",
      "|    std                | 50.5         |\n",
      "|    value_loss         | 2.36e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 1820         |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0.0539       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | -0.035       |\n",
      "|    reward             | -0.027022718 |\n",
      "|    std                | 53.9         |\n",
      "|    value_loss         | 6.24e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 1843         |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -1.36        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.0045      |\n",
      "|    reward             | -0.023847042 |\n",
      "|    std                | 57.7         |\n",
      "|    value_loss         | 2.72e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 1867         |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | -0.903       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 0.0125       |\n",
      "|    reward             | -0.027228836 |\n",
      "|    std                | 61.8         |\n",
      "|    value_loss         | 9.1e-07      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 1890         |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | -0.669       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | -0.0587      |\n",
      "|    reward             | -0.027465882 |\n",
      "|    std                | 66.3         |\n",
      "|    value_loss         | 1.74e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 63062.1796875\n",
      "Final accumulative portfolio value: 0.0630621796875\n",
      "Maximum DrawDown: -0.9537709264855961\n",
      "Sharpe ratio: -0.5041235994295638\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.12e+03   |\n",
      "|    ep_rew_mean        | -126       |\n",
      "| time/                 |            |\n",
      "|    fps                | 21         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 1916       |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17        |\n",
      "|    explained_variance | -0.00352   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 3.21       |\n",
      "|    reward             | 0.08681663 |\n",
      "|    std                | 70.4       |\n",
      "|    value_loss         | 0.053      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 1939         |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0.00373      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.495        |\n",
      "|    reward             | -0.012623648 |\n",
      "|    std                | 71.8         |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 1962         |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -0.0791      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.0589       |\n",
      "|    reward             | -0.015411836 |\n",
      "|    std                | 73.8         |\n",
      "|    value_loss         | 1.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 1986         |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | -0.089       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | 0.0835       |\n",
      "|    reward             | -0.017067812 |\n",
      "|    std                | 76.8         |\n",
      "|    value_loss         | 2.33e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -126        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2009        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | -5.27       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 0.0214      |\n",
      "|    reward             | -0.01631034 |\n",
      "|    std                | 81          |\n",
      "|    value_loss         | 3.95e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 2032         |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | -0.503       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 0.00915      |\n",
      "|    reward             | -0.012135922 |\n",
      "|    std                | 86.1         |\n",
      "|    value_loss         | 5.63e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 2055         |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0.227        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.0559      |\n",
      "|    reward             | -0.011999065 |\n",
      "|    std                | 91.9         |\n",
      "|    value_loss         | 1.16e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -126        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2079        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.127       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 0.0198      |\n",
      "|    reward             | -0.01140198 |\n",
      "|    std                | 98.4        |\n",
      "|    value_loss         | 1.51e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 2103         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | -3.14        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | 0.022        |\n",
      "|    reward             | -0.013738946 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 2.4e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 2126         |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | -0.019       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.0158      |\n",
      "|    reward             | -0.015809566 |\n",
      "|    std                | 113          |\n",
      "|    value_loss         | 8.06e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -126         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 2150         |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | -13.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -0.0126      |\n",
      "|    reward             | -0.017549355 |\n",
      "|    std                | 121          |\n",
      "|    value_loss         | 5.64e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 182426.3125\n",
      "Final accumulative portfolio value: 0.1824263125\n",
      "Maximum DrawDown: -0.8729486288463009\n",
      "Sharpe ratio: -0.2743229059696138\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 2176         |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | -0.199       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.347       |\n",
      "|    reward             | -0.047152404 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 0.00359      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 2200         |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0.21         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.0996       |\n",
      "|    reward             | -0.017709365 |\n",
      "|    std                | 127          |\n",
      "|    value_loss         | 3.78e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 2223         |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0.0782       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 0.0682       |\n",
      "|    reward             | -0.023223307 |\n",
      "|    std                | 133          |\n",
      "|    value_loss         | 1.67e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 2246         |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0.0889       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.018        |\n",
      "|    reward             | -0.020266935 |\n",
      "|    std                | 140          |\n",
      "|    value_loss         | 1.81e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -120        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 2269        |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | -1.32       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -0.0261     |\n",
      "|    reward             | -0.03271624 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 3.32e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 2293         |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | -32.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.00411     |\n",
      "|    reward             | -0.018569678 |\n",
      "|    std                | 159          |\n",
      "|    value_loss         | 2.17e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 2316         |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -4.22        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.00825     |\n",
      "|    reward             | -0.022905251 |\n",
      "|    std                | 170          |\n",
      "|    value_loss         | 2.06e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -120         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 2340         |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0.0915       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -0.0532      |\n",
      "|    reward             | -0.021839708 |\n",
      "|    std                | 182          |\n",
      "|    value_loss         | 7.84e-06     |\n",
      "----------------------------------------\n",
      "Logging to ./data/tb\\a2c_21\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0.0927       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10099        |\n",
      "|    policy_loss        | 0.738        |\n",
      "|    reward             | -0.037584886 |\n",
      "|    std                | 188          |\n",
      "|    value_loss         | 0.00164      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -3.41        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | 0.0137       |\n",
      "|    reward             | -0.022557277 |\n",
      "|    std                | 195          |\n",
      "|    value_loss         | 2.6e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | -2.15       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | 0.0609      |\n",
      "|    reward             | -0.02012071 |\n",
      "|    std                | 206         |\n",
      "|    value_loss         | 1.01e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | -4.14        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | -0.0244      |\n",
      "|    reward             | -0.025733521 |\n",
      "|    std                | 218          |\n",
      "|    value_loss         | 3.08e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -10.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10499        |\n",
      "|    policy_loss        | -0.0525      |\n",
      "|    reward             | -0.024504505 |\n",
      "|    std                | 233          |\n",
      "|    value_loss         | 7.1e-06      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -0.686       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | -0.123       |\n",
      "|    reward             | -0.020881506 |\n",
      "|    std                | 248          |\n",
      "|    value_loss         | 4.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 163          |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0.0694       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | 0.0191       |\n",
      "|    reward             | -0.020750469 |\n",
      "|    std                | 266          |\n",
      "|    value_loss         | 1.07e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | -0.0746      |\n",
      "|    reward             | -0.019272465 |\n",
      "|    std                | 284          |\n",
      "|    value_loss         | 1.66e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | 0.21         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | 0.0183       |\n",
      "|    reward             | -0.021039413 |\n",
      "|    std                | 305          |\n",
      "|    value_loss         | 8.96e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 234          |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -1.29        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | -0.00881     |\n",
      "|    reward             | -0.022987172 |\n",
      "|    std                | 327          |\n",
      "|    value_loss         | 1.81e-07     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 108240.078125\n",
      "Final accumulative portfolio value: 0.108240078125\n",
      "Maximum DrawDown: -0.9188222534881646\n",
      "Sharpe ratio: -0.35174477935303133\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -131        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | -0.063      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | -0.975      |\n",
      "|    reward             | -0.05376641 |\n",
      "|    std                | 343         |\n",
      "|    value_loss         | 0.00269     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -1.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | 0.016        |\n",
      "|    reward             | -0.036805954 |\n",
      "|    std                | 353          |\n",
      "|    value_loss         | 1.95e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 307          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -4.54        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | -0.0564      |\n",
      "|    reward             | -0.035314113 |\n",
      "|    std                | 369          |\n",
      "|    value_loss         | 6.41e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 331          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | -0.17        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | 0.0766       |\n",
      "|    reward             | -0.031629197 |\n",
      "|    std                | 391          |\n",
      "|    value_loss         | 1.43e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -131        |\n",
      "| time/                 |             |\n",
      "|    fps                | 21          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -0.177      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 0.0516      |\n",
      "|    reward             | -0.03190007 |\n",
      "|    std                | 416         |\n",
      "|    value_loss         | 7.3e-06     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 377          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 0.0199       |\n",
      "|    reward             | -0.020165123 |\n",
      "|    std                | 443          |\n",
      "|    value_loss         | 8.52e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 401          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | -0.72        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | 0.0142       |\n",
      "|    reward             | -0.020243062 |\n",
      "|    std                | 473          |\n",
      "|    value_loss         | 4.22e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 21           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | -2.81        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | 0.0063       |\n",
      "|    reward             | -0.017511496 |\n",
      "|    std                | 507          |\n",
      "|    value_loss         | 1.64e-07     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | -8.12        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.0322      |\n",
      "|    reward             | -0.021214996 |\n",
      "|    std                | 543          |\n",
      "|    value_loss         | 2.13e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -131         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 481          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | -0.31        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | 0.0497       |\n",
      "|    reward             | -0.025277924 |\n",
      "|    std                | 582          |\n",
      "|    value_loss         | 5.57e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 81707.203125\n",
      "Final accumulative portfolio value: 0.081707203125\n",
      "Maximum DrawDown: -0.9386966812696564\n",
      "Sharpe ratio: -0.41105446951012087\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 513          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | -0.0874      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | -1.33        |\n",
      "|    reward             | -0.036192115 |\n",
      "|    std                | 602          |\n",
      "|    value_loss         | 0.00496      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.12e+03   |\n",
      "|    ep_rew_mean        | -130       |\n",
      "| time/                 |            |\n",
      "|    fps                | 20         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 538        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.5      |\n",
      "|    explained_variance | -0.169     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12199      |\n",
      "|    policy_loss        | -0.179     |\n",
      "|    reward             | -0.0471002 |\n",
      "|    std                | 620        |\n",
      "|    value_loss         | 6.43e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 563          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | -4.17        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | -0.0669      |\n",
      "|    reward             | -0.039155945 |\n",
      "|    std                | 647          |\n",
      "|    value_loss         | 9.21e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 590          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 0.227        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | 0.0307       |\n",
      "|    reward             | -0.037353624 |\n",
      "|    std                | 682          |\n",
      "|    value_loss         | 1.71e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | -0.571       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | -0.040626273 |\n",
      "|    std                | 726          |\n",
      "|    value_loss         | 2.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 644          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.0101       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12599        |\n",
      "|    policy_loss        | 0.0635       |\n",
      "|    reward             | -0.036634948 |\n",
      "|    std                | 774          |\n",
      "|    value_loss         | 7.36e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 671          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12699        |\n",
      "|    policy_loss        | -0.0278      |\n",
      "|    reward             | -0.039968397 |\n",
      "|    std                | 828          |\n",
      "|    value_loss         | 1.27e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 694          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0.00475      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | 0.0513       |\n",
      "|    reward             | -0.034953117 |\n",
      "|    std                | 887          |\n",
      "|    value_loss         | 5.28e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -130         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 718          |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | -65.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | 0.00329      |\n",
      "|    reward             | -0.035345737 |\n",
      "|    std                | 951          |\n",
      "|    value_loss         | 7.58e-08     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -130        |\n",
      "| time/                 |             |\n",
      "|    fps                | 20          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 742         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.0136      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | -0.0473     |\n",
      "|    reward             | -0.03382651 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 3.98e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 42218.8046875\n",
      "Final accumulative portfolio value: 0.0422188046875\n",
      "Maximum DrawDown: -0.9668967100953646\n",
      "Sharpe ratio: -0.5421434520785303\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.12e+03  |\n",
      "|    ep_rew_mean        | -150      |\n",
      "| time/                 |           |\n",
      "|    fps                | 20        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 770       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -25.2     |\n",
      "|    explained_variance | -0.912    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 0.75      |\n",
      "|    reward             | 0.0451367 |\n",
      "|    std                | 1.08e+03  |\n",
      "|    value_loss         | 0.00131   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 793          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | 0.259        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | -0.272       |\n",
      "|    reward             | -0.017774154 |\n",
      "|    std                | 1.11e+03     |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 816          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | -1.88        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13299        |\n",
      "|    policy_loss        | -0.0388      |\n",
      "|    reward             | -0.014541871 |\n",
      "|    std                | 1.16e+03     |\n",
      "|    value_loss         | 9.59e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 843          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | -6.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | -0.0554      |\n",
      "|    reward             | -0.010226873 |\n",
      "|    std                | 1.22e+03     |\n",
      "|    value_loss         | 7.99e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.12e+03    |\n",
      "|    ep_rew_mean        | -150        |\n",
      "| time/                 |             |\n",
      "|    fps                | 20          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 870         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.7       |\n",
      "|    explained_variance | -0.0823     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | 0.0171      |\n",
      "|    reward             | -0.01622624 |\n",
      "|    std                | 1.3e+03     |\n",
      "|    value_loss         | 1.66e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 897          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0.341        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | 0.0399       |\n",
      "|    reward             | -0.009710794 |\n",
      "|    std                | 1.38e+03     |\n",
      "|    value_loss         | 2.92e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 20           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 924          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0.0457       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | 0.0451       |\n",
      "|    reward             | -0.004797511 |\n",
      "|    std                | 1.47e+03     |\n",
      "|    value_loss         | 3.83e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.12e+03      |\n",
      "|    ep_rew_mean        | -150          |\n",
      "| time/                 |               |\n",
      "|    fps                | 19            |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 951           |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | -0.379        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13799         |\n",
      "|    policy_loss        | -0.0383       |\n",
      "|    reward             | -0.0032288048 |\n",
      "|    std                | 1.58e+03      |\n",
      "|    value_loss         | 2.47e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.12e+03     |\n",
      "|    ep_rew_mean        | -150         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 978          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0.0467       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | -0.419       |\n",
      "|    reward             | -0.007711026 |\n",
      "|    std                | 1.69e+03     |\n",
      "|    value_loss         | 0.000322     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.12e+03      |\n",
      "|    ep_rew_mean        | -150          |\n",
      "| time/                 |               |\n",
      "|    fps                | 19            |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 1004          |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.8         |\n",
      "|    explained_variance | -0.0762       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13999         |\n",
      "|    policy_loss        | -0.0244       |\n",
      "|    reward             | -0.0062994286 |\n",
      "|    std                | 1.81e+03      |\n",
      "|    value_loss         | 9.55e-07      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 264228.71875\n",
      "Final accumulative portfolio value: 0.26422871875\n",
      "Maximum DrawDown: -0.8143632799798417\n",
      "Sharpe ratio: -0.1691600973233029\n",
      "=================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (1, 3)) of distribution Normal(loc: torch.Size([1, 3]), scale: torch.Size([1, 3])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recession_result_dax_sortino \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mINDICATORS\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn_vector_log_return_reward_recession\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreward_sortino\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m recession_result_dax_sharpe \u001b[38;5;241m=\u001b[39m benchmark(train_data,test_data,\u001b[38;5;241m50_000\u001b[39m,\u001b[38;5;241m1\u001b[39m,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m'\u001b[39m],INDICATORS,save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_vector_log_return_reward_recession\u001b[39m\u001b[38;5;124m'\u001b[39m,reward_sharpe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\versu\\Documents\\Thesis\\utils.py:101\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(train_data, test_data, iterations, t, features, INDICATORS, save, tag, reward_sortino, reward_sharpe, load_model)\u001b[0m\n\u001b[0;32m     90\u001b[0m training_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     91\u001b[0m     {\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_environment\u001b[38;5;241m.\u001b[39m_date_memory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     }\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m load_model:\n\u001b[1;32m--> 101\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mppo_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\versu\\Documents\\Thesis\\models.py:120\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    118\u001b[0m     model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m    119\u001b[0m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[0;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:202\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 202\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\common\\policies.py:654\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[0;32m    653\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[1;32m--> 654\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m    656\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\common\\policies.py:694\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    691\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\stable_baselines3\\common\\distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\torch\\distributions\\normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\versu\\anaconda3\\envs\\Thesis\\lib\\site-packages\\torch\\distributions\\distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (1, 3)) of distribution Normal(loc: torch.Size([1, 3]), scale: torch.Size([1, 3])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan, nan, nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "recession_result_dax_sortino = benchmark(train_data,test_data,50_000,1,['close','return'],INDICATORS,save=True,tag='return_vector_log_return_reward_recession',reward_sortino=True)\n",
    "recession_result_dax_sharpe = benchmark(train_data,test_data,50_000,1,['close','return'],INDICATORS,save=True,tag='return_vector_log_return_reward_recession',reward_sharpe=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "DATA_START_DATE = '1999-01-01'\n",
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2006-12-30'\n",
    "TEST_START_DATE = '2007-01-01'\n",
    "TEST_END_DATE = '2008-12-31'\n",
    "\n",
    "INDICATORS = [\n",
    "    \"close_5_ema\",\n",
    "]\n",
    "fe = FeatureEngineer(use_technical_indicator=False,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature =True)\n",
    "\n",
    "processed = fe.preprocess_data(df_dow)\n",
    "processed = processed.fillna(0)\n",
    "processed= processed.replace(np.inf,0)\n",
    "train_data= data_split(processed, DATA_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(processed, TEST_START_DATE, TEST_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'AMGN', 'AXP', 'BA', 'CAT', 'CVX', 'DIS', 'HD', 'HON',\n",
       "       'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT',\n",
       "       'NKE', 'PG', 'TRV', 'UNH', 'VZ', 'WBA', 'WMT'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AMAT', 'AMD', 'AMGN',\n",
       "       'CDNS', 'CMCSA', 'COST', 'CSX', 'CTAS', 'EA', 'FAST', 'HAS',\n",
       "       'INTC', 'JBHT', 'KLAC', 'LRCX', 'MNST', 'MSFT', 'MU', 'PAYX',\n",
       "       'PCAR', 'PEP', 'ROST', 'SWKS', 'TXN', 'WBA', 'WDC', 'XEL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_27\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1776396.75\n",
      "Final accumulative portfolio value: 1.77639675\n",
      "Maximum DrawDown: -0.4911439190751282\n",
      "Sharpe ratio: 0.40735133630416054\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 2.01e+03    |\n",
      "|    ep_rew_mean     | 60.3        |\n",
      "| time/              |             |\n",
      "|    fps             | 17          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 118         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.04306305 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1535482.0\n",
      "Final accumulative portfolio value: 1.535482\n",
      "Maximum DrawDown: -0.5335042402381374\n",
      "Sharpe ratio: 0.33669566973702203\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008793346 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | -0.0397     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.477      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    reward               | 0.026616236 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1719112.0\n",
      "Final accumulative portfolio value: 1.719112\n",
      "Maximum DrawDown: -0.468007286162175\n",
      "Sharpe ratio: 0.3901105222058704\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009059729 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.464      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    reward               | 0.046250124 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1796376.5\n",
      "Final accumulative portfolio value: 1.7963765\n",
      "Maximum DrawDown: -0.4902368035800453\n",
      "Sharpe ratio: 0.41192291692864413\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009901833 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0927      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.486      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    reward               | 0.05738685  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1507530.625\n",
      "Final accumulative portfolio value: 1.507530625\n",
      "Maximum DrawDown: -0.5159351583253566\n",
      "Sharpe ratio: 0.3278426050539881\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01076053  |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.0955      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.479      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    reward               | 0.036846604 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1893466.25\n",
      "Final accumulative portfolio value: 1.89346625\n",
      "Maximum DrawDown: -0.46917283256248665\n",
      "Sharpe ratio: 0.4391627532779262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 733         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008855065 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.469      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    reward               | 0.06646655  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1572163.25\n",
      "Final accumulative portfolio value: 1.57216325\n",
      "Maximum DrawDown: -0.5079533361831302\n",
      "Sharpe ratio: 0.3477010603179508\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010254918 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.456      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | 0.10667172  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1974045.75\n",
      "Final accumulative portfolio value: 1.97404575\n",
      "Maximum DrawDown: -0.46615649562830874\n",
      "Sharpe ratio: 0.4579790129955073\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 59.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 964         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010193925 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.469      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    reward               | 0.0944907   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1709452.625\n",
      "Final accumulative portfolio value: 1.709452625\n",
      "Maximum DrawDown: -0.4770565011248241\n",
      "Sharpe ratio: 0.38788677167756325\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1079        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011259031 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.427      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    reward               | 0.076239236 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1682930.5\n",
      "Final accumulative portfolio value: 1.6829305\n",
      "Maximum DrawDown: -0.4489026484772496\n",
      "Sharpe ratio: 0.3800971741778671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1194        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010942393 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.0592      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.476      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    reward               | 0.07326808  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1657497.75\n",
      "Final accumulative portfolio value: 1.65749775\n",
      "Maximum DrawDown: -0.4850742406975159\n",
      "Sharpe ratio: 0.3731440807126111\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1310        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011620212 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.405      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    reward               | 0.048866324 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1571514.625\n",
      "Final accumulative portfolio value: 1.571514625\n",
      "Maximum DrawDown: -0.5118450679399663\n",
      "Sharpe ratio: 0.34778117073571624\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1423        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012025833 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.47       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    reward               | 0.032842323 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1530036.125\n",
      "Final accumulative portfolio value: 1.530036125\n",
      "Maximum DrawDown: -0.5005701962791038\n",
      "Sharpe ratio: 0.3345524605350874\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 59.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1537        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012294294 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0973      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.457      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    reward               | 0.051301118 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1973957.625\n",
      "Final accumulative portfolio value: 1.973957625\n",
      "Maximum DrawDown: -0.431217818724422\n",
      "Sharpe ratio: 0.45783247617465295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1651        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014245838 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.446      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    reward               | 0.04233969  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1665325.375\n",
      "Final accumulative portfolio value: 1.665325375\n",
      "Maximum DrawDown: -0.5030740154629361\n",
      "Sharpe ratio: 0.3752952053410619\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 60          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1765        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012310339 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.448      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    reward               | 0.040168557 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1688724.5\n",
      "Final accumulative portfolio value: 1.6887245\n",
      "Maximum DrawDown: -0.4779253801071893\n",
      "Sharpe ratio: 0.382132020823994\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 59.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1877         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132322665 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.7        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.468       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0453      |\n",
      "|    reward               | 0.030545563  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.176        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1665823.125\n",
      "Final accumulative portfolio value: 1.665823125\n",
      "Maximum DrawDown: -0.49441254863713957\n",
      "Sharpe ratio: 0.3756542479223595\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 59.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1990        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011085989 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.464      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    reward               | 0.014290561 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1411085.625\n",
      "Final accumulative portfolio value: 1.411085625\n",
      "Maximum DrawDown: -0.5224169991779897\n",
      "Sharpe ratio: 0.29591219502725963\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 58.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2103        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013106675 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.444      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    reward               | 0.033180095 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1570959.125\n",
      "Final accumulative portfolio value: 1.570959125\n",
      "Maximum DrawDown: -0.4978999974085979\n",
      "Sharpe ratio: 0.3472208218049605\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 58.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2217        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013379907 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.445      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    reward               | 0.032101635 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1570638.375\n",
      "Final accumulative portfolio value: 1.570638375\n",
      "Maximum DrawDown: -0.447852603507091\n",
      "Sharpe ratio: 0.34720505332472434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2329        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012655317 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.487      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    reward               | 0.03723844  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1815296.375\n",
      "Final accumulative portfolio value: 1.815296375\n",
      "Maximum DrawDown: -0.46986791722430943\n",
      "Sharpe ratio: 0.41741598463367513\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2444        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013513587 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.412      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0465     |\n",
      "|    reward               | 0.017312314 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1634296.0\n",
      "Final accumulative portfolio value: 1.634296\n",
      "Maximum DrawDown: -0.48158948006239366\n",
      "Sharpe ratio: 0.3662622335710943\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 57.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2558         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01295753   |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.3        |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.484       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0443      |\n",
      "|    reward               | 0.0011693184 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1441946.25\n",
      "Final accumulative portfolio value: 1.44194625\n",
      "Maximum DrawDown: -0.5017956787468558\n",
      "Sharpe ratio: 0.3059433520697841\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2676         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119758155 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.3        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.5         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0424      |\n",
      "|    reward               | 0.011554161  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.127        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1911287.75\n",
      "Final accumulative portfolio value: 1.91128775\n",
      "Maximum DrawDown: -0.4675602148940361\n",
      "Sharpe ratio: 0.4415176938409519\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2792        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013104694 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.462      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    reward               | 0.014221419 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1729147.5\n",
      "Final accumulative portfolio value: 1.7291475\n",
      "Maximum DrawDown: -0.5113557571678665\n",
      "Sharpe ratio: 0.3924640738769872\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2907        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014632315 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.483      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    reward               | 0.002300372 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "Logging to ./data/tb\\ppo_28\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1626943.875\n",
      "Final accumulative portfolio value: 1.626943875\n",
      "Maximum DrawDown: -0.5357861358596636\n",
      "Sharpe ratio: 0.3637715322660158\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 2.01e+03    |\n",
      "|    ep_rew_mean     | 62.8        |\n",
      "| time/              |             |\n",
      "|    fps             | 17          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 114         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.08877025 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1560285.125\n",
      "Final accumulative portfolio value: 1.560285125\n",
      "Maximum DrawDown: -0.45943781021607977\n",
      "Sharpe ratio: 0.34466626956682367\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014008116 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.456      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    reward               | 0.001068799 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1544427.375\n",
      "Final accumulative portfolio value: 1.544427375\n",
      "Maximum DrawDown: -0.5165572547594046\n",
      "Sharpe ratio: 0.3394883008925022\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 54.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 17            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 344           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014234604   |\n",
      "|    clip_fraction        | 0.131         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.8         |\n",
      "|    explained_variance   | 0.107         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.483        |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.0462       |\n",
      "|    reward               | -0.0015436045 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.158         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1453834.0\n",
      "Final accumulative portfolio value: 1.453834\n",
      "Maximum DrawDown: -0.49469066949261664\n",
      "Sharpe ratio: 0.3100176539755159\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 49.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012664045 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    reward               | 0.031282473 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1749505.375\n",
      "Final accumulative portfolio value: 1.749505375\n",
      "Maximum DrawDown: -0.4693461598558485\n",
      "Sharpe ratio: 0.3994016007663981\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 51.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013624135 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.473      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    reward               | 0.035142906 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1696559.25\n",
      "Final accumulative portfolio value: 1.69655925\n",
      "Maximum DrawDown: -0.49160128762553335\n",
      "Sharpe ratio: 0.3852196057286267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013975285 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.463      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    reward               | 0.076484114 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1737713.0\n",
      "Final accumulative portfolio value: 1.737713\n",
      "Maximum DrawDown: -0.48535644854583515\n",
      "Sharpe ratio: 0.3957893361740215\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 811         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013970563 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.085       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.493      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    reward               | 0.06495103  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1514383.0\n",
      "Final accumulative portfolio value: 1.514383\n",
      "Maximum DrawDown: -0.4857994421575761\n",
      "Sharpe ratio: 0.3300141709580145\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 54.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 927          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146595165 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.2        |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.495       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0489      |\n",
      "|    reward               | 0.08665764   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.182        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1868423.625\n",
      "Final accumulative portfolio value: 1.868423625\n",
      "Maximum DrawDown: -0.4383387883216582\n",
      "Sharpe ratio: 0.4303724088057948\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1043        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844326 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.448      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    reward               | 0.07222964  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1722254.5\n",
      "Final accumulative portfolio value: 1.7222545\n",
      "Maximum DrawDown: -0.48829293503999815\n",
      "Sharpe ratio: 0.391801335815038\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014665718 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.489      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    reward               | 0.07282967  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1718000.875\n",
      "Final accumulative portfolio value: 1.718000875\n",
      "Maximum DrawDown: -0.49517686281333373\n",
      "Sharpe ratio: 0.391378754757405\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013342157 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.474      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    reward               | 0.05223921  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1894685.375\n",
      "Final accumulative portfolio value: 1.894685375\n",
      "Maximum DrawDown: -0.4676698077925555\n",
      "Sharpe ratio: 0.43722305521993776\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1388        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013919802 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.474      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    reward               | 0.023375474 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1647967.875\n",
      "Final accumulative portfolio value: 1.647967875\n",
      "Maximum DrawDown: -0.48303599349680815\n",
      "Sharpe ratio: 0.3708570246676776\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 55.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1502         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147176925 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.506       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0483      |\n",
      "|    reward               | 0.042908642  |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.159        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1879376.125\n",
      "Final accumulative portfolio value: 1.879376125\n",
      "Maximum DrawDown: -0.45384834448122857\n",
      "Sharpe ratio: 0.4345466599055193\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1616        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01320528  |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.463      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    reward               | 0.045041595 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1736314.125\n",
      "Final accumulative portfolio value: 1.736314125\n",
      "Maximum DrawDown: -0.49633910201885956\n",
      "Sharpe ratio: 0.39620805743287196\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093379 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.482      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    reward               | 0.034288682 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1701621.25\n",
      "Final accumulative portfolio value: 1.70162125\n",
      "Maximum DrawDown: -0.5048379234312905\n",
      "Sharpe ratio: 0.38647401175836743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1851        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015369441 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.462      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    reward               | 0.042617075 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1735901.0\n",
      "Final accumulative portfolio value: 1.735901\n",
      "Maximum DrawDown: -0.4583778081964469\n",
      "Sharpe ratio: 0.3949471664239212\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1961        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01363629  |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.503      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    reward               | 0.027446032 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1908369.125\n",
      "Final accumulative portfolio value: 1.908369125\n",
      "Maximum DrawDown: -0.4595376885832366\n",
      "Sharpe ratio: 0.44167367058392626\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2073        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014299734 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.504      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    reward               | 0.031401314 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1650522.5\n",
      "Final accumulative portfolio value: 1.6505225\n",
      "Maximum DrawDown: -0.486910193192972\n",
      "Sharpe ratio: 0.3715157913740396\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2184        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015589304 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.471      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    reward               | 0.042212483 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1782081.0\n",
      "Final accumulative portfolio value: 1.782081\n",
      "Maximum DrawDown: -0.45719977706137704\n",
      "Sharpe ratio: 0.4075930924579083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2295        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013890839 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.474      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    reward               | 0.034303285 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1573075.75\n",
      "Final accumulative portfolio value: 1.57307575\n",
      "Maximum DrawDown: -0.5144147798115823\n",
      "Sharpe ratio: 0.3479980089363443\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2406        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014757272 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.441      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    reward               | 0.02526059  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1974319.75\n",
      "Final accumulative portfolio value: 1.97431975\n",
      "Maximum DrawDown: -0.4376864102920641\n",
      "Sharpe ratio: 0.45824595279281705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2516        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01322579  |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.482      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    reward               | 0.005049984 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1436757.5\n",
      "Final accumulative portfolio value: 1.4367575\n",
      "Maximum DrawDown: -0.4980372234776159\n",
      "Sharpe ratio: 0.3045128612333175\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2627         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014856566  |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.5        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.516       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0494      |\n",
      "|    reward               | 0.0021999932 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.143        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1643520.375\n",
      "Final accumulative portfolio value: 1.643520375\n",
      "Maximum DrawDown: -0.47850854200812365\n",
      "Sharpe ratio: 0.37027936907595677\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2737        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014157064 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.516      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    reward               | 0.011321708 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1619217.875\n",
      "Final accumulative portfolio value: 1.619217875\n",
      "Maximum DrawDown: -0.5223535615447535\n",
      "Sharpe ratio: 0.36262663540609075\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2847         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015102947  |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.7        |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.514       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0499      |\n",
      "|    reward               | 0.0076773367 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.163        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 661963.5\n",
      "Final accumulative portfolio value: 0.6619635\n",
      "Maximum DrawDown: -0.5045468737305989\n",
      "Sharpe ratio: -0.5228665073635271\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_22\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.3       |\n",
      "|    explained_variance | -34.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 4.52        |\n",
      "|    reward             | 0.029103255 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0294      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.7      |\n",
      "|    explained_variance | -5.58      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 3.7        |\n",
      "|    reward             | 0.01345115 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.00717    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.3       |\n",
      "|    explained_variance | -15.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.837       |\n",
      "|    reward             | 0.026020862 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.000466    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49         |\n",
      "|    explained_variance | -31.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.638      |\n",
      "|    reward             | 0.024115385 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1664228.125\n",
      "Final accumulative portfolio value: 1.664228125\n",
      "Maximum DrawDown: -0.43680003335077777\n",
      "Sharpe ratio: 0.37574901630833124\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.4      |\n",
      "|    explained_variance | -776       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 2.89       |\n",
      "|    reward             | 0.03860514 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.0262     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.9       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -3.47       |\n",
      "|    reward             | 0.019958843 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.0047      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.5      |\n",
      "|    explained_variance | -2.91      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 0.266      |\n",
      "|    reward             | 0.02994466 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 9.37e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.4       |\n",
      "|    explained_variance | -330        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.0986      |\n",
      "|    reward             | 0.028566873 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 7.07e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1925319.75\n",
      "Final accumulative portfolio value: 1.92531975\n",
      "Maximum DrawDown: -0.45194482733719665\n",
      "Sharpe ratio: 0.44434952394637134\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.8       |\n",
      "|    explained_variance | -86.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -8.69       |\n",
      "|    reward             | 0.034517836 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.0403      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.5       |\n",
      "|    explained_variance | -0.382      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.514       |\n",
      "|    reward             | 0.012420947 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000285    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.2       |\n",
      "|    explained_variance | -12.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.214       |\n",
      "|    reward             | 0.023655152 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.1       |\n",
      "|    explained_variance | -1.49e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.618      |\n",
      "|    reward             | 0.021080686 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 0.000184    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1509142.75\n",
      "Final accumulative portfolio value: 1.50914275\n",
      "Maximum DrawDown: -0.4933686879687127\n",
      "Sharpe ratio: 0.32797022172536305\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.6       |\n",
      "|    explained_variance | -175        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.0959      |\n",
      "|    reward             | 0.041285343 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.2       |\n",
      "|    explained_variance | -7.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.899       |\n",
      "|    reward             | 0.024324799 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 0.00102     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 412        |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -55.9      |\n",
      "|    explained_variance | -2.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.0599    |\n",
      "|    reward             | 0.02868686 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 3.99e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.9       |\n",
      "|    explained_variance | -231        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.909       |\n",
      "|    reward             | 0.027460571 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.000411    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1836423.5\n",
      "Final accumulative portfolio value: 1.8364235\n",
      "Maximum DrawDown: -0.4354307911666857\n",
      "Sharpe ratio: 0.42248673122856895\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.4       |\n",
      "|    explained_variance | -2.2e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -2.74       |\n",
      "|    reward             | 0.042391997 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 0.0194      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 495         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.9       |\n",
      "|    explained_variance | -8.35       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -3.41       |\n",
      "|    reward             | 0.010093002 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 0.00629     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 523        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -58.6      |\n",
      "|    explained_variance | -14.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.451     |\n",
      "|    reward             | 0.01977588 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 0.000145   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 551         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.6       |\n",
      "|    explained_variance | -12.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.293      |\n",
      "|    reward             | 0.019683214 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 6.76e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1465123.75\n",
      "Final accumulative portfolio value: 1.46512375\n",
      "Maximum DrawDown: -0.5155123332894063\n",
      "Sharpe ratio: 0.31433938331310735\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 56.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 581        |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -60        |\n",
      "|    explained_variance | -138       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 7.57       |\n",
      "|    reward             | 0.03959974 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 0.0219     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 56.3         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 608          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.6        |\n",
      "|    explained_variance | -4.67        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | -3.56        |\n",
      "|    reward             | 0.0067301425 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.00551      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 56.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 635         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.3       |\n",
      "|    explained_variance | -198        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.954      |\n",
      "|    reward             | 0.017699571 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 56.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 662         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.3       |\n",
      "|    explained_variance | -15.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.814       |\n",
      "|    reward             | 0.020328082 |\n",
      "|    std                | 1.6         |\n",
      "|    value_loss         | 0.000168    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1461643.0\n",
      "Final accumulative portfolio value: 1.461643\n",
      "Maximum DrawDown: -0.49260246663498175\n",
      "Sharpe ratio: 0.312561367208811\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 692         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.9       |\n",
      "|    explained_variance | -1.48e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -2.77       |\n",
      "|    reward             | 0.061054524 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 0.0389      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 719         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.3       |\n",
      "|    explained_variance | -4.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 2.12        |\n",
      "|    reward             | 0.017230134 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.00372     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 747         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.9       |\n",
      "|    explained_variance | -7.44e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -0.755      |\n",
      "|    reward             | 0.027257873 |\n",
      "|    std                | 1.68        |\n",
      "|    value_loss         | 0.000717    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 773         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.8       |\n",
      "|    explained_variance | -925        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 1           |\n",
      "|    reward             | 0.028387677 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 0.000508    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1939119.5\n",
      "Final accumulative portfolio value: 1.9391195\n",
      "Maximum DrawDown: -0.4592090521581649\n",
      "Sharpe ratio: 0.4506506657578366\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 804        |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -65.2      |\n",
      "|    explained_variance | -27.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -5.93      |\n",
      "|    reward             | 0.04597147 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 0.0256     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 831         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.7       |\n",
      "|    explained_variance | 0.3         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.293      |\n",
      "|    reward             | 0.015932452 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 0.000578    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 858         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -66.4       |\n",
      "|    explained_variance | -28.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -1.18       |\n",
      "|    reward             | 0.023723813 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 0.000517    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 885         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.3       |\n",
      "|    explained_variance | -23.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -0.567      |\n",
      "|    reward             | 0.027284691 |\n",
      "|    std                | 1.86        |\n",
      "|    value_loss         | 9.56e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1841251.75\n",
      "Final accumulative portfolio value: 1.84125175\n",
      "Maximum DrawDown: -0.43278510002740955\n",
      "Sharpe ratio: 0.423589281353488\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 56.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 915        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -67.9      |\n",
      "|    explained_variance | -12        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 9.01       |\n",
      "|    reward             | 0.02955223 |\n",
      "|    std                | 1.9        |\n",
      "|    value_loss         | 0.0198     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 56.8          |\n",
      "| time/                 |               |\n",
      "|    fps                | 18            |\n",
      "|    iterations         | 3400          |\n",
      "|    time_elapsed       | 942           |\n",
      "|    total_timesteps    | 17000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -68.5         |\n",
      "|    explained_variance | -9.85         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3399          |\n",
      "|    policy_loss        | -8.2          |\n",
      "|    reward             | -0.0025572502 |\n",
      "|    std                | 1.93          |\n",
      "|    value_loss         | 0.0223        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 56.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 969         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.2       |\n",
      "|    explained_variance | -3.03e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 0.11        |\n",
      "|    reward             | 0.015508446 |\n",
      "|    std                | 1.98        |\n",
      "|    value_loss         | 0.000202    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 56.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 996         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.2       |\n",
      "|    explained_variance | -186        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -1.74       |\n",
      "|    reward             | 0.017615866 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.000731    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1370946.75\n",
      "Final accumulative portfolio value: 1.37094675\n",
      "Maximum DrawDown: -0.5520229176282906\n",
      "Sharpe ratio: 0.281956587230638\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 1027       |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -70.8      |\n",
      "|    explained_variance | -15.1      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 2.41       |\n",
      "|    reward             | 0.05735471 |\n",
      "|    std                | 2.07       |\n",
      "|    value_loss         | 0.0026     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1054        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.3       |\n",
      "|    explained_variance | -0.314      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -3.98       |\n",
      "|    reward             | 0.004992166 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.00429     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1081        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72         |\n",
      "|    explained_variance | -80.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | -0.161      |\n",
      "|    reward             | 0.017293323 |\n",
      "|    std                | 2.15        |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1108        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.9       |\n",
      "|    explained_variance | -8.73       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.156       |\n",
      "|    reward             | 0.020870488 |\n",
      "|    std                | 2.21        |\n",
      "|    value_loss         | 3.25e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1572379.0\n",
      "Final accumulative portfolio value: 1.572379\n",
      "Maximum DrawDown: -0.5057116380249725\n",
      "Sharpe ratio: 0.34812853401333144\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 1137       |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.5      |\n",
      "|    explained_variance | -12.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.04930032 |\n",
      "|    std                | 2.25       |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 55.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 1164         |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.1        |\n",
      "|    explained_variance | 0.703        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.456       |\n",
      "|    reward             | -0.003618168 |\n",
      "|    std                | 2.29         |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1191        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -74.8       |\n",
      "|    explained_variance | -29.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.0411     |\n",
      "|    reward             | 0.014523378 |\n",
      "|    std                | 2.34        |\n",
      "|    value_loss         | 0.000352    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1218        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -75.8       |\n",
      "|    explained_variance | -41.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -0.0193     |\n",
      "|    reward             | 0.017079106 |\n",
      "|    std                | 2.41        |\n",
      "|    value_loss         | 1.44e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1390762.75\n",
      "Final accumulative portfolio value: 1.39076275\n",
      "Maximum DrawDown: -0.5066292814298401\n",
      "Sharpe ratio: 0.288606563920033\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 1249       |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -76.6      |\n",
      "|    explained_variance | -68.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -7.43      |\n",
      "|    reward             | 0.05908527 |\n",
      "|    std                | 2.47       |\n",
      "|    value_loss         | 0.0103     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 53.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 1276         |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.3        |\n",
      "|    explained_variance | -1.07        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -3.62        |\n",
      "|    reward             | 0.0057461853 |\n",
      "|    std                | 2.52         |\n",
      "|    value_loss         | 0.00267      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1303        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -78         |\n",
      "|    explained_variance | -12.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -2.82       |\n",
      "|    reward             | 0.017499961 |\n",
      "|    std                | 2.57        |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 1330       |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -79        |\n",
      "|    explained_variance | -5.37      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 0.103      |\n",
      "|    reward             | 0.01860805 |\n",
      "|    std                | 2.66       |\n",
      "|    value_loss         | 2.13e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1518902.625\n",
      "Final accumulative portfolio value: 1.518902625\n",
      "Maximum DrawDown: -0.5120711052483504\n",
      "Sharpe ratio: 0.3313761948271189\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 1360       |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -79.6      |\n",
      "|    explained_variance | -153       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -0.193     |\n",
      "|    reward             | 0.07894345 |\n",
      "|    std                | 2.7        |\n",
      "|    value_loss         | 0.00162    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 1388        |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80         |\n",
      "|    explained_variance | -7.58       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -4.64       |\n",
      "|    reward             | 0.011239963 |\n",
      "|    std                | 2.74        |\n",
      "|    value_loss         | 0.00609     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1416        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80.7       |\n",
      "|    explained_variance | -1.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 1.25        |\n",
      "|    reward             | 0.021417016 |\n",
      "|    std                | 2.8         |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 1444        |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -81.7       |\n",
      "|    explained_variance | -252        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | 0.023602793 |\n",
      "|    std                | 2.88        |\n",
      "|    value_loss         | 0.000647    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1759695.5\n",
      "Final accumulative portfolio value: 1.7596955\n",
      "Maximum DrawDown: -0.4760795330789669\n",
      "Sharpe ratio: 0.40130456778822493\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 1474       |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -82.5      |\n",
      "|    explained_variance | -20.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -1.77      |\n",
      "|    reward             | 0.06910973 |\n",
      "|    std                | 2.95       |\n",
      "|    value_loss         | 0.00124    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1501        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.1       |\n",
      "|    explained_variance | -4.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -5.12       |\n",
      "|    reward             | 0.018280309 |\n",
      "|    std                | 3.01        |\n",
      "|    value_loss         | 0.00539     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 1528        |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.8       |\n",
      "|    explained_variance | -10.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -1.44       |\n",
      "|    reward             | 0.021833923 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 0.000477    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1554        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84.8       |\n",
      "|    explained_variance | -11.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -2.85       |\n",
      "|    reward             | 0.022264339 |\n",
      "|    std                | 3.17        |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1820124.125\n",
      "Final accumulative portfolio value: 1.820124125\n",
      "Maximum DrawDown: -0.45158724620205903\n",
      "Sharpe ratio: 0.41617963249884754\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1584        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85.5       |\n",
      "|    explained_variance | -6.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 5.67        |\n",
      "|    reward             | 0.051492956 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 0.00595     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1611        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -86         |\n",
      "|    explained_variance | -8.65       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -1.49       |\n",
      "|    reward             | 0.007371563 |\n",
      "|    std                | 3.29        |\n",
      "|    value_loss         | 0.00674     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1638        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -86.8       |\n",
      "|    explained_variance | -9.86       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -0.0918     |\n",
      "|    reward             | 0.015848571 |\n",
      "|    std                | 3.36        |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1665        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -87.8       |\n",
      "|    explained_variance | -7.88       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.0302      |\n",
      "|    reward             | 0.020010274 |\n",
      "|    std                | 3.47        |\n",
      "|    value_loss         | 0.000249    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1594143.75\n",
      "Final accumulative portfolio value: 1.59414375\n",
      "Maximum DrawDown: -0.4911522211582575\n",
      "Sharpe ratio: 0.35424805418773253\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 1694        |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.5       |\n",
      "|    explained_variance | -27.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -15.7       |\n",
      "|    reward             | 0.061027184 |\n",
      "|    std                | 3.54        |\n",
      "|    value_loss         | 0.0342      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1721        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -89         |\n",
      "|    explained_variance | -3.05       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 6.43        |\n",
      "|    reward             | 0.003951648 |\n",
      "|    std                | 3.6         |\n",
      "|    value_loss         | 0.00674     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 1749       |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -89.7      |\n",
      "|    explained_variance | -19.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | -3.4       |\n",
      "|    reward             | 0.01836303 |\n",
      "|    std                | 3.67       |\n",
      "|    value_loss         | 0.00205    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1776        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -90.7       |\n",
      "|    explained_variance | -10.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -0.982      |\n",
      "|    reward             | 0.017579433 |\n",
      "|    std                | 3.79        |\n",
      "|    value_loss         | 0.000155    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1514998.125\n",
      "Final accumulative portfolio value: 1.514998125\n",
      "Maximum DrawDown: -0.5203496383000312\n",
      "Sharpe ratio: 0.32976780213941415\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 1805       |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -91.4      |\n",
      "|    explained_variance | -34        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | 0.06939219 |\n",
      "|    std                | 3.87       |\n",
      "|    value_loss         | 0.0196     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1832        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92         |\n",
      "|    explained_variance | 0.613       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 4.88        |\n",
      "|    reward             | 0.011010705 |\n",
      "|    std                | 3.94        |\n",
      "|    value_loss         | 0.00319     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1859        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92.7       |\n",
      "|    explained_variance | -32.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 0.102       |\n",
      "|    reward             | 0.023056058 |\n",
      "|    std                | 4.02        |\n",
      "|    value_loss         | 0.000267    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 1886        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -93.6       |\n",
      "|    explained_variance | -24.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | 0.512       |\n",
      "|    reward             | 0.022554582 |\n",
      "|    std                | 4.14        |\n",
      "|    value_loss         | 8.59e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1703054.125\n",
      "Final accumulative portfolio value: 1.703054125\n",
      "Maximum DrawDown: -0.4824977268169869\n",
      "Sharpe ratio: 0.38566585076014676\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 1916       |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -94.3      |\n",
      "|    explained_variance | -17.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | 6.44       |\n",
      "|    reward             | 0.06265246 |\n",
      "|    std                | 4.22       |\n",
      "|    value_loss         | 0.00744    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 1943        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -94.9       |\n",
      "|    explained_variance | -2.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -6.77       |\n",
      "|    reward             | 0.006193521 |\n",
      "|    std                | 4.3         |\n",
      "|    value_loss         | 0.00647     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 1970        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -95.5       |\n",
      "|    explained_variance | -854        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 0.474       |\n",
      "|    reward             | 0.017123196 |\n",
      "|    std                | 4.39        |\n",
      "|    value_loss         | 0.000151    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 1997        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.4       |\n",
      "|    explained_variance | 0.0387      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -1.66       |\n",
      "|    reward             | 0.019879028 |\n",
      "|    std                | 4.51        |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1485334.375\n",
      "Final accumulative portfolio value: 1.485334375\n",
      "Maximum DrawDown: -0.5191626531457698\n",
      "Sharpe ratio: 0.31967693361511634\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 2027       |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -97.2      |\n",
      "|    explained_variance | -7.23      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 8.98       |\n",
      "|    reward             | 0.07722509 |\n",
      "|    std                | 4.61       |\n",
      "|    value_loss         | 0.0116     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 2055       |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -97.7      |\n",
      "|    explained_variance | -10.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -3.17      |\n",
      "|    reward             | 0.01366606 |\n",
      "|    std                | 4.68       |\n",
      "|    value_loss         | 0.00311    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 2082        |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.4       |\n",
      "|    explained_variance | -346        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | 0.022441939 |\n",
      "|    std                | 4.79        |\n",
      "|    value_loss         | 0.000214    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 2109        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.3       |\n",
      "|    explained_variance | -3.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | -1.78       |\n",
      "|    reward             | 0.020173414 |\n",
      "|    std                | 4.92        |\n",
      "|    value_loss         | 0.000363    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1556159.0\n",
      "Final accumulative portfolio value: 1.556159\n",
      "Maximum DrawDown: -0.507252214585202\n",
      "Sharpe ratio: 0.3422451934495994\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2138        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -100        |\n",
      "|    explained_variance | -49.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 1.54        |\n",
      "|    reward             | 0.079637244 |\n",
      "|    std                | 5.03        |\n",
      "|    value_loss         | 0.00489     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2165        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -6.05       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 8.83        |\n",
      "|    reward             | 0.018666783 |\n",
      "|    std                | 5.1         |\n",
      "|    value_loss         | 0.00874     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2192        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -82.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -1.93       |\n",
      "|    reward             | 0.023194922 |\n",
      "|    std                | 5.21        |\n",
      "|    value_loss         | 0.00055     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 2219       |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -102       |\n",
      "|    explained_variance | -131       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 1.06       |\n",
      "|    reward             | 0.02068533 |\n",
      "|    std                | 5.38       |\n",
      "|    value_loss         | 0.000183   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1603617.125\n",
      "Final accumulative portfolio value: 1.603617125\n",
      "Maximum DrawDown: -0.49054047445295346\n",
      "Sharpe ratio: 0.3570106599238979\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 2249       |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -103       |\n",
      "|    explained_variance | -64.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 3.23       |\n",
      "|    reward             | 0.07428621 |\n",
      "|    std                | 5.5        |\n",
      "|    value_loss         | 0.0206     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 2276        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | -5.06       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -5.88       |\n",
      "|    reward             | 0.022986537 |\n",
      "|    std                | 5.6         |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 2304       |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -104       |\n",
      "|    explained_variance | -111       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 0.153      |\n",
      "|    reward             | 0.02440142 |\n",
      "|    std                | 5.73       |\n",
      "|    value_loss         | 0.000347   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2331        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | -671        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -0.684      |\n",
      "|    reward             | 0.025926609 |\n",
      "|    std                | 5.9         |\n",
      "|    value_loss         | 9.24e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1784441.0\n",
      "Final accumulative portfolio value: 1.784441\n",
      "Maximum DrawDown: -0.4912710473664096\n",
      "Sharpe ratio: 0.40869934481493386\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 2361       |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | -172       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -2.92      |\n",
      "|    reward             | 0.07409965 |\n",
      "|    std                | 6.04       |\n",
      "|    value_loss         | 0.00601    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2388        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | -6.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | -2.47       |\n",
      "|    reward             | 0.020643815 |\n",
      "|    std                | 6.15        |\n",
      "|    value_loss         | 0.000714    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 2415        |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | -2.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.021449113 |\n",
      "|    std                | 6.29        |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2442        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -108        |\n",
      "|    explained_variance | -25.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.021455487 |\n",
      "|    std                | 6.47        |\n",
      "|    value_loss         | 0.000124    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1540910.125\n",
      "Final accumulative portfolio value: 1.540910125\n",
      "Maximum DrawDown: -0.503568431225695\n",
      "Sharpe ratio: 0.33744250448588203\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.01e+03  |\n",
      "|    ep_rew_mean        | 55.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 18        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 2471      |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -109      |\n",
      "|    explained_variance | -13       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 15.2      |\n",
      "|    reward             | 0.0622138 |\n",
      "|    std                | 6.63      |\n",
      "|    value_loss         | 0.023     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 2497        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -110        |\n",
      "|    explained_variance | -1.61       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -3.11       |\n",
      "|    reward             | 0.024492376 |\n",
      "|    std                | 6.74        |\n",
      "|    value_loss         | 0.000962    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2522        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -110        |\n",
      "|    explained_variance | -4.58       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 0.514       |\n",
      "|    reward             | 0.019366827 |\n",
      "|    std                | 6.88        |\n",
      "|    value_loss         | 3.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2549        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -111        |\n",
      "|    explained_variance | -139        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -1.59       |\n",
      "|    reward             | 0.022827037 |\n",
      "|    std                | 7.08        |\n",
      "|    value_loss         | 0.000273    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1523577.75\n",
      "Final accumulative portfolio value: 1.52357775\n",
      "Maximum DrawDown: -0.5199979559728036\n",
      "Sharpe ratio: 0.3319352784265111\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 55         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 2580       |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -112       |\n",
      "|    explained_variance | -22.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | 0.07435348 |\n",
      "|    std                | 7.23       |\n",
      "|    value_loss         | 0.00657    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2608        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -4.13       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -5.35       |\n",
      "|    reward             | 0.029057516 |\n",
      "|    std                | 7.36        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2635        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -844        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | 0.017958483 |\n",
      "|    std                | 7.52        |\n",
      "|    value_loss         | 0.000657    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 55          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2662        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | -37.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.0966      |\n",
      "|    reward             | 0.021461133 |\n",
      "|    std                | 7.73        |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1452342.5\n",
      "Final accumulative portfolio value: 1.4523425\n",
      "Maximum DrawDown: -0.5108222912567182\n",
      "Sharpe ratio: 0.3095418358312846\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 2690       |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -115       |\n",
      "|    explained_variance | -22.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 22.5       |\n",
      "|    reward             | 0.08391359 |\n",
      "|    std                | 7.94       |\n",
      "|    value_loss         | 0.0561     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 54.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 2715       |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -116       |\n",
      "|    explained_variance | -56.5      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | 0.02686653 |\n",
      "|    std                | 8.07       |\n",
      "|    value_loss         | 0.000344   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2741        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -116        |\n",
      "|    explained_variance | -255        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -0.958      |\n",
      "|    reward             | 0.022348752 |\n",
      "|    std                | 8.25        |\n",
      "|    value_loss         | 0.000325    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2766        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -117        |\n",
      "|    explained_variance | -36.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -1.17       |\n",
      "|    reward             | 0.024429085 |\n",
      "|    std                | 8.5         |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "Logging to ./data/tb\\a2c_23\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | -7.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -9.32       |\n",
      "|    reward             | 0.020315712 |\n",
      "|    std                | 8.63        |\n",
      "|    value_loss         | 0.0165      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -119        |\n",
      "|    explained_variance | -363        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 0.922       |\n",
      "|    reward             | 0.006292247 |\n",
      "|    std                | 8.81        |\n",
      "|    value_loss         | 0.000625    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 19        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -119      |\n",
      "|    explained_variance | -8.08     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -1.59     |\n",
      "|    reward             | 0.0214748 |\n",
      "|    std                | 9.04      |\n",
      "|    value_loss         | 0.000244  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -121        |\n",
      "|    explained_variance | -29.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | 0.019394232 |\n",
      "|    std                | 9.36        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1430850.625\n",
      "Final accumulative portfolio value: 1.430850625\n",
      "Maximum DrawDown: -0.506817755322277\n",
      "Sharpe ratio: 0.302286153670486\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 44.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -121       |\n",
      "|    explained_variance | -4.49      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | 3.2        |\n",
      "|    reward             | 0.01997992 |\n",
      "|    std                | 9.57       |\n",
      "|    value_loss         | 0.00648    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 44.6         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 154          |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -122         |\n",
      "|    explained_variance | -3.47e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | -0.214       |\n",
      "|    reward             | 0.0039565475 |\n",
      "|    std                | 9.75         |\n",
      "|    value_loss         | 0.000492     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 44.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -123        |\n",
      "|    explained_variance | -48.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.017283555 |\n",
      "|    std                | 9.98        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 44.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | -1.88e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -1.17       |\n",
      "|    reward             | 0.018626409 |\n",
      "|    std                | 10.3        |\n",
      "|    value_loss         | 0.000208    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1388482.125\n",
      "Final accumulative portfolio value: 1.388482125\n",
      "Maximum DrawDown: -0.5267108665363212\n",
      "Sharpe ratio: 0.2876917350776185\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 41.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | -30.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | -6.55       |\n",
      "|    reward             | 0.049683377 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 41.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | -120        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | -6.04       |\n",
      "|    reward             | 0.018091328 |\n",
      "|    std                | 10.7        |\n",
      "|    value_loss         | 0.00344     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 41.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -126       |\n",
      "|    explained_variance | -2.15      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11099      |\n",
      "|    policy_loss        | 0.745      |\n",
      "|    reward             | 0.02737308 |\n",
      "|    std                | 10.9       |\n",
      "|    value_loss         | 6.83e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 41.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -127        |\n",
      "|    explained_variance | -2.86       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | 0.026228009 |\n",
      "|    std                | 11.3        |\n",
      "|    value_loss         | 0.000146    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1774364.125\n",
      "Final accumulative portfolio value: 1.774364125\n",
      "Maximum DrawDown: -0.44575616718593347\n",
      "Sharpe ratio: 0.4062430315729028\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -127        |\n",
      "|    explained_variance | -10.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -5.27       |\n",
      "|    reward             | 0.027166385 |\n",
      "|    std                | 11.5        |\n",
      "|    value_loss         | 0.00601     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -128        |\n",
      "|    explained_variance | -89.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 7.15        |\n",
      "|    reward             | 0.013580054 |\n",
      "|    std                | 11.7        |\n",
      "|    value_loss         | 0.00341     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | -7.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 0.9         |\n",
      "|    reward             | 0.019696675 |\n",
      "|    std                | 12          |\n",
      "|    value_loss         | 0.000139    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -130        |\n",
      "|    explained_variance | -46         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | -0.307      |\n",
      "|    reward             | 0.020943522 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 6.88e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1474283.25\n",
      "Final accumulative portfolio value: 1.47428325\n",
      "Maximum DrawDown: -0.48882130103530697\n",
      "Sharpe ratio: 0.31685715871125636\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 44.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -130        |\n",
      "|    explained_variance | -0.276      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | -13.8       |\n",
      "|    reward             | 0.044071727 |\n",
      "|    std                | 12.6        |\n",
      "|    value_loss         | 0.0123      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 44.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 474         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | -1.9        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | 2.11        |\n",
      "|    reward             | 0.013175431 |\n",
      "|    std                | 12.8        |\n",
      "|    value_loss         | 0.000602    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 44.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 501        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -132       |\n",
      "|    explained_variance | -26.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | -0.827     |\n",
      "|    reward             | 0.02327473 |\n",
      "|    std                | 13.2       |\n",
      "|    value_loss         | 6.79e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 44.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -133        |\n",
      "|    explained_variance | -143        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.465      |\n",
      "|    reward             | 0.023981327 |\n",
      "|    std                | 13.6        |\n",
      "|    value_loss         | 5.6e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1679728.25\n",
      "Final accumulative portfolio value: 1.67972825\n",
      "Maximum DrawDown: -0.5414894372273802\n",
      "Sharpe ratio: 0.37881896859820785\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -134        |\n",
      "|    explained_variance | -0.786      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -15         |\n",
      "|    reward             | 0.039037116 |\n",
      "|    std                | 13.9        |\n",
      "|    value_loss         | 0.013       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -134        |\n",
      "|    explained_variance | -222        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 1.82        |\n",
      "|    reward             | 0.005295718 |\n",
      "|    std                | 14.1        |\n",
      "|    value_loss         | 0.000481    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | -16.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 2.1         |\n",
      "|    reward             | 0.020417118 |\n",
      "|    std                | 14.5        |\n",
      "|    value_loss         | 0.000432    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -136        |\n",
      "|    explained_variance | -1.8e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 2.31        |\n",
      "|    reward             | 0.021444984 |\n",
      "|    std                | 15          |\n",
      "|    value_loss         | 0.000349    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1508986.25\n",
      "Final accumulative portfolio value: 1.50898625\n",
      "Maximum DrawDown: -0.5118984820594779\n",
      "Sharpe ratio: 0.328292165540595\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 672         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -137        |\n",
      "|    explained_variance | -3.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | 10          |\n",
      "|    reward             | 0.057232007 |\n",
      "|    std                | 15.3        |\n",
      "|    value_loss         | 0.00888     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 699         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -137        |\n",
      "|    explained_variance | -54.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 5.51        |\n",
      "|    reward             | 0.010534184 |\n",
      "|    std                | 15.6        |\n",
      "|    value_loss         | 0.00311     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 727         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | -67.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -2.87       |\n",
      "|    reward             | 0.020497438 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 0.000661    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 756         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -139        |\n",
      "|    explained_variance | -47.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.751      |\n",
      "|    reward             | 0.020476919 |\n",
      "|    std                | 16.5        |\n",
      "|    value_loss         | 8.58e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1505429.5\n",
      "Final accumulative portfolio value: 1.5054295\n",
      "Maximum DrawDown: -0.5136851355269014\n",
      "Sharpe ratio: 0.32687803302364793\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 788         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | -16.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | -7.32       |\n",
      "|    reward             | 0.038191833 |\n",
      "|    std                | 16.8        |\n",
      "|    value_loss         | 0.0162      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 816         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | -27.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | 6.99        |\n",
      "|    reward             | 0.005356083 |\n",
      "|    std                | 17.2        |\n",
      "|    value_loss         | 0.00422     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 844         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | -557        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | -0.558      |\n",
      "|    reward             | 0.018909317 |\n",
      "|    std                | 17.6        |\n",
      "|    value_loss         | 0.000152    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 872         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -143        |\n",
      "|    explained_variance | -42.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.020519957 |\n",
      "|    std                | 18.2        |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1484942.25\n",
      "Final accumulative portfolio value: 1.48494225\n",
      "Maximum DrawDown: -0.5351719332309111\n",
      "Sharpe ratio: 0.3201737673244276\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 49.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 903        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -143       |\n",
      "|    explained_variance | -4.84      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 3.93       |\n",
      "|    reward             | 0.03834739 |\n",
      "|    std                | 18.5       |\n",
      "|    value_loss         | 0.0021     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 933         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -144        |\n",
      "|    explained_variance | -11.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | -14         |\n",
      "|    reward             | 0.003783537 |\n",
      "|    std                | 18.9        |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 962         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | -13.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | 3.37        |\n",
      "|    reward             | 0.018559635 |\n",
      "|    std                | 19.4        |\n",
      "|    value_loss         | 0.000673    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 991         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | -389        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -0.486      |\n",
      "|    reward             | 0.019909844 |\n",
      "|    std                | 20          |\n",
      "|    value_loss         | 3.94e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1526590.25\n",
      "Final accumulative portfolio value: 1.52659025\n",
      "Maximum DrawDown: -0.4998081224962254\n",
      "Sharpe ratio: 0.3335061172497828\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 1023       |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -146       |\n",
      "|    explained_variance | -30.5      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13699      |\n",
      "|    policy_loss        | -14        |\n",
      "|    reward             | 0.04396733 |\n",
      "|    std                | 20.4       |\n",
      "|    value_loss         | 0.00959    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1051        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | -0.993      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | 0.117       |\n",
      "|    reward             | 0.002840927 |\n",
      "|    std                | 20.9        |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 1079       |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -148       |\n",
      "|    explained_variance | -447       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13899      |\n",
      "|    policy_loss        | 1.35       |\n",
      "|    reward             | 0.01821339 |\n",
      "|    std                | 21.4       |\n",
      "|    value_loss         | 0.000196   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1106        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | -29.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | 1.32        |\n",
      "|    reward             | 0.022433529 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1657710.5\n",
      "Final accumulative portfolio value: 1.6577105\n",
      "Maximum DrawDown: -0.4883786167446664\n",
      "Sharpe ratio: 0.37325196420252643\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1137        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | -13.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 2.14        |\n",
      "|    reward             | 0.054191742 |\n",
      "|    std                | 22.7        |\n",
      "|    value_loss         | 0.000757    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 48.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 18            |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 1165          |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -150          |\n",
      "|    explained_variance | -0.426        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14199         |\n",
      "|    policy_loss        | -2.28         |\n",
      "|    reward             | -0.0009550081 |\n",
      "|    std                | 23.1          |\n",
      "|    value_loss         | 0.000331      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1192        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | -23.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | -1.01       |\n",
      "|    reward             | 0.018485023 |\n",
      "|    std                | 23.7        |\n",
      "|    value_loss         | 0.00024     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 1220       |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -152       |\n",
      "|    explained_variance | -14        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14399      |\n",
      "|    policy_loss        | 1.1        |\n",
      "|    reward             | 0.01985157 |\n",
      "|    std                | 24.5       |\n",
      "|    value_loss         | 5.73e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1524705.75\n",
      "Final accumulative portfolio value: 1.52470575\n",
      "Maximum DrawDown: -0.5012719882910656\n",
      "Sharpe ratio: 0.33316117154429675\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 1250       |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -153       |\n",
      "|    explained_variance | -219       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14499      |\n",
      "|    policy_loss        | -13.9      |\n",
      "|    reward             | 0.06320082 |\n",
      "|    std                | 25.1       |\n",
      "|    value_loss         | 0.00918    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1278        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -0.684      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | -5.58       |\n",
      "|    reward             | 0.005068287 |\n",
      "|    std                | 25.6        |\n",
      "|    value_loss         | 0.00155     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -41.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | -1.79       |\n",
      "|    reward             | 0.015797198 |\n",
      "|    std                | 26.2        |\n",
      "|    value_loss         | 0.00026     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 1334        |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -156        |\n",
      "|    explained_variance | -64.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 1.26        |\n",
      "|    reward             | 0.018118639 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1472114.875\n",
      "Final accumulative portfolio value: 1.472114875\n",
      "Maximum DrawDown: -0.5135684483959352\n",
      "Sharpe ratio: 0.31598038533282413\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 1365       |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -156       |\n",
      "|    explained_variance | -286       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14899      |\n",
      "|    policy_loss        | -2.44      |\n",
      "|    reward             | 0.05598254 |\n",
      "|    std                | 27.6       |\n",
      "|    value_loss         | 0.00221    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 47.5          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 1392          |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -157          |\n",
      "|    explained_variance | -17           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -8.27         |\n",
      "|    reward             | -0.0015447598 |\n",
      "|    std                | 28.2          |\n",
      "|    value_loss         | 0.00346       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1419        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -158        |\n",
      "|    explained_variance | -227        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 5.95        |\n",
      "|    reward             | 0.014310535 |\n",
      "|    std                | 28.9        |\n",
      "|    value_loss         | 0.00145     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 1446        |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -159        |\n",
      "|    explained_variance | -10.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | 0.308       |\n",
      "|    reward             | 0.017037738 |\n",
      "|    std                | 29.9        |\n",
      "|    value_loss         | 4.96e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1423890.125\n",
      "Final accumulative portfolio value: 1.423890125\n",
      "Maximum DrawDown: -0.519808856399879\n",
      "Sharpe ratio: 0.3000146386256733\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 46.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 1475       |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -160       |\n",
      "|    explained_variance | -1.68      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15299      |\n",
      "|    policy_loss        | -16.2      |\n",
      "|    reward             | 0.06678776 |\n",
      "|    std                | 30.6       |\n",
      "|    value_loss         | 0.0109     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1502        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -160        |\n",
      "|    explained_variance | -2.21       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | -4.22       |\n",
      "|    reward             | 0.013367644 |\n",
      "|    std                | 31.1        |\n",
      "|    value_loss         | 0.00122     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 1530        |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -161        |\n",
      "|    explained_variance | -134        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15499       |\n",
      "|    policy_loss        | -1.5        |\n",
      "|    reward             | 0.015342788 |\n",
      "|    std                | 31.9        |\n",
      "|    value_loss         | 0.000228    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 46.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1558        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | -5.78       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -4.33       |\n",
      "|    reward             | 0.018108325 |\n",
      "|    std                | 33          |\n",
      "|    value_loss         | 0.000754    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1550934.25\n",
      "Final accumulative portfolio value: 1.55093425\n",
      "Maximum DrawDown: -0.5078900263749775\n",
      "Sharpe ratio: 0.3409675760960894\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1590        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -163        |\n",
      "|    explained_variance | -167        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | 0.057835523 |\n",
      "|    std                | 33.9        |\n",
      "|    value_loss         | 0.00492     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1616        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -12.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -14.9       |\n",
      "|    reward             | 0.009442962 |\n",
      "|    std                | 34.5        |\n",
      "|    value_loss         | 0.0132      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1643        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -9.57       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 0.0379      |\n",
      "|    reward             | 0.021256696 |\n",
      "|    std                | 35.4        |\n",
      "|    value_loss         | 7.08e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 1669       |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -165       |\n",
      "|    explained_variance | -11.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -0.939     |\n",
      "|    reward             | 0.02435147 |\n",
      "|    std                | 36.6       |\n",
      "|    value_loss         | 0.000228   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1761601.375\n",
      "Final accumulative portfolio value: 1.761601375\n",
      "Maximum DrawDown: -0.464724040016374\n",
      "Sharpe ratio: 0.40276860947161397\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 1697       |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -166       |\n",
      "|    explained_variance | -75.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16099      |\n",
      "|    policy_loss        | -9.5       |\n",
      "|    reward             | 0.03909374 |\n",
      "|    std                | 37.4       |\n",
      "|    value_loss         | 0.00465    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 48.2          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 1723          |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -167          |\n",
      "|    explained_variance | -0.383        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16199         |\n",
      "|    policy_loss        | 10.6          |\n",
      "|    reward             | -0.0014335322 |\n",
      "|    std                | 38.2          |\n",
      "|    value_loss         | 0.00441       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1750        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -168        |\n",
      "|    explained_variance | -5.35       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -3.24       |\n",
      "|    reward             | 0.014000032 |\n",
      "|    std                | 39.1        |\n",
      "|    value_loss         | 0.000539    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1776        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -169        |\n",
      "|    explained_variance | -28.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | 0.017979033 |\n",
      "|    std                | 40.5        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1510259.375\n",
      "Final accumulative portfolio value: 1.510259375\n",
      "Maximum DrawDown: -0.4910032666300147\n",
      "Sharpe ratio: 0.3281148468749282\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 1805       |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -170       |\n",
      "|    explained_variance | -370       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | 14.7       |\n",
      "|    reward             | 0.06762942 |\n",
      "|    std                | 41.4       |\n",
      "|    value_loss         | 0.014      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 1831       |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -170       |\n",
      "|    explained_variance | -48.1      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | 6.7        |\n",
      "|    reward             | 0.00852929 |\n",
      "|    std                | 42.2       |\n",
      "|    value_loss         | 0.00327    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1857        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -171        |\n",
      "|    explained_variance | -84.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 1.05        |\n",
      "|    reward             | 0.021196684 |\n",
      "|    std                | 43.2        |\n",
      "|    value_loss         | 0.000116    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 1883       |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -172       |\n",
      "|    explained_variance | -4.02      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16799      |\n",
      "|    policy_loss        | -0.288     |\n",
      "|    reward             | 0.02147803 |\n",
      "|    std                | 44.6       |\n",
      "|    value_loss         | 5.65e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1679936.625\n",
      "Final accumulative portfolio value: 1.679936625\n",
      "Maximum DrawDown: -0.48736931328352584\n",
      "Sharpe ratio: 0.3797480659467887\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 1912       |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -173       |\n",
      "|    explained_variance | -12.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16899      |\n",
      "|    policy_loss        | 7.98       |\n",
      "|    reward             | 0.06933301 |\n",
      "|    std                | 45.7       |\n",
      "|    value_loss         | 0.00345    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 1938       |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -173       |\n",
      "|    explained_variance | -2.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | -19.1      |\n",
      "|    reward             | 0.00731453 |\n",
      "|    std                | 46.6       |\n",
      "|    value_loss         | 0.0132     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 1965        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -174        |\n",
      "|    explained_variance | -299        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | 0.013870524 |\n",
      "|    std                | 47.7        |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 1991        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -175        |\n",
      "|    explained_variance | -1.42       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17199       |\n",
      "|    policy_loss        | -1.5        |\n",
      "|    reward             | 0.017442957 |\n",
      "|    std                | 49.4        |\n",
      "|    value_loss         | 7.97e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1382361.5\n",
      "Final accumulative portfolio value: 1.3823615\n",
      "Maximum DrawDown: -0.5263160103305071\n",
      "Sharpe ratio: 0.2856500710788572\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 47.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 2022       |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -176       |\n",
      "|    explained_variance | -550       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17299      |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | 0.07774051 |\n",
      "|    std                | 50.6       |\n",
      "|    value_loss         | 0.00582    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 2050        |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -177        |\n",
      "|    explained_variance | -12         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -2.42       |\n",
      "|    reward             | 0.015995622 |\n",
      "|    std                | 51.6        |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 2078        |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -178        |\n",
      "|    explained_variance | -418        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | -1.86       |\n",
      "|    reward             | 0.023266934 |\n",
      "|    std                | 52.8        |\n",
      "|    value_loss         | 0.000222    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 47.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 2104        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -179        |\n",
      "|    explained_variance | -0.285      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | -4.18       |\n",
      "|    reward             | 0.021432487 |\n",
      "|    std                | 54.5        |\n",
      "|    value_loss         | 0.000537    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1579835.375\n",
      "Final accumulative portfolio value: 1.579835375\n",
      "Maximum DrawDown: -0.4881467651541218\n",
      "Sharpe ratio: 0.3505128180145331\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2133        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -18.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | -13.7       |\n",
      "|    reward             | 0.077807285 |\n",
      "|    std                | 56          |\n",
      "|    value_loss         | 0.00841     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2159        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -21.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 14.9        |\n",
      "|    reward             | 0.017995134 |\n",
      "|    std                | 57          |\n",
      "|    value_loss         | 0.00821     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2186        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -181        |\n",
      "|    explained_variance | -59.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 0.736       |\n",
      "|    reward             | 0.022259366 |\n",
      "|    std                | 58.5        |\n",
      "|    value_loss         | 6.99e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2214        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -182        |\n",
      "|    explained_variance | -1.7e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 0.635       |\n",
      "|    reward             | 0.022893183 |\n",
      "|    std                | 60.5        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1764515.25\n",
      "Final accumulative portfolio value: 1.76451525\n",
      "Maximum DrawDown: -0.4813170800434198\n",
      "Sharpe ratio: 0.4023298710649579\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 2246       |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -183       |\n",
      "|    explained_variance | -36.5      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | 18.4       |\n",
      "|    reward             | 0.07849408 |\n",
      "|    std                | 62.3       |\n",
      "|    value_loss         | 0.0153     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 2274        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -184        |\n",
      "|    explained_variance | -4.3        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | -8.78       |\n",
      "|    reward             | 0.028549097 |\n",
      "|    std                | 63.4        |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2302        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -184        |\n",
      "|    explained_variance | -221        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 1.78        |\n",
      "|    reward             | 0.029863082 |\n",
      "|    std                | 64.9        |\n",
      "|    value_loss         | 0.000204    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2329        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -185        |\n",
      "|    explained_variance | -31.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 0.0376      |\n",
      "|    reward             | 0.028754784 |\n",
      "|    std                | 67          |\n",
      "|    value_loss         | 2.73e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1847818.25\n",
      "Final accumulative portfolio value: 1.84781825\n",
      "Maximum DrawDown: -0.42942594978316384\n",
      "Sharpe ratio: 0.42487866394011053\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.01e+03  |\n",
      "|    ep_rew_mean        | 49.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 18        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 2360      |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -186      |\n",
      "|    explained_variance | -126      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -3.8      |\n",
      "|    reward             | 0.0689638 |\n",
      "|    std                | 68.9      |\n",
      "|    value_loss         | 0.00229   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2389        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -187        |\n",
      "|    explained_variance | -15.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | -3.74       |\n",
      "|    reward             | 0.021668643 |\n",
      "|    std                | 70.2        |\n",
      "|    value_loss         | 0.000763    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 2416        |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -188        |\n",
      "|    explained_variance | 0.0992      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | -2.66       |\n",
      "|    reward             | 0.021970807 |\n",
      "|    std                | 71.9        |\n",
      "|    value_loss         | 0.000213    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2444        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -189        |\n",
      "|    explained_variance | -0.785      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -0.83       |\n",
      "|    reward             | 0.022540873 |\n",
      "|    std                | 74.2        |\n",
      "|    value_loss         | 2.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1601560.125\n",
      "Final accumulative portfolio value: 1.601560125\n",
      "Maximum DrawDown: -0.4787658957146619\n",
      "Sharpe ratio: 0.3565303639196693\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2476        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -190        |\n",
      "|    explained_variance | -40         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | -4.92       |\n",
      "|    reward             | 0.054116238 |\n",
      "|    std                | 76.2        |\n",
      "|    value_loss         | 0.00684     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 2505        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -190        |\n",
      "|    explained_variance | -173        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 3.15        |\n",
      "|    reward             | 0.020023525 |\n",
      "|    std                | 77.8        |\n",
      "|    value_loss         | 0.000717    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2535        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -191        |\n",
      "|    explained_variance | -64.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | -2.4        |\n",
      "|    reward             | 0.013392773 |\n",
      "|    std                | 79.7        |\n",
      "|    value_loss         | 0.000199    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2563        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -192        |\n",
      "|    explained_variance | -74.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | -0.797      |\n",
      "|    reward             | 0.019729732 |\n",
      "|    std                | 82.4        |\n",
      "|    value_loss         | 6.05e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1394495.375\n",
      "Final accumulative portfolio value: 1.394495375\n",
      "Maximum DrawDown: -0.5211357091819904\n",
      "Sharpe ratio: 0.2902303410444359\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 49.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 2594       |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -193       |\n",
      "|    explained_variance | -187       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19299      |\n",
      "|    policy_loss        | -6.05      |\n",
      "|    reward             | 0.07822841 |\n",
      "|    std                | 84.6       |\n",
      "|    value_loss         | 0.00305    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2621        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -194        |\n",
      "|    explained_variance | -6.89       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -11.5       |\n",
      "|    reward             | 0.029237065 |\n",
      "|    std                | 86.2        |\n",
      "|    value_loss         | 0.00416     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2649        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -195        |\n",
      "|    explained_variance | -962        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | 0.020634752 |\n",
      "|    std                | 88.3        |\n",
      "|    value_loss         | 0.000265    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 49.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 2677       |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -196       |\n",
      "|    explained_variance | -25.7      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19599      |\n",
      "|    policy_loss        | 1.85       |\n",
      "|    reward             | 0.02224048 |\n",
      "|    std                | 91.2       |\n",
      "|    value_loss         | 0.000168   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1488549.375\n",
      "Final accumulative portfolio value: 1.488549375\n",
      "Maximum DrawDown: -0.5291455923625802\n",
      "Sharpe ratio: 0.32161475891810215\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 49.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 2706       |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -197       |\n",
      "|    explained_variance | -1.58e+03  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19699      |\n",
      "|    policy_loss        | 33.7       |\n",
      "|    reward             | 0.08542779 |\n",
      "|    std                | 93.7       |\n",
      "|    value_loss         | 0.0322     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2734        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -197        |\n",
      "|    explained_variance | -40.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | -3.03       |\n",
      "|    reward             | 0.029529683 |\n",
      "|    std                | 95.4        |\n",
      "|    value_loss         | 0.000751    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2763        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -198        |\n",
      "|    explained_variance | -24.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -2.92       |\n",
      "|    reward             | 0.026634255 |\n",
      "|    std                | 97.6        |\n",
      "|    value_loss         | 0.000322    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2791        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -199        |\n",
      "|    explained_variance | -81.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 0.0647      |\n",
      "|    reward             | 0.029025435 |\n",
      "|    std                | 101         |\n",
      "|    value_loss         | 5.67e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 645269.3125\n",
      "Final accumulative portfolio value: 0.6452693125\n",
      "Maximum DrawDown: -0.5032510571122513\n",
      "Sharpe ratio: -0.5723778417489891\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "recession_result_dax_sortino = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession',reward_sortino=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_30\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1772771.125\n",
      "Final accumulative portfolio value: 1.772771125\n",
      "Maximum DrawDown: -0.4971671873416902\n",
      "Sharpe ratio: 0.4053166203272813\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 2.01e+03     |\n",
      "|    ep_rew_mean     | 0.568        |\n",
      "| time/              |              |\n",
      "|    fps             | 45           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 45           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0007451379 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1691494.375\n",
      "Final accumulative portfolio value: 1.691494375\n",
      "Maximum DrawDown: -0.44469747342514865\n",
      "Sharpe ratio: 0.3835085886737895\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.545       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008879187 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | -3.47       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.529      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    reward               | 0.007180243 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1534286.0\n",
      "Final accumulative portfolio value: 1.534286\n",
      "Maximum DrawDown: -0.5219145234997196\n",
      "Sharpe ratio: 0.33581910755650207\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.504       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01092143  |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | -0.0934     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.528      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    reward               | 0.003272775 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1660690.5\n",
      "Final accumulative portfolio value: 1.6606905\n",
      "Maximum DrawDown: -0.47509472082835535\n",
      "Sharpe ratio: 0.37439338072066297\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.504         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 186           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0110751735  |\n",
      "|    clip_fraction        | 0.0814        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47           |\n",
      "|    explained_variance   | 0.0247        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.527        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.0341       |\n",
      "|    reward               | -0.0021271664 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00169       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1739436.75\n",
      "Final accumulative portfolio value: 1.73943675\n",
      "Maximum DrawDown: -0.46669654925727966\n",
      "Sharpe ratio: 0.39576133685725146\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.513         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 229           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0110668475  |\n",
      "|    clip_fraction        | 0.0903        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.1         |\n",
      "|    explained_variance   | 0.0562        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.522        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.0352       |\n",
      "|    reward               | -0.0062101996 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.00162       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2044181.0\n",
      "Final accumulative portfolio value: 2.044181\n",
      "Maximum DrawDown: -0.44989446920956977\n",
      "Sharpe ratio: 0.4729970494849138\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.545        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011305646  |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.1        |\n",
      "|    explained_variance   | 0.0735       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.519       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0347      |\n",
      "|    reward               | 0.0029529799 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00163      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1331780.0\n",
      "Final accumulative portfolio value: 1.33178\n",
      "Maximum DrawDown: -0.5400767157289454\n",
      "Sharpe ratio: 0.2677520889054005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.508       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011663672 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    reward               | 0.027768454 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00162     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1894347.75\n",
      "Final accumulative portfolio value: 1.89434775\n",
      "Maximum DrawDown: -0.4520678152036278\n",
      "Sharpe ratio: 0.4371566839170398\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.523       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012580321 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0813      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.546      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    reward               | 0.04133486  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00166     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1874665.0\n",
      "Final accumulative portfolio value: 1.874665\n",
      "Maximum DrawDown: -0.48769092891657284\n",
      "Sharpe ratio: 0.43154236737591195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.534       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013727951 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.0755      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.534      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    reward               | 0.014683397 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00165     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1767683.75\n",
      "Final accumulative portfolio value: 1.76768375\n",
      "Maximum DrawDown: -0.4673572362231214\n",
      "Sharpe ratio: 0.4032729931852846\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.538        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012028182  |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | 0.0914       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.535       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    reward               | 0.0152575495 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1476574.625\n",
      "Final accumulative portfolio value: 1.476574625\n",
      "Maximum DrawDown: -0.5243496642928689\n",
      "Sharpe ratio: 0.317275765560771\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.524        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01167099   |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.5        |\n",
      "|    explained_variance   | 0.0853       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.547       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0379      |\n",
      "|    reward               | 0.0063445345 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00165      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1773978.375\n",
      "Final accumulative portfolio value: 1.773978375\n",
      "Maximum DrawDown: -0.4534257428966423\n",
      "Sharpe ratio: 0.40563575912582506\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.527        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 546          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011637753  |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.6        |\n",
      "|    explained_variance   | 0.0889       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.545       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    reward               | -0.008972966 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00161      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1938037.25\n",
      "Final accumulative portfolio value: 1.93803725\n",
      "Maximum DrawDown: -0.42996593314143217\n",
      "Sharpe ratio: 0.4476806296181868\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.537       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012264011 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.0969      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.531      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | -0.02914002 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1676848.0\n",
      "Final accumulative portfolio value: 1.676848\n",
      "Maximum DrawDown: -0.50122110701389\n",
      "Sharpe ratio: 0.377630719601962\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013301633 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.54       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    reward               | 0.029570581 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1636886.125\n",
      "Final accumulative portfolio value: 1.636886125\n",
      "Maximum DrawDown: -0.5023427066137451\n",
      "Sharpe ratio: 0.3667844020875771\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.532        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 680          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015573733  |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.8        |\n",
      "|    explained_variance   | 0.0905       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.538       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0433      |\n",
      "|    reward               | -0.004736537 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00167      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1613523.875\n",
      "Final accumulative portfolio value: 1.613523875\n",
      "Maximum DrawDown: -0.520879777961742\n",
      "Sharpe ratio: 0.3601933046410942\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.529       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014462376 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    reward               | -0.01514376 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2221962.25\n",
      "Final accumulative portfolio value: 2.22196225\n",
      "Maximum DrawDown: -0.4408445083978434\n",
      "Sharpe ratio: 0.5130271210705145\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.544         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 768           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013626607   |\n",
      "|    clip_fraction        | 0.125         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48           |\n",
      "|    explained_variance   | 0.0896        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.544        |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0434       |\n",
      "|    reward               | -0.0026105114 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.00163       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1930599.25\n",
      "Final accumulative portfolio value: 1.93059925\n",
      "Maximum DrawDown: -0.47327899400665574\n",
      "Sharpe ratio: 0.4446238892451206\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014682657 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    reward               | 0.027894825 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00176     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2034586.375\n",
      "Final accumulative portfolio value: 2.034586375\n",
      "Maximum DrawDown: -0.4128863750768509\n",
      "Sharpe ratio: 0.4718357620372218\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.558        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 856          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013547683  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.1        |\n",
      "|    explained_variance   | 0.0915       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.552       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0437      |\n",
      "|    reward               | -0.014867308 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1464234.875\n",
      "Final accumulative portfolio value: 1.464234875\n",
      "Maximum DrawDown: -0.4962413647197055\n",
      "Sharpe ratio: 0.3135526577345751\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.549         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 899           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012981952   |\n",
      "|    clip_fraction        | 0.113         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.1         |\n",
      "|    explained_variance   | 0.0966        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.54         |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.0421       |\n",
      "|    reward               | -0.0047275536 |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 0.00149       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1825930.0\n",
      "Final accumulative portfolio value: 1.82593\n",
      "Maximum DrawDown: -0.46008492962708847\n",
      "Sharpe ratio: 0.4185263473396289\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.551        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 946          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012149233  |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.2        |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.55        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0422      |\n",
      "|    reward               | 0.0011522089 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00163      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1799287.625\n",
      "Final accumulative portfolio value: 1.799287625\n",
      "Maximum DrawDown: -0.4688434196607455\n",
      "Sharpe ratio: 0.41290894909333714\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.553        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 991          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013522364  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.3        |\n",
      "|    explained_variance   | 0.091        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.558       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    reward               | -0.024679516 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00163      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1348030.0\n",
      "Final accumulative portfolio value: 1.34803\n",
      "Maximum DrawDown: -0.5386190809088018\n",
      "Sharpe ratio: 0.27356746570186863\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.542       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013678058 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    reward               | 0.04589653  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00164     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1994227.625\n",
      "Final accumulative portfolio value: 1.994227625\n",
      "Maximum DrawDown: -0.4433348153631186\n",
      "Sharpe ratio: 0.4612172800782459\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.547        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013375535  |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.5        |\n",
      "|    explained_variance   | 0.0987       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.546       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0451      |\n",
      "|    reward               | -0.041250084 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00168      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2001192.875\n",
      "Final accumulative portfolio value: 2.001192875\n",
      "Maximum DrawDown: -0.4643457268866905\n",
      "Sharpe ratio: 0.4618122352311439\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.553        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1128         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014078395  |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.6        |\n",
      "|    explained_variance   | 0.089        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.545       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0455      |\n",
      "|    reward               | -0.015768459 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00166      |\n",
      "------------------------------------------\n",
      "Logging to ./data/tb\\ppo_31\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1558720.25\n",
      "Final accumulative portfolio value: 1.55872025\n",
      "Maximum DrawDown: -0.5200822497173219\n",
      "Sharpe ratio: 0.3435500538109311\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 2.01e+03     |\n",
      "|    ep_rew_mean     | 0.44         |\n",
      "| time/              |              |\n",
      "|    fps             | 43           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 46           |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0037969893 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1481419.875\n",
      "Final accumulative portfolio value: 1.481419875\n",
      "Maximum DrawDown: -0.530672300649145\n",
      "Sharpe ratio: 0.31890722795263454\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.413       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016258253 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0922      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    reward               | 0.010593136 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00168     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1602791.625\n",
      "Final accumulative portfolio value: 1.602791625\n",
      "Maximum DrawDown: -0.4927400099037875\n",
      "Sharpe ratio: 0.35700708421362687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.431        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014611494  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.8        |\n",
      "|    explained_variance   | 0.0909       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.569       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0464      |\n",
      "|    reward               | 0.0035181078 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.00167      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1839623.0\n",
      "Final accumulative portfolio value: 1.839623\n",
      "Maximum DrawDown: -0.48996113316567247\n",
      "Sharpe ratio: 0.42306992450091296\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.475         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 44            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 182           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01352719    |\n",
      "|    clip_fraction        | 0.129         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.9         |\n",
      "|    explained_variance   | 0.0967        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.557        |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.0453       |\n",
      "|    reward               | -0.0018566787 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.00159       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1981268.125\n",
      "Final accumulative portfolio value: 1.981268125\n",
      "Maximum DrawDown: -0.47016065742038204\n",
      "Sharpe ratio: 0.45801473800813103\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 0.516         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01225656    |\n",
      "|    clip_fraction        | 0.114         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49           |\n",
      "|    explained_variance   | 0.0973        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.553        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.0443       |\n",
      "|    reward               | -0.0075814696 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.00165       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1550600.625\n",
      "Final accumulative portfolio value: 1.550600625\n",
      "Maximum DrawDown: -0.5000924961957807\n",
      "Sharpe ratio: 0.3408922788795205\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.502        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013955527  |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49          |\n",
      "|    explained_variance   | 0.0941       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.565       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0461      |\n",
      "|    reward               | 0.0021073055 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.00161      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1984005.0\n",
      "Final accumulative portfolio value: 1.984005\n",
      "Maximum DrawDown: -0.4379071877462565\n",
      "Sharpe ratio: 0.4599575072716254\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.528       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014286159 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    reward               | 0.02532135  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1608082.625\n",
      "Final accumulative portfolio value: 1.608082625\n",
      "Maximum DrawDown: -0.49221795590397244\n",
      "Sharpe ratio: 0.35812267568912265\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013780441 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0987      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0441     |\n",
      "|    reward               | 0.02497458  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1528061.25\n",
      "Final accumulative portfolio value: 1.52806125\n",
      "Maximum DrawDown: -0.5188199150730078\n",
      "Sharpe ratio: 0.3342496483974611\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016372595 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0845      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.573      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    reward               | 0.015401949 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00166     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1619767.5\n",
      "Final accumulative portfolio value: 1.6197675\n",
      "Maximum DrawDown: -0.5047944391630278\n",
      "Sharpe ratio: 0.3620326648398058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.506       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014815293 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.564      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    reward               | 0.014109029 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00165     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1595560.875\n",
      "Final accumulative portfolio value: 1.595560875\n",
      "Maximum DrawDown: -0.5002690617593661\n",
      "Sharpe ratio: 0.35469503782337475\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.502       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014058407 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.097       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    reward               | 0.007953048 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1656281.75\n",
      "Final accumulative portfolio value: 1.65628175\n",
      "Maximum DrawDown: -0.47551071044893356\n",
      "Sharpe ratio: 0.3727402536868662\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.502        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 552          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155780865 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.3        |\n",
      "|    explained_variance   | 0.0882       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.576       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0497      |\n",
      "|    reward               | -0.008601357 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1448429.875\n",
      "Final accumulative portfolio value: 1.448429875\n",
      "Maximum DrawDown: -0.5389030665620294\n",
      "Sharpe ratio: 0.3083967185253334\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.491        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 599          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015512255  |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.4        |\n",
      "|    explained_variance   | 0.0898       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.566       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0472      |\n",
      "|    reward               | -0.019023517 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.00169      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1575976.75\n",
      "Final accumulative portfolio value: 1.57597675\n",
      "Maximum DrawDown: -0.5199401489953103\n",
      "Sharpe ratio: 0.34903470943026577\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.488       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01612521  |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0999      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    reward               | 0.022261139 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00162     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1604971.75\n",
      "Final accumulative portfolio value: 1.60497175\n",
      "Maximum DrawDown: -0.5200016873348225\n",
      "Sharpe ratio: 0.35728246317441587\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.487        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015541662  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.5        |\n",
      "|    explained_variance   | 0.09         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.563       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0508      |\n",
      "|    reward               | -0.004334233 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00171      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1608052.25\n",
      "Final accumulative portfolio value: 1.60805225\n",
      "Maximum DrawDown: -0.473230440685381\n",
      "Sharpe ratio: 0.3580925971088226\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.486        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 738          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015347365  |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.6        |\n",
      "|    explained_variance   | 0.0904       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.572       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0494      |\n",
      "|    reward               | -0.014806812 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00162      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1749765.0\n",
      "Final accumulative portfolio value: 1.749765\n",
      "Maximum DrawDown: -0.4600197644009275\n",
      "Sharpe ratio: 0.39804189722604383\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 785         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016933322 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    reward               | -0.00432214 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1424498.625\n",
      "Final accumulative portfolio value: 1.424498625\n",
      "Maximum DrawDown: -0.474321380254735\n",
      "Sharpe ratio: 0.30000657066768505\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.482       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015799847 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    reward               | 0.02475376  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.00167     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1781972.5\n",
      "Final accumulative portfolio value: 1.7819725\n",
      "Maximum DrawDown: -0.45975056808213655\n",
      "Sharpe ratio: 0.4080723239286765\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.487        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 874          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014530437  |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.0899       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.573       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.048       |\n",
      "|    reward               | -0.015679272 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00153      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1654559.625\n",
      "Final accumulative portfolio value: 1.654559625\n",
      "Maximum DrawDown: -0.4820803499883891\n",
      "Sharpe ratio: 0.3723759099331602\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.488        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 920          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014831893  |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.0982       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.557       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0476      |\n",
      "|    reward               | -0.006473828 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.00156      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1763068.75\n",
      "Final accumulative portfolio value: 1.76306875\n",
      "Maximum DrawDown: -0.48230840635293126\n",
      "Sharpe ratio: 0.40305125522395396\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.491        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015250718  |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.8        |\n",
      "|    explained_variance   | 0.0949       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.568       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0488      |\n",
      "|    reward               | -0.004247734 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1898409.25\n",
      "Final accumulative portfolio value: 1.89840925\n",
      "Maximum DrawDown: -0.4937479767389107\n",
      "Sharpe ratio: 0.4374788000938323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.498       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1015        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015139303 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    reward               | -0.02506546 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00178     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1826077.375\n",
      "Final accumulative portfolio value: 1.826077375\n",
      "Maximum DrawDown: -0.4655951264273498\n",
      "Sharpe ratio: 0.4189881323831445\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 0.502       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1060        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015254964 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.584      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    reward               | 0.04912089  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00177     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1812992.5\n",
      "Final accumulative portfolio value: 1.8129925\n",
      "Maximum DrawDown: -0.49113668258070164\n",
      "Sharpe ratio: 0.41532281878495386\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.506        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1107         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154984435 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50          |\n",
      "|    explained_variance   | 0.0965       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.565       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0506      |\n",
      "|    reward               | -0.043689944 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1799196.375\n",
      "Final accumulative portfolio value: 1.799196375\n",
      "Maximum DrawDown: -0.4444558403250647\n",
      "Sharpe ratio: 0.4122366542140186\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 0.509        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1151         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013998859  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50          |\n",
      "|    explained_variance   | 0.0931       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.575       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0467      |\n",
      "|    reward               | -0.016625335 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.00165      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 644800.5625\n",
      "Final accumulative portfolio value: 0.6448005625\n",
      "Maximum DrawDown: -0.5106689952253207\n",
      "Sharpe ratio: -0.5589494045744952\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_24\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48          |\n",
      "|    explained_variance | -0.873       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | 0.385        |\n",
      "|    reward             | -0.026942488 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.000474     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 43        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.9     |\n",
      "|    explained_variance | -1.34     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.264    |\n",
      "|    reward             | 0.0382872 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.000739  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.8       |\n",
      "|    explained_variance | -2.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.502      |\n",
      "|    reward             | 0.009501357 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51          |\n",
      "|    explained_variance | 0.204        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 399          |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.002828601 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 2.13e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1523822.25\n",
      "Final accumulative portfolio value: 1.52382225\n",
      "Maximum DrawDown: -0.48290745369844756\n",
      "Sharpe ratio: 0.33345729968893334\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.416       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.4       |\n",
      "|    explained_variance | -2.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.523       |\n",
      "|    reward             | -0.03684184 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.00433     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.416        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53.4        |\n",
      "|    explained_variance | -0.962       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -1.52        |\n",
      "|    reward             | 0.0098463325 |\n",
      "|    std                | 1.22         |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.416         |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 81            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -54.4         |\n",
      "|    explained_variance | -0.404        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.527        |\n",
      "|    reward             | -0.0067134043 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 0.000177      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.416         |\n",
      "| time/                 |               |\n",
      "|    fps                | 43            |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.7         |\n",
      "|    explained_variance | -0.037        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.191         |\n",
      "|    reward             | -0.0011661294 |\n",
      "|    std                | 1.31          |\n",
      "|    value_loss         | 2.19e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1500477.0\n",
      "Final accumulative portfolio value: 1.500477\n",
      "Maximum DrawDown: -0.5006267502743882\n",
      "Sharpe ratio: 0.32529864398899083\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.408       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.1       |\n",
      "|    explained_variance | -0.511      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -3.25       |\n",
      "|    reward             | 0.024133721 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.00447     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.408         |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.2         |\n",
      "|    explained_variance | 0.353         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -1.61         |\n",
      "|    reward             | -0.0034570778 |\n",
      "|    std                | 1.41          |\n",
      "|    value_loss         | 0.000901      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.3        |\n",
      "|    explained_variance | -0.54        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.353       |\n",
      "|    reward             | -0.019574907 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 4.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.6        |\n",
      "|    explained_variance | -1.86        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.197        |\n",
      "|    reward             | 0.0024855216 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1643768.875\n",
      "Final accumulative portfolio value: 1.643768875\n",
      "Maximum DrawDown: -0.48540580216074336\n",
      "Sharpe ratio: 0.3695665190175739\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.436       |\n",
      "| time/                 |             |\n",
      "|    fps                | 41          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.9       |\n",
      "|    explained_variance | 0.69        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | -0.03958369 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 8.78e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.436        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -63.1        |\n",
      "|    explained_variance | -0.681       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 2.51         |\n",
      "|    reward             | 0.0023241434 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 0.00235      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.436         |\n",
      "| time/                 |               |\n",
      "|    fps                | 41            |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 179           |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -64.2         |\n",
      "|    explained_variance | 0.246         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 0.169         |\n",
      "|    reward             | -0.0011822415 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 3.55e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.436        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.5        |\n",
      "|    explained_variance | 0.0647       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | 0.0033820833 |\n",
      "|    std                | 1.76         |\n",
      "|    value_loss         | 6.02e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1564439.75\n",
      "Final accumulative portfolio value: 1.56443975\n",
      "Maximum DrawDown: -0.4838608064525517\n",
      "Sharpe ratio: 0.3454517735878737\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.8        |\n",
      "|    explained_variance | 0.271        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -2.89        |\n",
      "|    reward             | -0.011412828 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 0.00221      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.438       |\n",
      "| time/                 |             |\n",
      "|    fps                | 41          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68         |\n",
      "|    explained_variance | 0.605       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -0.0263     |\n",
      "|    reward             | 0.030003686 |\n",
      "|    std                | 1.9         |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.1        |\n",
      "|    explained_variance | 0.0655       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.511        |\n",
      "|    reward             | -0.008181391 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.5        |\n",
      "|    explained_variance | 0.598        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.679       |\n",
      "|    reward             | -0.016340174 |\n",
      "|    std                | 2.05         |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1447240.0\n",
      "Final accumulative portfolio value: 1.44724\n",
      "Maximum DrawDown: -0.5453382315286615\n",
      "Sharpe ratio: 0.30820384613933355\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.9        |\n",
      "|    explained_variance | -0.0602      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 3.14         |\n",
      "|    reward             | -0.010759089 |\n",
      "|    std                | 2.14         |\n",
      "|    value_loss         | 0.00224      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.9        |\n",
      "|    explained_variance | -0.0638      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 4.14         |\n",
      "|    reward             | -0.033784498 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74          |\n",
      "|    explained_variance | -0.0577      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 1.59         |\n",
      "|    reward             | 0.0061628064 |\n",
      "|    std                | 2.28         |\n",
      "|    value_loss         | 0.000659     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 2.01e+03       |\n",
      "|    ep_rew_mean        | 0.423          |\n",
      "| time/                 |                |\n",
      "|    fps                | 41             |\n",
      "|    iterations         | 2400           |\n",
      "|    time_elapsed       | 287            |\n",
      "|    total_timesteps    | 12000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.3          |\n",
      "|    explained_variance | 0.0706         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2399           |\n",
      "|    policy_loss        | -0.0268        |\n",
      "|    reward             | -0.00065980264 |\n",
      "|    std                | 2.37           |\n",
      "|    value_loss         | 2.25e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1390549.25\n",
      "Final accumulative portfolio value: 1.39054925\n",
      "Maximum DrawDown: -0.5297611084702483\n",
      "Sharpe ratio: 0.28838475288892895\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.407       |\n",
      "| time/                 |             |\n",
      "|    fps                | 41          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.7       |\n",
      "|    explained_variance | 0.676       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 0.597       |\n",
      "|    reward             | 0.034632534 |\n",
      "|    std                | 2.48        |\n",
      "|    value_loss         | 0.000496    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.407         |\n",
      "| time/                 |               |\n",
      "|    fps                | 41            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 313           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -77.9         |\n",
      "|    explained_variance | 0.588         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -0.0858       |\n",
      "|    reward             | -0.0064060995 |\n",
      "|    std                | 2.56          |\n",
      "|    value_loss         | 0.000294      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.407       |\n",
      "| time/                 |             |\n",
      "|    fps                | 41          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -79         |\n",
      "|    explained_variance | -0.0792     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.0512      |\n",
      "|    reward             | 0.022964481 |\n",
      "|    std                | 2.65        |\n",
      "|    value_loss         | 3.82e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.407         |\n",
      "| time/                 |               |\n",
      "|    fps                | 41            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 336           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -80.3         |\n",
      "|    explained_variance | -1.7          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | 1.15          |\n",
      "|    reward             | -0.0033323793 |\n",
      "|    std                | 2.76          |\n",
      "|    value_loss         | 0.000308      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1734406.25\n",
      "Final accumulative portfolio value: 1.73440625\n",
      "Maximum DrawDown: -0.47967844857135256\n",
      "Sharpe ratio: 0.39400916000342295\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.426        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -81.8        |\n",
      "|    explained_variance | -0.65        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.564        |\n",
      "|    reward             | 0.0066858632 |\n",
      "|    std                | 2.88         |\n",
      "|    value_loss         | 0.000897     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.426        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -82.9        |\n",
      "|    explained_variance | 0.6          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 10.8         |\n",
      "|    reward             | -0.029255029 |\n",
      "|    std                | 2.99         |\n",
      "|    value_loss         | 0.0176       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.426       |\n",
      "| time/                 |             |\n",
      "|    fps                | 41          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84         |\n",
      "|    explained_variance | -0.766      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -1.67       |\n",
      "|    reward             | 0.009399919 |\n",
      "|    std                | 3.09        |\n",
      "|    value_loss         | 0.000586    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.426        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 381          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -85.3        |\n",
      "|    explained_variance | -0.709       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.133        |\n",
      "|    reward             | 0.0034735599 |\n",
      "|    std                | 3.22         |\n",
      "|    value_loss         | 7.2e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1878741.125\n",
      "Final accumulative portfolio value: 1.878741125\n",
      "Maximum DrawDown: -0.5048678963530298\n",
      "Sharpe ratio: 0.43371865824179123\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86.8        |\n",
      "|    explained_variance | 0.637        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.007898987 |\n",
      "|    std                | 3.36         |\n",
      "|    value_loss         | 0.000565     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.451       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -87.9       |\n",
      "|    explained_variance | -0.161      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -3.14       |\n",
      "|    reward             | 0.051627014 |\n",
      "|    std                | 3.48        |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -89          |\n",
      "|    explained_variance | -0.241       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.87         |\n",
      "|    reward             | -0.010726074 |\n",
      "|    std                | 3.6          |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -90.4        |\n",
      "|    explained_variance | -0.299       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.171        |\n",
      "|    reward             | -0.012714829 |\n",
      "|    std                | 3.75         |\n",
      "|    value_loss         | 5.96e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1279952.75\n",
      "Final accumulative portfolio value: 1.27995275\n",
      "Maximum DrawDown: -0.5296426024006845\n",
      "Sharpe ratio: 0.24853299697348918\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.428        |\n",
      "| time/                 |              |\n",
      "|    fps                | 41           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -91.8        |\n",
      "|    explained_variance | -1.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -3.32        |\n",
      "|    reward             | -0.017074328 |\n",
      "|    std                | 3.91         |\n",
      "|    value_loss         | 0.00175      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.428        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -93          |\n",
      "|    explained_variance | -0.831       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | -0.015644638 |\n",
      "|    std                | 4.05         |\n",
      "|    value_loss         | 0.000895     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.428         |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 461           |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -94.1         |\n",
      "|    explained_variance | -0.447        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 1.22          |\n",
      "|    reward             | -0.0007075786 |\n",
      "|    std                | 4.19          |\n",
      "|    value_loss         | 0.000245      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.428        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 472          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -95.4        |\n",
      "|    explained_variance | -0.0364      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 1.74         |\n",
      "|    reward             | -0.012665933 |\n",
      "|    std                | 4.37         |\n",
      "|    value_loss         | 0.00065      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1509526.125\n",
      "Final accumulative portfolio value: 1.509526125\n",
      "Maximum DrawDown: -0.49025048783506997\n",
      "Sharpe ratio: 0.3283945375509242\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.426        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 485          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -96.9        |\n",
      "|    explained_variance | -0.446       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -1.61        |\n",
      "|    reward             | -0.022737026 |\n",
      "|    std                | 4.56         |\n",
      "|    value_loss         | 0.000508     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.426        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 495          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -98          |\n",
      "|    explained_variance | 0.767        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 1.39         |\n",
      "|    reward             | -0.025982399 |\n",
      "|    std                | 4.72         |\n",
      "|    value_loss         | 0.000254     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.426       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 505         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.1       |\n",
      "|    explained_variance | 0.545       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 2.82        |\n",
      "|    reward             | 0.008038431 |\n",
      "|    std                | 4.87        |\n",
      "|    value_loss         | 0.000846    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.426       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -100        |\n",
      "|    explained_variance | -1.92       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | 0.023912717 |\n",
      "|    std                | 5.08        |\n",
      "|    value_loss         | 7.62e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1512736.375\n",
      "Final accumulative portfolio value: 1.512736375\n",
      "Maximum DrawDown: -0.5315189925323219\n",
      "Sharpe ratio: 0.32867885692090426\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.424        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -102         |\n",
      "|    explained_variance | -0.0996      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.939        |\n",
      "|    reward             | -0.006972604 |\n",
      "|    std                | 5.3          |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.424        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 540          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -103         |\n",
      "|    explained_variance | 0.532        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -3.91        |\n",
      "|    reward             | -0.037097897 |\n",
      "|    std                | 5.5          |\n",
      "|    value_loss         | 0.00162      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 2.01e+03       |\n",
      "|    ep_rew_mean        | 0.424          |\n",
      "| time/                 |                |\n",
      "|    fps                | 42             |\n",
      "|    iterations         | 4700           |\n",
      "|    time_elapsed       | 550            |\n",
      "|    total_timesteps    | 23500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -104           |\n",
      "|    explained_variance | -1.55          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4699           |\n",
      "|    policy_loss        | -0.208         |\n",
      "|    reward             | -0.00068592705 |\n",
      "|    std                | 5.69           |\n",
      "|    value_loss         | 9.14e-05       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 2.01e+03       |\n",
      "|    ep_rew_mean        | 0.424          |\n",
      "| time/                 |                |\n",
      "|    fps                | 42             |\n",
      "|    iterations         | 4800           |\n",
      "|    time_elapsed       | 560            |\n",
      "|    total_timesteps    | 24000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -106           |\n",
      "|    explained_variance | 0.351          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 4799           |\n",
      "|    policy_loss        | -1.18          |\n",
      "|    reward             | -0.00086559553 |\n",
      "|    std                | 5.93           |\n",
      "|    value_loss         | 0.000157       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1463165.25\n",
      "Final accumulative portfolio value: 1.46316525\n",
      "Maximum DrawDown: -0.48138832723733327\n",
      "Sharpe ratio: 0.31301897122962835\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 574         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | 0.556       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 2.02        |\n",
      "|    reward             | 0.007273385 |\n",
      "|    std                | 6.2         |\n",
      "|    value_loss         | 0.00041     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 585          |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -108         |\n",
      "|    explained_variance | 0.045        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | -0.0392      |\n",
      "|    reward             | -0.045092106 |\n",
      "|    std                | 6.41         |\n",
      "|    value_loss         | 0.000204     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 596          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -109         |\n",
      "|    explained_variance | 0.409        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | 1.24         |\n",
      "|    reward             | 0.0013217531 |\n",
      "|    std                | 6.63         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 608          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -110         |\n",
      "|    explained_variance | -0.029       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | 2.53         |\n",
      "|    reward             | 0.0018799505 |\n",
      "|    std                | 6.89         |\n",
      "|    value_loss         | 0.000499     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1482241.25\n",
      "Final accumulative portfolio value: 1.48224125\n",
      "Maximum DrawDown: -0.5019009461226129\n",
      "Sharpe ratio: 0.3195693166434838\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.418      |\n",
      "| time/                 |            |\n",
      "|    fps                | 42         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 623        |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -112       |\n",
      "|    explained_variance | -0.129     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 2.7        |\n",
      "|    reward             | 0.00425327 |\n",
      "|    std                | 7.2        |\n",
      "|    value_loss         | 0.000779   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.418       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 633         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -0.253      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 2.63        |\n",
      "|    reward             | 0.012366875 |\n",
      "|    std                | 7.46        |\n",
      "|    value_loss         | 0.000826    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.418       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 644         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | 0.18        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -0.922      |\n",
      "|    reward             | 0.022150377 |\n",
      "|    std                | 7.72        |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 656           |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -116          |\n",
      "|    explained_variance | 0.0446        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 0.613         |\n",
      "|    reward             | -0.0097502405 |\n",
      "|    std                | 8.05          |\n",
      "|    value_loss         | 7.3e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1633518.875\n",
      "Final accumulative portfolio value: 1.633518875\n",
      "Maximum DrawDown: -0.49623090221407073\n",
      "Sharpe ratio: 0.36662778726921896\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.423       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -117        |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | 0.011256757 |\n",
      "|    std                | 8.41        |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.423       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 680         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | 0.479       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -3.84       |\n",
      "|    reward             | -0.02304024 |\n",
      "|    std                | 8.73        |\n",
      "|    value_loss         | 0.00202     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 690          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -119         |\n",
      "|    explained_variance | 0.245        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.0982       |\n",
      "|    reward             | 0.0005648924 |\n",
      "|    std                | 9.04         |\n",
      "|    value_loss         | 9.71e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.423       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 701         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -121        |\n",
      "|    explained_variance | 0.455       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.52        |\n",
      "|    reward             | 0.021147834 |\n",
      "|    std                | 9.42        |\n",
      "|    value_loss         | 0.000109    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1453152.875\n",
      "Final accumulative portfolio value: 1.453152875\n",
      "Maximum DrawDown: -0.48701710646724516\n",
      "Sharpe ratio: 0.30980749688046627\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.419        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 714          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -122         |\n",
      "|    explained_variance | 0.518        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -3.96        |\n",
      "|    reward             | -0.001203665 |\n",
      "|    std                | 9.82         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.419        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 724          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -123         |\n",
      "|    explained_variance | 0.273        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -2.67        |\n",
      "|    reward             | -0.020192044 |\n",
      "|    std                | 10.2         |\n",
      "|    value_loss         | 0.00091      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.419       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | 0.000268    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | 0.019161362 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.000154    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.419       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 747         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | 0.0811      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -3.32       |\n",
      "|    reward             | 0.015768481 |\n",
      "|    std                | 11          |\n",
      "|    value_loss         | 0.000895    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1474122.625\n",
      "Final accumulative portfolio value: 1.474122625\n",
      "Maximum DrawDown: -0.5018557532778094\n",
      "Sharpe ratio: 0.31689069556607524\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 761          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -127         |\n",
      "|    explained_variance | 0.51         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 1.6          |\n",
      "|    reward             | -0.009889166 |\n",
      "|    std                | 11.5         |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.417      |\n",
      "| time/                 |            |\n",
      "|    fps                | 42         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 771        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -129       |\n",
      "|    explained_variance | 0.336      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | 0.429      |\n",
      "|    reward             | 0.03793365 |\n",
      "|    std                | 11.9       |\n",
      "|    value_loss         | 8.67e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.417       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 783         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -130        |\n",
      "|    explained_variance | -1.03       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -1.82       |\n",
      "|    reward             | 0.016122917 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.000325    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -131         |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -1.84        |\n",
      "|    reward             | -0.014716257 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.000309     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1531661.0\n",
      "Final accumulative portfolio value: 1.531661\n",
      "Maximum DrawDown: -0.5021192198938138\n",
      "Sharpe ratio: 0.334410364176256\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.417       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 809         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -133        |\n",
      "|    explained_variance | 0.843       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.014469339 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 8.98e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.417       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 820         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -134        |\n",
      "|    explained_variance | 0.106       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.010693393 |\n",
      "|    std                | 13.9        |\n",
      "|    value_loss         | 0.000644    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 830          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -135         |\n",
      "|    explained_variance | -0.151       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | -1.56        |\n",
      "|    reward             | 0.0059625604 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -136         |\n",
      "|    explained_variance | -0.204       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.112       |\n",
      "|    reward             | 0.0085443165 |\n",
      "|    std                | 15           |\n",
      "|    value_loss         | 3.82e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1614225.25\n",
      "Final accumulative portfolio value: 1.61422525\n",
      "Maximum DrawDown: -0.5139570660056194\n",
      "Sharpe ratio: 0.3593442439094912\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 854         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | 0.402       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 0.085       |\n",
      "|    reward             | 0.025149316 |\n",
      "|    std                | 15.7        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 864          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -139         |\n",
      "|    explained_variance | -0.957       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -1.51        |\n",
      "|    reward             | 0.0123559255 |\n",
      "|    std                | 16.2         |\n",
      "|    value_loss         | 0.00077      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 874         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | -0.516      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | 0.42        |\n",
      "|    reward             | 0.008186831 |\n",
      "|    std                | 16.8        |\n",
      "|    value_loss         | 9.71e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.42          |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 886           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -141          |\n",
      "|    explained_variance | -0.68         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | 1.23          |\n",
      "|    reward             | -0.0071248906 |\n",
      "|    std                | 17.5          |\n",
      "|    value_loss         | 0.000224      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1523188.5\n",
      "Final accumulative portfolio value: 1.5231885\n",
      "Maximum DrawDown: -0.4928167865293327\n",
      "Sharpe ratio: 0.3321818640890689\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 901          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -143         |\n",
      "|    explained_variance | -0.0977      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | -0.721       |\n",
      "|    reward             | -0.020481288 |\n",
      "|    std                | 18.3         |\n",
      "|    value_loss         | 0.000145     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 912         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -144        |\n",
      "|    explained_variance | 0.175       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 2.68        |\n",
      "|    reward             | 0.015895085 |\n",
      "|    std                | 18.9        |\n",
      "|    value_loss         | 0.000405    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 922          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -145         |\n",
      "|    explained_variance | 0.342        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.185       |\n",
      "|    reward             | 0.0016287408 |\n",
      "|    std                | 19.6         |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.42          |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 933           |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -146          |\n",
      "|    explained_variance | 0.275         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | -0.863        |\n",
      "|    reward             | -0.0078497855 |\n",
      "|    std                | 20.4          |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1430199.25\n",
      "Final accumulative portfolio value: 1.43019925\n",
      "Maximum DrawDown: -0.5145893407521085\n",
      "Sharpe ratio: 0.30203316147813275\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.417       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 946         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -148        |\n",
      "|    explained_variance | 0.0267      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 1.93        |\n",
      "|    reward             | 0.019960724 |\n",
      "|    std                | 21.3        |\n",
      "|    value_loss         | 0.000836    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 957          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -149         |\n",
      "|    explained_variance | -0.0302      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -5.26        |\n",
      "|    reward             | -0.011994845 |\n",
      "|    std                | 22.1         |\n",
      "|    value_loss         | 0.0015       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.417        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 968          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -150         |\n",
      "|    explained_variance | 0.619        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 1.15         |\n",
      "|    reward             | 0.0014753183 |\n",
      "|    std                | 22.9         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.417         |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 980           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -151          |\n",
      "|    explained_variance | -0.318        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | -1.45         |\n",
      "|    reward             | -0.0031427601 |\n",
      "|    std                | 23.8          |\n",
      "|    value_loss         | 0.000229      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1640307.875\n",
      "Final accumulative portfolio value: 1.640307875\n",
      "Maximum DrawDown: -0.47575242872432544\n",
      "Sharpe ratio: 0.3677293539695969\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.42       |\n",
      "| time/                 |            |\n",
      "|    fps                | 42         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 993        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -153       |\n",
      "|    explained_variance | 0.0524     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -4.52      |\n",
      "|    reward             | 0.04022909 |\n",
      "|    std                | 24.9       |\n",
      "|    value_loss         | 0.0015     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 1004        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | -2.35       |\n",
      "|    reward             | 0.004221457 |\n",
      "|    std                | 25.8        |\n",
      "|    value_loss         | 0.000315    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 1015        |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -155        |\n",
      "|    explained_variance | -0.407      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -0.00569    |\n",
      "|    reward             | 0.008990757 |\n",
      "|    std                | 26.7        |\n",
      "|    value_loss         | 3.03e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 1025         |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -157         |\n",
      "|    explained_variance | 0.519        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -2.2         |\n",
      "|    reward             | -0.016002946 |\n",
      "|    std                | 27.8         |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1638018.5\n",
      "Final accumulative portfolio value: 1.6380185\n",
      "Maximum DrawDown: -0.5202794511845386\n",
      "Sharpe ratio: 0.3672309121295924\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 1038         |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -158         |\n",
      "|    explained_variance | 0.294        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 3.13         |\n",
      "|    reward             | -0.025987167 |\n",
      "|    std                | 29.1         |\n",
      "|    value_loss         | 0.000503     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.423       |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 1048        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -159        |\n",
      "|    explained_variance | 0.5         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 4.47        |\n",
      "|    reward             | 0.008129129 |\n",
      "|    std                | 30.2        |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.423      |\n",
      "| time/                 |            |\n",
      "|    fps                | 42         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 1059       |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -160       |\n",
      "|    explained_variance | 0.205      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | 0.927      |\n",
      "|    reward             | 0.00803997 |\n",
      "|    std                | 31.2       |\n",
      "|    value_loss         | 4.98e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.423        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -162         |\n",
      "|    explained_variance | -0.633       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 1.53         |\n",
      "|    reward             | -0.009036718 |\n",
      "|    std                | 32.5         |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1429713.0\n",
      "Final accumulative portfolio value: 1.429713\n",
      "Maximum DrawDown: -0.5017656896949123\n",
      "Sharpe ratio: 0.30238481057651573\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.42          |\n",
      "| time/                 |               |\n",
      "|    fps                | 42            |\n",
      "|    iterations         | 9300          |\n",
      "|    time_elapsed       | 1083          |\n",
      "|    total_timesteps    | 46500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -163          |\n",
      "|    explained_variance | -0.0832       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9299          |\n",
      "|    policy_loss        | -3.45         |\n",
      "|    reward             | -0.0010849757 |\n",
      "|    std                | 34            |\n",
      "|    value_loss         | 0.000966      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.42        |\n",
      "| time/                 |             |\n",
      "|    fps                | 42          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 1093        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | 0.28        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -9.48       |\n",
      "|    reward             | 0.032055233 |\n",
      "|    std                | 35.3        |\n",
      "|    value_loss         | 0.00383     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.42         |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 1103         |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -165         |\n",
      "|    explained_variance | 0.128        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | -6.22        |\n",
      "|    reward             | 0.0016196956 |\n",
      "|    std                | 36.5         |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.42          |\n",
      "| time/                 |               |\n",
      "|    fps                | 43            |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 1115          |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -167          |\n",
      "|    explained_variance | 0.446         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9599          |\n",
      "|    policy_loss        | -1.05         |\n",
      "|    reward             | -0.0030653323 |\n",
      "|    std                | 38            |\n",
      "|    value_loss         | 6.76e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1465082.75\n",
      "Final accumulative portfolio value: 1.46508275\n",
      "Maximum DrawDown: -0.5267087635565716\n",
      "Sharpe ratio: 0.3141786442595781\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.418        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 1130         |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -168         |\n",
      "|    explained_variance | 0.0746       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 2.17         |\n",
      "|    reward             | -0.029232321 |\n",
      "|    std                | 39.8         |\n",
      "|    value_loss         | 0.000478     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.418        |\n",
      "| time/                 |              |\n",
      "|    fps                | 42           |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 1140         |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -170         |\n",
      "|    explained_variance | 0.188        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -7.33        |\n",
      "|    reward             | -0.020478733 |\n",
      "|    std                | 41.4         |\n",
      "|    value_loss         | 0.00206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.418        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 1149         |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -171         |\n",
      "|    explained_variance | 0.344        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -1.92        |\n",
      "|    reward             | -0.011406197 |\n",
      "|    std                | 42.9         |\n",
      "|    value_loss         | 0.000196     |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/              |                 |\n",
      "|    ep_len_mean        | 2.01e+03        |\n",
      "|    ep_rew_mean        | 0.418           |\n",
      "| time/                 |                 |\n",
      "|    fps                | 43              |\n",
      "|    iterations         | 10000           |\n",
      "|    time_elapsed       | 1159            |\n",
      "|    total_timesteps    | 50000           |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -172            |\n",
      "|    explained_variance | -0.898          |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 9999            |\n",
      "|    policy_loss        | -0.89           |\n",
      "|    reward             | -0.000106996056 |\n",
      "|    std                | 44.7            |\n",
      "|    value_loss         | 5.34e-05        |\n",
      "-------------------------------------------\n",
      "Logging to ./data/tb\\a2c_25\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 51          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | 0.528       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | 3.22        |\n",
      "|    reward             | -0.02893477 |\n",
      "|    std                | 46.5        |\n",
      "|    value_loss         | 0.000507    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 51          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -175        |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | 0.035852738 |\n",
      "|    std                | 48.1        |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 51          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -1.63       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -2.26       |\n",
      "|    reward             | 0.009576689 |\n",
      "|    std                | 49.8        |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 51           |\n",
      "|    iterations         | 400          |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 2000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -177         |\n",
      "|    explained_variance | -0.179       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | -0.477       |\n",
      "|    reward             | -0.002462257 |\n",
      "|    std                | 51.9         |\n",
      "|    value_loss         | 1.61e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1506958.0\n",
      "Final accumulative portfolio value: 1.506958\n",
      "Maximum DrawDown: -0.4640006249268792\n",
      "Sharpe ratio: 0.32701081556821077\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.405       |\n",
      "| time/                 |             |\n",
      "|    fps                | 48          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -179        |\n",
      "|    explained_variance | 0.47        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 1.46        |\n",
      "|    reward             | -0.03316816 |\n",
      "|    std                | 54.3        |\n",
      "|    value_loss         | 0.000578    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.405       |\n",
      "| time/                 |             |\n",
      "|    fps                | 48          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -0.128      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -3.84       |\n",
      "|    reward             | 0.008216271 |\n",
      "|    std                | 56.3        |\n",
      "|    value_loss         | 0.000664    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.405         |\n",
      "| time/                 |               |\n",
      "|    fps                | 49            |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -181          |\n",
      "|    explained_variance | -0.161        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10699         |\n",
      "|    policy_loss        | -1.3          |\n",
      "|    reward             | -0.0051079085 |\n",
      "|    std                | 58.4          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 2.01e+03       |\n",
      "|    ep_rew_mean        | 0.405          |\n",
      "| time/                 |                |\n",
      "|    fps                | 49             |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 80             |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -182           |\n",
      "|    explained_variance | 0.0619         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 10799          |\n",
      "|    policy_loss        | 0.406          |\n",
      "|    reward             | -0.00072630786 |\n",
      "|    std                | 61             |\n",
      "|    value_loss         | 1.58e-05       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1516089.25\n",
      "Final accumulative portfolio value: 1.51608925\n",
      "Maximum DrawDown: -0.5225743384062266\n",
      "Sharpe ratio: 0.3305585050331039\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.408      |\n",
      "| time/                 |            |\n",
      "|    fps                | 47         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 94         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -184       |\n",
      "|    explained_variance | -0.38      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -6.75      |\n",
      "|    reward             | 0.03699954 |\n",
      "|    std                | 63.7       |\n",
      "|    value_loss         | 0.00251    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.408         |\n",
      "| time/                 |               |\n",
      "|    fps                | 48            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 104           |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -185          |\n",
      "|    explained_variance | 0.456         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10999         |\n",
      "|    policy_loss        | -4.33         |\n",
      "|    reward             | -0.0043976298 |\n",
      "|    std                | 66.1          |\n",
      "|    value_loss         | 0.000691      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 48           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -186         |\n",
      "|    explained_variance | -5.64        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -0.874       |\n",
      "|    reward             | -0.019948428 |\n",
      "|    std                | 68.4         |\n",
      "|    value_loss         | 6.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 48           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -188         |\n",
      "|    explained_variance | -0.914       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | 1.79         |\n",
      "|    reward             | 0.0006580572 |\n",
      "|    std                | 71.3         |\n",
      "|    value_loss         | 9.23e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1475084.625\n",
      "Final accumulative portfolio value: 1.475084625\n",
      "Maximum DrawDown: -0.501521601465578\n",
      "Sharpe ratio: 0.3168529511627787\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.4          |\n",
      "| time/                 |              |\n",
      "|    fps                | 47           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -189         |\n",
      "|    explained_variance | 0.531        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | -3.02        |\n",
      "|    reward             | -0.044315856 |\n",
      "|    std                | 74.5         |\n",
      "|    value_loss         | 0.000326     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.4         |\n",
      "| time/                 |             |\n",
      "|    fps                | 47          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -190        |\n",
      "|    explained_variance | -0.208      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 5.82        |\n",
      "|    reward             | 0.006395942 |\n",
      "|    std                | 77.1        |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.4          |\n",
      "| time/                 |              |\n",
      "|    fps                | 48           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -191         |\n",
      "|    explained_variance | 0.178        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | 1.49         |\n",
      "|    reward             | -0.001426641 |\n",
      "|    std                | 79.8         |\n",
      "|    value_loss         | 9.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.4         |\n",
      "| time/                 |             |\n",
      "|    fps                | 48          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -193        |\n",
      "|    explained_variance | 0.695       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | 0.711       |\n",
      "|    reward             | 0.003912771 |\n",
      "|    std                | 83.3        |\n",
      "|    value_loss         | 2.63e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1598322.625\n",
      "Final accumulative portfolio value: 1.598322625\n",
      "Maximum DrawDown: -0.5128491735641365\n",
      "Sharpe ratio: 0.35505853464350406\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.416         |\n",
      "| time/                 |               |\n",
      "|    fps                | 47            |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 180           |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -194          |\n",
      "|    explained_variance | 0.324         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11699         |\n",
      "|    policy_loss        | -5.85         |\n",
      "|    reward             | -0.0040919944 |\n",
      "|    std                | 87            |\n",
      "|    value_loss         | 0.00141       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.416       |\n",
      "| time/                 |             |\n",
      "|    fps                | 47          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -195        |\n",
      "|    explained_variance | 0.641       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | -0.0245     |\n",
      "|    reward             | 0.032191455 |\n",
      "|    std                | 90.1        |\n",
      "|    value_loss         | 0.000271    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.416        |\n",
      "| time/                 |              |\n",
      "|    fps                | 47           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -196         |\n",
      "|    explained_variance | -0.502       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | 2.21         |\n",
      "|    reward             | -0.007549879 |\n",
      "|    std                | 93.3         |\n",
      "|    value_loss         | 0.00027      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.416        |\n",
      "| time/                 |              |\n",
      "|    fps                | 47           |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -198         |\n",
      "|    explained_variance | 0.721        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | -1.45        |\n",
      "|    reward             | -0.014729202 |\n",
      "|    std                | 97.2         |\n",
      "|    value_loss         | 7.9e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1490298.75\n",
      "Final accumulative portfolio value: 1.49029875\n",
      "Maximum DrawDown: -0.5304516080130706\n",
      "Sharpe ratio: 0.32174433262371527\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.411         |\n",
      "| time/                 |               |\n",
      "|    fps                | 46            |\n",
      "|    iterations         | 2100          |\n",
      "|    time_elapsed       | 224           |\n",
      "|    total_timesteps    | 10500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -199          |\n",
      "|    explained_variance | 0.0592        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12099         |\n",
      "|    policy_loss        | 6.38          |\n",
      "|    reward             | -0.0046577877 |\n",
      "|    std                | 101           |\n",
      "|    value_loss         | 0.00133       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.411        |\n",
      "| time/                 |              |\n",
      "|    fps                | 46           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 234          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -200         |\n",
      "|    explained_variance | -0.609       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | 7.33         |\n",
      "|    reward             | -0.029992158 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 0.00176      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.411       |\n",
      "| time/                 |             |\n",
      "|    fps                | 47          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -201        |\n",
      "|    explained_variance | -0.122      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 3.62        |\n",
      "|    reward             | 0.006434319 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.000569    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.411         |\n",
      "| time/                 |               |\n",
      "|    fps                | 47            |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 254           |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -203          |\n",
      "|    explained_variance | 0.0545        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12399         |\n",
      "|    policy_loss        | -0.307        |\n",
      "|    reward             | -0.0006424464 |\n",
      "|    std                | 113           |\n",
      "|    value_loss         | 3.05e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1697675.0\n",
      "Final accumulative portfolio value: 1.697675\n",
      "Maximum DrawDown: -0.5061713265732151\n",
      "Sharpe ratio: 0.38407298693452147\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.43        |\n",
      "| time/                 |             |\n",
      "|    fps                | 46          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -204        |\n",
      "|    explained_variance | 0.648       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | 0.173       |\n",
      "|    reward             | 0.031120468 |\n",
      "|    std                | 118         |\n",
      "|    value_loss         | 0.000531    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.43          |\n",
      "| time/                 |               |\n",
      "|    fps                | 46            |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 277           |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -205          |\n",
      "|    explained_variance | 0.685         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | -1.45         |\n",
      "|    reward             | -0.0041593267 |\n",
      "|    std                | 123           |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.43        |\n",
      "| time/                 |             |\n",
      "|    fps                | 46          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -207        |\n",
      "|    explained_variance | 0.229       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 0.665       |\n",
      "|    reward             | 0.024894118 |\n",
      "|    std                | 127         |\n",
      "|    value_loss         | 7.1e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.43          |\n",
      "| time/                 |               |\n",
      "|    fps                | 46            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 300           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -208          |\n",
      "|    explained_variance | -1.33         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12799         |\n",
      "|    policy_loss        | 2.77          |\n",
      "|    reward             | -0.0034600084 |\n",
      "|    std                | 133           |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1569625.0\n",
      "Final accumulative portfolio value: 1.569625\n",
      "Maximum DrawDown: -0.48661344587214905\n",
      "Sharpe ratio: 0.3461619628751727\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.433       |\n",
      "| time/                 |             |\n",
      "|    fps                | 46          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -209        |\n",
      "|    explained_variance | -0.156      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | -1.99       |\n",
      "|    reward             | 0.011356827 |\n",
      "|    std                | 139         |\n",
      "|    value_loss         | 0.000979    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.433        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -211         |\n",
      "|    explained_variance | 0.585        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | 22           |\n",
      "|    reward             | -0.028400637 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.433       |\n",
      "| time/                 |             |\n",
      "|    fps                | 46          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -212        |\n",
      "|    explained_variance | -0.247      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | -2.51       |\n",
      "|    reward             | 0.008608377 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 0.000259    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.433         |\n",
      "| time/                 |               |\n",
      "|    fps                | 45            |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -213          |\n",
      "|    explained_variance | -0.154        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13199         |\n",
      "|    policy_loss        | -1.03         |\n",
      "|    reward             | 0.00086532335 |\n",
      "|    std                | 155           |\n",
      "|    value_loss         | 9.6e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1788352.5\n",
      "Final accumulative portfolio value: 1.7883525\n",
      "Maximum DrawDown: -0.46729493763306273\n",
      "Sharpe ratio: 0.4100044078220367\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -215         |\n",
      "|    explained_variance | 0.053        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13299        |\n",
      "|    policy_loss        | 0.797        |\n",
      "|    reward             | -0.010044667 |\n",
      "|    std                | 162          |\n",
      "|    value_loss         | 0.000578     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.451       |\n",
      "| time/                 |             |\n",
      "|    fps                | 45          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -216        |\n",
      "|    explained_variance | 0.0348      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | -6.79       |\n",
      "|    reward             | 0.052306846 |\n",
      "|    std                | 168         |\n",
      "|    value_loss         | 0.00126     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 387          |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -217         |\n",
      "|    explained_variance | -0.315       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 2.75         |\n",
      "|    reward             | -0.011350853 |\n",
      "|    std                | 174          |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 398          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -218         |\n",
      "|    explained_variance | -0.799       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | 1.46         |\n",
      "|    reward             | -0.010932985 |\n",
      "|    std                | 181          |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1503457.625\n",
      "Final accumulative portfolio value: 1.503457625\n",
      "Maximum DrawDown: -0.510843098132925\n",
      "Sharpe ratio: 0.3258988873884707\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.445        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 411          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -220         |\n",
      "|    explained_variance | -0.109       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -6.62        |\n",
      "|    reward             | -0.014606841 |\n",
      "|    std                | 189          |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.445        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 422          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -221         |\n",
      "|    explained_variance | -0.426       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | 0.918        |\n",
      "|    reward             | -0.013737431 |\n",
      "|    std                | 197          |\n",
      "|    value_loss         | 0.000627     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.445        |\n",
      "| time/                 |              |\n",
      "|    fps                | 45           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 433          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -222         |\n",
      "|    explained_variance | -1.32        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | 3.63         |\n",
      "|    reward             | -0.000982469 |\n",
      "|    std                | 203          |\n",
      "|    value_loss         | 0.000379     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.445         |\n",
      "| time/                 |               |\n",
      "|    fps                | 45            |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 444           |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -224          |\n",
      "|    explained_variance | -0.115        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13999         |\n",
      "|    policy_loss        | 4.03          |\n",
      "|    reward             | -0.0135967005 |\n",
      "|    std                | 212           |\n",
      "|    value_loss         | 0.000557      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1490416.5\n",
      "Final accumulative portfolio value: 1.4904165\n",
      "Maximum DrawDown: -0.5063312301611228\n",
      "Sharpe ratio: 0.3218865739554416\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.44         |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 457          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -225         |\n",
      "|    explained_variance | -0.365       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.025452163 |\n",
      "|    std                | 221          |\n",
      "|    value_loss         | 0.000155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.44         |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 468          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -226         |\n",
      "|    explained_variance | 0.647        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | 0.761        |\n",
      "|    reward             | -0.027443435 |\n",
      "|    std                | 228          |\n",
      "|    value_loss         | 8.05e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.44        |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 478         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -227        |\n",
      "|    explained_variance | 0.561       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | 4.94        |\n",
      "|    reward             | 0.008774179 |\n",
      "|    std                | 237         |\n",
      "|    value_loss         | 0.000498    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.44       |\n",
      "| time/                 |            |\n",
      "|    fps                | 44         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 489        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -229       |\n",
      "|    explained_variance | -3.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14399      |\n",
      "|    policy_loss        | 1.66       |\n",
      "|    reward             | 0.01985321 |\n",
      "|    std                | 247        |\n",
      "|    value_loss         | 9.4e-05    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1668107.375\n",
      "Final accumulative portfolio value: 1.668107375\n",
      "Maximum DrawDown: -0.4752438702873715\n",
      "Sharpe ratio: 0.3759871285435704\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.446        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 504          |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -230         |\n",
      "|    explained_variance | -0.658       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 1.78         |\n",
      "|    reward             | -0.008155791 |\n",
      "|    std                | 258          |\n",
      "|    value_loss         | 9.58e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.446       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -231        |\n",
      "|    explained_variance | 0.527       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | -9.46       |\n",
      "|    reward             | -0.03497498 |\n",
      "|    std                | 268         |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.446         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 525           |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -232          |\n",
      "|    explained_variance | -1.22         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14699         |\n",
      "|    policy_loss        | -0.876        |\n",
      "|    reward             | -0.0016428011 |\n",
      "|    std                | 277           |\n",
      "|    value_loss         | 8.08e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.446         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 536           |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -234          |\n",
      "|    explained_variance | 0.245         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14799         |\n",
      "|    policy_loss        | -2.54         |\n",
      "|    reward             | 0.00020847534 |\n",
      "|    std                | 289           |\n",
      "|    value_loss         | 0.000159      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1801957.875\n",
      "Final accumulative portfolio value: 1.801957875\n",
      "Maximum DrawDown: -0.4610642560391537\n",
      "Sharpe ratio: 0.4140709436052085\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 551         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -235        |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | 1.18        |\n",
      "|    reward             | 0.005576886 |\n",
      "|    std                | 302         |\n",
      "|    value_loss         | 5.95e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -236        |\n",
      "|    explained_variance | 0.381       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 0.436       |\n",
      "|    reward             | -0.04226462 |\n",
      "|    std                | 313         |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.458        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 575          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -237         |\n",
      "|    explained_variance | 0.439        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | 2.37         |\n",
      "|    reward             | 0.0023447184 |\n",
      "|    std                | 323          |\n",
      "|    value_loss         | 0.000191     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.458         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 585           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -239          |\n",
      "|    explained_variance | -0.515        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15199         |\n",
      "|    policy_loss        | 3.39          |\n",
      "|    reward             | 0.00036602476 |\n",
      "|    std                | 336           |\n",
      "|    value_loss         | 0.000274      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1589265.125\n",
      "Final accumulative portfolio value: 1.589265125\n",
      "Maximum DrawDown: -0.486962056002064\n",
      "Sharpe ratio: 0.3521063663348512\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 599         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -240        |\n",
      "|    explained_variance | -0.301      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 7.51        |\n",
      "|    reward             | 0.005204581 |\n",
      "|    std                | 351         |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -241        |\n",
      "|    explained_variance | 0.421       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | 5.24        |\n",
      "|    reward             | 0.010189537 |\n",
      "|    std                | 364         |\n",
      "|    value_loss         | 0.000597    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 621         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -242        |\n",
      "|    explained_variance | 0.166       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15499       |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | 0.020715313 |\n",
      "|    std                | 377         |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.458        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 633          |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -244         |\n",
      "|    explained_variance | 0.195        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | 1.95         |\n",
      "|    reward             | -0.010712277 |\n",
      "|    std                | 393          |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1714732.25\n",
      "Final accumulative portfolio value: 1.71473225\n",
      "Maximum DrawDown: -0.4658546492683474\n",
      "Sharpe ratio: 0.3891517683949443\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.463       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 649         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -245        |\n",
      "|    explained_variance | 0.408       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | -3.36       |\n",
      "|    reward             | 0.014443843 |\n",
      "|    std                | 411         |\n",
      "|    value_loss         | 0.000236    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.463        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 660          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -247         |\n",
      "|    explained_variance | 0.538        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | -7.19        |\n",
      "|    reward             | -0.021983957 |\n",
      "|    std                | 426          |\n",
      "|    value_loss         | 0.00161      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.463        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 671          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -248         |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15899        |\n",
      "|    policy_loss        | -1.29        |\n",
      "|    reward             | 0.0017610771 |\n",
      "|    std                | 441          |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.463       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 682         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -249        |\n",
      "|    explained_variance | 0.298       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | 1.64        |\n",
      "|    reward             | 0.016854381 |\n",
      "|    std                | 459         |\n",
      "|    value_loss         | 0.000133    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1645843.75\n",
      "Final accumulative portfolio value: 1.64584375\n",
      "Maximum DrawDown: -0.49390302227265015\n",
      "Sharpe ratio: 0.3696227022895379\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.465         |\n",
      "| time/                 |               |\n",
      "|    fps                | 43            |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 696           |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -250          |\n",
      "|    explained_variance | 0.0502        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16099         |\n",
      "|    policy_loss        | -7.04         |\n",
      "|    reward             | -0.0018561413 |\n",
      "|    std                | 479           |\n",
      "|    value_loss         | 0.000995      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.465        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 707          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -252         |\n",
      "|    explained_variance | 0.44         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | -6.58        |\n",
      "|    reward             | -0.018933732 |\n",
      "|    std                | 496          |\n",
      "|    value_loss         | 0.000963     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.465       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 718         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -253        |\n",
      "|    explained_variance | 0.117       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -0.59       |\n",
      "|    reward             | 0.018962534 |\n",
      "|    std                | 515         |\n",
      "|    value_loss         | 8.71e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.465       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 728         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -254        |\n",
      "|    explained_variance | 0.0429      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -6.34       |\n",
      "|    reward             | 0.016289001 |\n",
      "|    std                | 537         |\n",
      "|    value_loss         | 0.000787    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1508977.125\n",
      "Final accumulative portfolio value: 1.508977125\n",
      "Maximum DrawDown: -0.5285992658945717\n",
      "Sharpe ratio: 0.32746031745115395\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.461         |\n",
      "| time/                 |               |\n",
      "|    fps                | 43            |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 741           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -256          |\n",
      "|    explained_variance | 0.887         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16499         |\n",
      "|    policy_loss        | 0.816         |\n",
      "|    reward             | -0.0074995533 |\n",
      "|    std                | 562           |\n",
      "|    value_loss         | 1.94e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.461       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 751         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -257        |\n",
      "|    explained_variance | 0.559       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | -0.842      |\n",
      "|    reward             | 0.038950127 |\n",
      "|    std                | 584         |\n",
      "|    value_loss         | 5.94e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.461      |\n",
      "| time/                 |            |\n",
      "|    fps                | 43         |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 762        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -258       |\n",
      "|    explained_variance | -0.98      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16699      |\n",
      "|    policy_loss        | -4.38      |\n",
      "|    reward             | 0.01766871 |\n",
      "|    std                | 604        |\n",
      "|    value_loss         | 0.000391   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.461        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -259         |\n",
      "|    explained_variance | 0.179        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | -3.61        |\n",
      "|    reward             | -0.013475989 |\n",
      "|    std                | 629          |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1394050.625\n",
      "Final accumulative portfolio value: 1.394050625\n",
      "Maximum DrawDown: -0.5000594319195656\n",
      "Sharpe ratio: 0.2896841473988075\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.454       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 786         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -261        |\n",
      "|    explained_variance | 0.449       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.184      |\n",
      "|    reward             | 0.004033644 |\n",
      "|    std                | 657         |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.454       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 796         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -262        |\n",
      "|    explained_variance | 0.0726      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | 0.011654624 |\n",
      "|    std                | 682         |\n",
      "|    value_loss         | 0.000615    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.454        |\n",
      "| time/                 |              |\n",
      "|    fps                | 43           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -263         |\n",
      "|    explained_variance | -1.31        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17099        |\n",
      "|    policy_loss        | -2.99        |\n",
      "|    reward             | 0.0016133877 |\n",
      "|    std                | 705          |\n",
      "|    value_loss         | 0.000163     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.454        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 817          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -264         |\n",
      "|    explained_variance | -0.115       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 0.0654       |\n",
      "|    reward             | 0.0077697197 |\n",
      "|    std                | 733          |\n",
      "|    value_loss         | 3.43e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1464906.75\n",
      "Final accumulative portfolio value: 1.46490675\n",
      "Maximum DrawDown: -0.49215203155448983\n",
      "Sharpe ratio: 0.31381428758981356\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.449       |\n",
      "| time/                 |             |\n",
      "|    fps                | 43          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -266        |\n",
      "|    explained_variance | 0.391       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | -2.49       |\n",
      "|    reward             | 0.021011736 |\n",
      "|    std                | 764         |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.449        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -267         |\n",
      "|    explained_variance | -0.795       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17399        |\n",
      "|    policy_loss        | -6.69        |\n",
      "|    reward             | 0.0062357862 |\n",
      "|    std                | 792          |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.449       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -268        |\n",
      "|    explained_variance | -0.263      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | 0.798       |\n",
      "|    reward             | 0.008470325 |\n",
      "|    std                | 820         |\n",
      "|    value_loss         | 7.34e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.449        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 860          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -269         |\n",
      "|    explained_variance | -0.44        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | 1.53         |\n",
      "|    reward             | -0.007343487 |\n",
      "|    std                | 855          |\n",
      "|    value_loss         | 0.000216     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1392174.0\n",
      "Final accumulative portfolio value: 1.392174\n",
      "Maximum DrawDown: -0.49488692924767097\n",
      "Sharpe ratio: 0.2891490275376108\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.443       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 873         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -271        |\n",
      "|    explained_variance | -0.047      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 0.591       |\n",
      "|    reward             | -0.02284441 |\n",
      "|    std                | 894         |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.443       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 884         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -272        |\n",
      "|    explained_variance | -0.762      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 3.5         |\n",
      "|    reward             | 0.010363337 |\n",
      "|    std                | 927         |\n",
      "|    value_loss         | 0.000278    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.443        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 894          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -273         |\n",
      "|    explained_variance | 0.337        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | -0.00127     |\n",
      "|    reward             | 0.0019171921 |\n",
      "|    std                | 962          |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.443        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 905          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -275         |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.175       |\n",
      "|    reward             | -0.009872251 |\n",
      "|    std                | 1e+03        |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1669949.75\n",
      "Final accumulative portfolio value: 1.66994975\n",
      "Maximum DrawDown: -0.499529322399596\n",
      "Sharpe ratio: 0.37673616669163873\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.446       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 918         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -276        |\n",
      "|    explained_variance | 0.117       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | 7.06        |\n",
      "|    reward             | 0.019184282 |\n",
      "|    std                | 1.05e+03    |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.446        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 928          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -277         |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | -9.91        |\n",
      "|    reward             | -0.013558336 |\n",
      "|    std                | 1.08e+03     |\n",
      "|    value_loss         | 0.00146      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.446        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 938          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -278         |\n",
      "|    explained_variance | 0.759        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | 2.02         |\n",
      "|    reward             | 0.0006413787 |\n",
      "|    std                | 1.12e+03     |\n",
      "|    value_loss         | 8.42e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.446        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 948          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -280         |\n",
      "|    explained_variance | -0.145       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | -3.62        |\n",
      "|    reward             | -0.002735897 |\n",
      "|    std                | 1.17e+03     |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1536418.375\n",
      "Final accumulative portfolio value: 1.536418375\n",
      "Maximum DrawDown: -0.5160220048604216\n",
      "Sharpe ratio: 0.3363334378245493\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.445       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 960         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -281        |\n",
      "|    explained_variance | 0.0895      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -9.44       |\n",
      "|    reward             | 0.038769986 |\n",
      "|    std                | 1.22e+03    |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.445        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 970          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -282         |\n",
      "|    explained_variance | 0.358        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18599        |\n",
      "|    policy_loss        | -4.33        |\n",
      "|    reward             | 0.0060559353 |\n",
      "|    std                | 1.27e+03     |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.445       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 980         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -284        |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | -0.524      |\n",
      "|    reward             | 0.008636386 |\n",
      "|    std                | 1.31e+03    |\n",
      "|    value_loss         | 3.51e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.445       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 989         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -285        |\n",
      "|    explained_variance | 0.485       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -3.56       |\n",
      "|    reward             | -0.01624851 |\n",
      "|    std                | 1.37e+03    |\n",
      "|    value_loss         | 0.000267    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1346858.875\n",
      "Final accumulative portfolio value: 1.346858875\n",
      "Maximum DrawDown: -0.5150500312001742\n",
      "Sharpe ratio: 0.2733055388282304\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.438      |\n",
      "| time/                 |            |\n",
      "|    fps                | 44         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 1002       |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -286       |\n",
      "|    explained_variance | 0.554      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18899      |\n",
      "|    policy_loss        | 7.49       |\n",
      "|    reward             | -0.0269341 |\n",
      "|    std                | 1.43e+03   |\n",
      "|    value_loss         | 0.000759   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.438       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 1012        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -288        |\n",
      "|    explained_variance | 0.634       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 6.22        |\n",
      "|    reward             | 0.009651072 |\n",
      "|    std                | 1.49e+03    |\n",
      "|    value_loss         | 0.000637    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 0.438       |\n",
      "| time/                 |             |\n",
      "|    fps                | 44          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 1022        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -289        |\n",
      "|    explained_variance | -0.0892     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | 0.981       |\n",
      "|    reward             | 0.009663587 |\n",
      "|    std                | 1.54e+03    |\n",
      "|    value_loss         | 2.5e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.438         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 1033          |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -290          |\n",
      "|    explained_variance | 0.203         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19199         |\n",
      "|    policy_loss        | 4.3           |\n",
      "|    reward             | -0.0070533967 |\n",
      "|    std                | 1.6e+03       |\n",
      "|    value_loss         | 0.000229      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1538322.375\n",
      "Final accumulative portfolio value: 1.538322375\n",
      "Maximum DrawDown: -0.527956698082759\n",
      "Sharpe ratio: 0.33698641316118805\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.437         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 9300          |\n",
      "|    time_elapsed       | 1045          |\n",
      "|    total_timesteps    | 46500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -292          |\n",
      "|    explained_variance | 0.224         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | -2.79         |\n",
      "|    reward             | 0.00063804287 |\n",
      "|    std                | 1.68e+03      |\n",
      "|    value_loss         | 0.000515      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 0.437      |\n",
      "| time/                 |            |\n",
      "|    fps                | 44         |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 1055       |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -293       |\n",
      "|    explained_variance | 0.292      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19399      |\n",
      "|    policy_loss        | -16.2      |\n",
      "|    reward             | 0.03436408 |\n",
      "|    std                | 1.74e+03   |\n",
      "|    value_loss         | 0.00354    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.437        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 1066         |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -294         |\n",
      "|    explained_variance | 0.112        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | -10.5        |\n",
      "|    reward             | 0.0019558603 |\n",
      "|    std                | 1.8e+03      |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.437         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 1076          |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -295          |\n",
      "|    explained_variance | 0.563         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19599         |\n",
      "|    policy_loss        | -0.539        |\n",
      "|    reward             | -0.0036751127 |\n",
      "|    std                | 1.87e+03      |\n",
      "|    value_loss         | 1.39e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1734865.125\n",
      "Final accumulative portfolio value: 1.734865125\n",
      "Maximum DrawDown: -0.48022375955832264\n",
      "Sharpe ratio: 0.3950417167119167\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.442        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 1089         |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -297         |\n",
      "|    explained_variance | -0.0519      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | 6.74         |\n",
      "|    reward             | -0.027199758 |\n",
      "|    std                | 1.96e+03     |\n",
      "|    value_loss         | 0.000841     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.442        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 1099         |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -298         |\n",
      "|    explained_variance | 0.211        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19799        |\n",
      "|    policy_loss        | -11.5        |\n",
      "|    reward             | -0.018312635 |\n",
      "|    std                | 2.04e+03     |\n",
      "|    value_loss         | 0.00165      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 0.442        |\n",
      "| time/                 |              |\n",
      "|    fps                | 44           |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 1109         |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -299         |\n",
      "|    explained_variance | 0.13         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | -4.28        |\n",
      "|    reward             | -0.013205434 |\n",
      "|    std                | 2.11e+03     |\n",
      "|    value_loss         | 0.000272     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 0.442         |\n",
      "| time/                 |               |\n",
      "|    fps                | 44            |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 1119          |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -301          |\n",
      "|    explained_variance | -1.25         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19999         |\n",
      "|    policy_loss        | -2.91         |\n",
      "|    reward             | -0.0011404698 |\n",
      "|    std                | 2.19e+03      |\n",
      "|    value_loss         | 0.00015       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 663731.625\n",
      "Final accumulative portfolio value: 0.663731625\n",
      "Maximum DrawDown: -0.5129882867261418\n",
      "Sharpe ratio: -0.503656422319733\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_32\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1684911.75\n",
      "Final accumulative portfolio value: 1.68491175\n",
      "Maximum DrawDown: -0.47266313884089606\n",
      "Sharpe ratio: 0.380397608953906\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 2.01e+03    |\n",
      "|    ep_rew_mean     | 50.6        |\n",
      "| time/              |             |\n",
      "|    fps             | 19          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 104         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.06691368 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1730246.875\n",
      "Final accumulative portfolio value: 1.730246875\n",
      "Maximum DrawDown: -0.4660855389896277\n",
      "Sharpe ratio: 0.39399726250916356\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 48.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008616631  |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.9        |\n",
      "|    explained_variance   | 0.00015      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.426       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.031       |\n",
      "|    reward               | 0.0035343247 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.225        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1772767.5\n",
      "Final accumulative portfolio value: 1.7727675\n",
      "Maximum DrawDown: -0.45364086068784326\n",
      "Sharpe ratio: 0.40546368249396814\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009028615 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.425      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    reward               | 0.06232     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1677831.875\n",
      "Final accumulative portfolio value: 1.677831875\n",
      "Maximum DrawDown: -0.48070929587478817\n",
      "Sharpe ratio: 0.3793907693184528\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 52.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009893006 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.081       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.488      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    reward               | 0.034715064 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0867      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1564132.75\n",
      "Final accumulative portfolio value: 1.56413275\n",
      "Maximum DrawDown: -0.4964476133530925\n",
      "Sharpe ratio: 0.3451160832743877\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 51.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 554          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108209755 |\n",
      "|    clip_fraction        | 0.0791       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.2        |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.481       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    reward               | 0.036078826  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1965662.875\n",
      "Final accumulative portfolio value: 1.965662875\n",
      "Maximum DrawDown: -0.46188048134488113\n",
      "Sharpe ratio: 0.45524642853361735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010052832 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.453      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    reward               | 0.06423283  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1604098.625\n",
      "Final accumulative portfolio value: 1.604098625\n",
      "Maximum DrawDown: -0.49561802149461887\n",
      "Sharpe ratio: 0.35676938475661607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011238256 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.451      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | 0.07057448  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1858907.5\n",
      "Final accumulative portfolio value: 1.8589075\n",
      "Maximum DrawDown: -0.42184111960464965\n",
      "Sharpe ratio: 0.42962439150452336\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 53.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 874          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095991045 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.3        |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.458       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0392      |\n",
      "|    reward               | 0.08503958   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.155        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1685242.125\n",
      "Final accumulative portfolio value: 1.685242125\n",
      "Maximum DrawDown: -0.45481077216282206\n",
      "Sharpe ratio: 0.3809209337886157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 979         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010402139 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.462      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    reward               | 0.062252432 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1796121.125\n",
      "Final accumulative portfolio value: 1.796121125\n",
      "Maximum DrawDown: -0.4523224608276486\n",
      "Sharpe ratio: 0.4116794625393323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1083        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011607494 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.423      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    reward               | 0.06905848  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1891281.5\n",
      "Final accumulative portfolio value: 1.8912815\n",
      "Maximum DrawDown: -0.4280191658919308\n",
      "Sharpe ratio: 0.43723766825624777\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1185        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010696998 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.452      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    reward               | 0.056631263 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1801135.125\n",
      "Final accumulative portfolio value: 1.801135125\n",
      "Maximum DrawDown: -0.5086713552292912\n",
      "Sharpe ratio: 0.41134202484785487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010620933 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.416      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    reward               | 0.038218807 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1792084.25\n",
      "Final accumulative portfolio value: 1.79208425\n",
      "Maximum DrawDown: -0.4921403905720175\n",
      "Sharpe ratio: 0.4112182658215585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1395        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011991896 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.09        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.46       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    reward               | 0.041865185 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1505155.375\n",
      "Final accumulative portfolio value: 1.505155375\n",
      "Maximum DrawDown: -0.5387821782891031\n",
      "Sharpe ratio: 0.3269383349651082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1508        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448179 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.45       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    reward               | 0.053837523 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1739757.5\n",
      "Final accumulative portfolio value: 1.7397575\n",
      "Maximum DrawDown: -0.4754137434819744\n",
      "Sharpe ratio: 0.39668287604989505\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1618         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118107125 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.9        |\n",
      "|    explained_variance   | 0.0865       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.48        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0442      |\n",
      "|    reward               | 0.03123651   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.173        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1726204.875\n",
      "Final accumulative portfolio value: 1.726204875\n",
      "Maximum DrawDown: -0.4991058109484575\n",
      "Sharpe ratio: 0.3928158899881021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1728        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013154086 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0982      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.41       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    reward               | 0.03998634  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1691264.25\n",
      "Final accumulative portfolio value: 1.69126425\n",
      "Maximum DrawDown: -0.4726321793567847\n",
      "Sharpe ratio: 0.3836611920793364\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1839        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013505199 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.454      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    reward               | 0.030770112 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2015043.75\n",
      "Final accumulative portfolio value: 2.01504375\n",
      "Maximum DrawDown: -0.4438566642207269\n",
      "Sharpe ratio: 0.467727950491916\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1944        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016182713 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.446      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    reward               | 0.03304983  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1504737.375\n",
      "Final accumulative portfolio value: 1.504737375\n",
      "Maximum DrawDown: -0.4865162370148308\n",
      "Sharpe ratio: 0.32638399659198547\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2056        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013162432 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.478      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    reward               | 0.036848105 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1677955.125\n",
      "Final accumulative portfolio value: 1.677955125\n",
      "Maximum DrawDown: -0.4621918705328705\n",
      "Sharpe ratio: 0.38042850843263715\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 57.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2169         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117267445 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.4        |\n",
      "|    explained_variance   | 0.0831       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.451       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0435      |\n",
      "|    reward               | 0.036914602  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.171        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1735103.625\n",
      "Final accumulative portfolio value: 1.735103625\n",
      "Maximum DrawDown: -0.47378425136045177\n",
      "Sharpe ratio: 0.39572163440011365\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 57.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 2282         |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130870715 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.5        |\n",
      "|    explained_variance   | 0.114        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.49        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0465      |\n",
      "|    reward               | 0.01694588   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.177        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1559500.375\n",
      "Final accumulative portfolio value: 1.559500375\n",
      "Maximum DrawDown: -0.5188754756578831\n",
      "Sharpe ratio: 0.34385040894092533\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 57           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2390         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012896037  |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.5        |\n",
      "|    explained_variance   | 0.119        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.451       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0461      |\n",
      "|    reward               | 0.0013466534 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.164        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1550434.125\n",
      "Final accumulative portfolio value: 1.550434125\n",
      "Maximum DrawDown: -0.5151526433147232\n",
      "Sharpe ratio: 0.3413406446713189\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.01e+03      |\n",
      "|    ep_rew_mean          | 56.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 2500          |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015037301   |\n",
      "|    clip_fraction        | 0.139         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.7         |\n",
      "|    explained_variance   | 0.13          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.497        |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.0478       |\n",
      "|    reward               | -0.0009879831 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.158         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1497411.5\n",
      "Final accumulative portfolio value: 1.4974115\n",
      "Maximum DrawDown: -0.515382951848405\n",
      "Sharpe ratio: 0.32498793942992593\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2611        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012602283 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.506      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    reward               | 0.012774199 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1758776.375\n",
      "Final accumulative portfolio value: 1.758776375\n",
      "Maximum DrawDown: -0.4718209831942044\n",
      "Sharpe ratio: 0.4022538132655156\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2725        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01271327  |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.495      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0466     |\n",
      "|    reward               | 0.008441104 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "Logging to ./data/tb\\ppo_33\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1793010.0\n",
      "Final accumulative portfolio value: 1.79301\n",
      "Maximum DrawDown: -0.46979580591233727\n",
      "Sharpe ratio: 0.41064206506725587\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 2.01e+03     |\n",
      "|    ep_rew_mean     | 58.3         |\n",
      "| time/              |              |\n",
      "|    fps             | 18           |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 109          |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.051344518 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1465220.625\n",
      "Final accumulative portfolio value: 1.465220625\n",
      "Maximum DrawDown: -0.5123765118286951\n",
      "Sharpe ratio: 0.31374868470541184\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 51.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014440898  |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49          |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.473       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0473      |\n",
      "|    reward               | -0.005520279 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1731598.5\n",
      "Final accumulative portfolio value: 1.7315985\n",
      "Maximum DrawDown: -0.4505829086950984\n",
      "Sharpe ratio: 0.3953687203420745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 52.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012410695 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.497      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    reward               | 0.02867546  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1869420.625\n",
      "Final accumulative portfolio value: 1.869420625\n",
      "Maximum DrawDown: -0.4521777493852631\n",
      "Sharpe ratio: 0.4312794645790366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012678105 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.475      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    reward               | 0.038797982 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1719357.75\n",
      "Final accumulative portfolio value: 1.71935775\n",
      "Maximum DrawDown: -0.4641645774607178\n",
      "Sharpe ratio: 0.39135932467492446\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013905786 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.441      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    reward               | 0.049144298 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1833410.0\n",
      "Final accumulative portfolio value: 1.83341\n",
      "Maximum DrawDown: -0.47818130859551555\n",
      "Sharpe ratio: 0.42068750293369134\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014280792 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.0738      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.492      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    reward               | 0.067222364 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1542628.625\n",
      "Final accumulative portfolio value: 1.542628625\n",
      "Maximum DrawDown: -0.4995844093123081\n",
      "Sharpe ratio: 0.3392073874878983\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 764          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139007885 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.6        |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.481       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0476      |\n",
      "|    reward               | 0.09061664   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1811648.875\n",
      "Final accumulative portfolio value: 1.811648875\n",
      "Maximum DrawDown: -0.4648406808259119\n",
      "Sharpe ratio: 0.41701927296294783\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.01e+03   |\n",
      "|    ep_rew_mean          | 58.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 878        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0123138  |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.7      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.487     |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0467    |\n",
      "|    reward               | 0.07034761 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1826538.625\n",
      "Final accumulative portfolio value: 1.826538625\n",
      "Maximum DrawDown: -0.4452059763701314\n",
      "Sharpe ratio: 0.4213124852284167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 988         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013445975 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.444      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    reward               | 0.07223625  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.253       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1591768.375\n",
      "Final accumulative portfolio value: 1.591768375\n",
      "Maximum DrawDown: -0.46661122916133035\n",
      "Sharpe ratio: 0.3540341637087752\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1099        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012140328 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.517      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    reward               | 0.072773665 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2062243.625\n",
      "Final accumulative portfolio value: 2.062243625\n",
      "Maximum DrawDown: -0.4614519894244121\n",
      "Sharpe ratio: 0.47860061123880293\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 58          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015360065 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.492      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    reward               | 0.043625206 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1626343.125\n",
      "Final accumulative portfolio value: 1.626343125\n",
      "Maximum DrawDown: -0.4749088604396511\n",
      "Sharpe ratio: 0.36403471421542155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1305        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013808347 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.478      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0467     |\n",
      "|    reward               | 0.032092165 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1669242.75\n",
      "Final accumulative portfolio value: 1.66924275\n",
      "Maximum DrawDown: -0.4617214582782505\n",
      "Sharpe ratio: 0.37721815872914605\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 57          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1401        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014191237 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.501      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    reward               | 0.029348325 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1416334.0\n",
      "Final accumulative portfolio value: 1.416334\n",
      "Maximum DrawDown: -0.5067924834458624\n",
      "Sharpe ratio: 0.29735504440445715\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014874218 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.529      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    reward               | 0.03307189  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1582207.75\n",
      "Final accumulative portfolio value: 1.58220775\n",
      "Maximum DrawDown: -0.4606036781892401\n",
      "Sharpe ratio: 0.3517658419000921\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1602        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012997897 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.514      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    reward               | 0.020980986 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1602352.25\n",
      "Final accumulative portfolio value: 1.60235225\n",
      "Maximum DrawDown: -0.5149291247934591\n",
      "Sharpe ratio: 0.3571313717665907\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 54.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014363328 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.434      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    reward               | 0.035811566 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1631794.0\n",
      "Final accumulative portfolio value: 1.631794\n",
      "Maximum DrawDown: -0.4928834449468643\n",
      "Sharpe ratio: 0.3657295912486467\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 53.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1812        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014969233 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.528      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    reward               | 0.03218324  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1915448.75\n",
      "Final accumulative portfolio value: 1.91544875\n",
      "Maximum DrawDown: -0.44601718627351294\n",
      "Sharpe ratio: 0.44426022316642316\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.01e+03   |\n",
      "|    ep_rew_mean          | 55         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 19         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 1916       |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01467157 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | 0.0799     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.504     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0512    |\n",
      "|    reward               | 0.03404639 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1767173.875\n",
      "Final accumulative portfolio value: 1.767173875\n",
      "Maximum DrawDown: -0.5068490907530405\n",
      "Sharpe ratio: 0.40458175023091714\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 55.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2019        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015056334 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.524      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    reward               | 0.03651766  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1939983.375\n",
      "Final accumulative portfolio value: 1.939983375\n",
      "Maximum DrawDown: -0.4714284413083417\n",
      "Sharpe ratio: 0.4498367112214253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2123        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012743302 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.467      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    reward               | 0.036718175 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1717778.0\n",
      "Final accumulative portfolio value: 1.717778\n",
      "Maximum DrawDown: -0.5109848527634389\n",
      "Sharpe ratio: 0.3904957181420696\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2226        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014481148 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.491      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    reward               | 0.019324325 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1701515.5\n",
      "Final accumulative portfolio value: 1.7015155\n",
      "Maximum DrawDown: -0.478656680174788\n",
      "Sharpe ratio: 0.3856539680305165\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2330         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014008382  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.7        |\n",
      "|    explained_variance   | 0.0922       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.533       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0499      |\n",
      "|    reward               | 0.0034247988 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.111        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1524112.375\n",
      "Final accumulative portfolio value: 1.524112375\n",
      "Maximum DrawDown: -0.5368384442169594\n",
      "Sharpe ratio: 0.33247145258246075\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2434         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016725115  |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.8        |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.49        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0522      |\n",
      "|    reward               | 0.0035570937 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1694600.875\n",
      "Final accumulative portfolio value: 1.694600875\n",
      "Maximum DrawDown: -0.4934069092788784\n",
      "Sharpe ratio: 0.3834512011028644\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 56.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2538         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014171829  |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.8        |\n",
      "|    explained_variance   | 0.0656       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.5         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0498      |\n",
      "|    reward               | 0.0127658965 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.173        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1641338.0\n",
      "Final accumulative portfolio value: 1.641338\n",
      "Maximum DrawDown: -0.46506692574212827\n",
      "Sharpe ratio: 0.36942061729782366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 56.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2641        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01422303  |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.516      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    reward               | 0.006878758 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 660474.5625\n",
      "Final accumulative portfolio value: 0.6604745625\n",
      "Maximum DrawDown: -0.4983401233846795\n",
      "Sharpe ratio: -0.5348463693163361\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_26\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47         |\n",
      "|    explained_variance | -9.91       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 16.7        |\n",
      "|    reward             | 0.045817923 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 19        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | -2.69     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -1.01     |\n",
      "|    reward             | 0.0160667 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.0012    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.9       |\n",
      "|    explained_variance | -4.93       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.568      |\n",
      "|    reward             | 0.028282057 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000244    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.5       |\n",
      "|    explained_variance | -23         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.378      |\n",
      "|    reward             | 0.025822017 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.000183    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1769054.5\n",
      "Final accumulative portfolio value: 1.7690545\n",
      "Maximum DrawDown: -0.48519585928213227\n",
      "Sharpe ratio: 0.4043518404451302\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 68.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49        |\n",
      "|    explained_variance | -1.02e+03  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -8.89      |\n",
      "|    reward             | 0.03527287 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.0746     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 68.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.5       |\n",
      "|    explained_variance | -0.96       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -3.85       |\n",
      "|    reward             | 0.014804414 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00692     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 68.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.2       |\n",
      "|    explained_variance | -16.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.833       |\n",
      "|    reward             | 0.028106717 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000795    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 68.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.1      |\n",
      "|    explained_variance | -112       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -0.546     |\n",
      "|    reward             | 0.02648225 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.000279   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1798369.625\n",
      "Final accumulative portfolio value: 1.798369625\n",
      "Maximum DrawDown: -0.48096226213926274\n",
      "Sharpe ratio: 0.4117606463163983\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 65.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.5       |\n",
      "|    explained_variance | -9.69       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -5.35       |\n",
      "|    reward             | 0.043429986 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.0156      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 65.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52         |\n",
      "|    explained_variance | -2.18       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -1.41       |\n",
      "|    reward             | 0.013030999 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.00159     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 65.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52.7       |\n",
      "|    explained_variance | -10.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 0.384       |\n",
      "|    reward             | 0.022850785 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 65.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -53.6      |\n",
      "|    explained_variance | -17.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 0.074      |\n",
      "|    reward             | 0.02105782 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 2.41e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1501056.75\n",
      "Final accumulative portfolio value: 1.50105675\n",
      "Maximum DrawDown: -0.5187082809108144\n",
      "Sharpe ratio: 0.3248281207649691\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54         |\n",
      "|    explained_variance | -37.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -2.75       |\n",
      "|    reward             | 0.036323063 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.00973     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.4       |\n",
      "|    explained_variance | -1.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 2.18        |\n",
      "|    reward             | 0.021242032 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.00228     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 412         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55         |\n",
      "|    explained_variance | -1.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | 0.026239168 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 7.59e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.9       |\n",
      "|    explained_variance | -3.96e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.126       |\n",
      "|    reward             | 0.025506437 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 6.96e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1707422.375\n",
      "Final accumulative portfolio value: 1.707422375\n",
      "Maximum DrawDown: -0.46730939088934154\n",
      "Sharpe ratio: 0.38607127966734517\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.5       |\n",
      "|    explained_variance | -167        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -4.02       |\n",
      "|    reward             | 0.042320203 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.0212      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 498         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57         |\n",
      "|    explained_variance | -9.98       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -3.1        |\n",
      "|    reward             | 0.016082792 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.00524     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.7       |\n",
      "|    explained_variance | -69.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.775       |\n",
      "|    reward             | 0.023301905 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 0.000246    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 552         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -58.7       |\n",
      "|    explained_variance | -41.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.736      |\n",
      "|    reward             | 0.022240518 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 0.000265    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1604351.375\n",
      "Final accumulative portfolio value: 1.604351375\n",
      "Maximum DrawDown: -0.4637806326035717\n",
      "Sharpe ratio: 0.35756835628990713\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 581         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.3       |\n",
      "|    explained_variance | -327        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 5.75        |\n",
      "|    reward             | 0.050238788 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.0203      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 608         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.8       |\n",
      "|    explained_variance | -3.46       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -5.13       |\n",
      "|    reward             | 0.014359558 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.00792     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 635         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.5       |\n",
      "|    explained_variance | -597        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.899      |\n",
      "|    reward             | 0.025651723 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.000563    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 661         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.5       |\n",
      "|    explained_variance | -90.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.515       |\n",
      "|    reward             | 0.025901627 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1768181.625\n",
      "Final accumulative portfolio value: 1.768181625\n",
      "Maximum DrawDown: -0.4761697169698247\n",
      "Sharpe ratio: 0.4032093624697483\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 691        |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -62        |\n",
      "|    explained_variance | -155       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 3.72       |\n",
      "|    reward             | 0.06749608 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 0.0506     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 718         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62.5       |\n",
      "|    explained_variance | -3.36       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 1.66        |\n",
      "|    reward             | 0.017255599 |\n",
      "|    std                | 1.61        |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 746         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.2       |\n",
      "|    explained_variance | -322        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.185       |\n",
      "|    reward             | 0.028204832 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 0.000338    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 773         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.1       |\n",
      "|    explained_variance | -158        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.959       |\n",
      "|    reward             | 0.029428506 |\n",
      "|    std                | 1.69        |\n",
      "|    value_loss         | 0.000371    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2023143.25\n",
      "Final accumulative portfolio value: 2.02314325\n",
      "Maximum DrawDown: -0.47689982716912416\n",
      "Sharpe ratio: 0.4710187711293309\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64.7       |\n",
      "|    explained_variance | -51.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -6.98       |\n",
      "|    reward             | 0.045001574 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 0.024       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 831         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.1       |\n",
      "|    explained_variance | -0.148      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | 0.012772428 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 859         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.8       |\n",
      "|    explained_variance | -1.05e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | 0.024270665 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 0.000239    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 61.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 886        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -66.8      |\n",
      "|    explained_variance | -45.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -0.0755    |\n",
      "|    reward             | 0.02598826 |\n",
      "|    std                | 1.84       |\n",
      "|    value_loss         | 6.29e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1811385.375\n",
      "Final accumulative portfolio value: 1.811385375\n",
      "Maximum DrawDown: -0.4664803063733427\n",
      "Sharpe ratio: 0.41361176548035683\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 916         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.4       |\n",
      "|    explained_variance | -135        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 4.47        |\n",
      "|    reward             | 0.047234464 |\n",
      "|    std                | 1.87        |\n",
      "|    value_loss         | 0.00526     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 943         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.9       |\n",
      "|    explained_variance | -9.25       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -10.2       |\n",
      "|    reward             | 0.011772095 |\n",
      "|    std                | 1.9         |\n",
      "|    value_loss         | 0.029       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 969         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -68.7       |\n",
      "|    explained_variance | -550        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 0.543       |\n",
      "|    reward             | 0.024834862 |\n",
      "|    std                | 1.94        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 996         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.7       |\n",
      "|    explained_variance | -267        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.767      |\n",
      "|    reward             | 0.027061762 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 0.000202    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1913294.25\n",
      "Final accumulative portfolio value: 1.91329425\n",
      "Maximum DrawDown: -0.46167292691866635\n",
      "Sharpe ratio: 0.43945924204553555\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 1026        |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.2       |\n",
      "|    explained_variance | -217        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | -5.51       |\n",
      "|    reward             | 0.052338094 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.00939     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.8       |\n",
      "|    explained_variance | -0.357      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -1.84       |\n",
      "|    reward             | 0.010006077 |\n",
      "|    std                | 2.07        |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1079        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.6       |\n",
      "|    explained_variance | -180        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | 0.025732862 |\n",
      "|    std                | 2.12        |\n",
      "|    value_loss         | 0.000318    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1106        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.5       |\n",
      "|    explained_variance | -6.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.2         |\n",
      "|    reward             | 0.028083865 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 3.12e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1970424.5\n",
      "Final accumulative portfolio value: 1.9704245\n",
      "Maximum DrawDown: -0.4432013391932643\n",
      "Sharpe ratio: 0.4555014697800436\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 62.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 1135       |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -73.2      |\n",
      "|    explained_variance | -5.85      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 4.57       |\n",
      "|    reward             | 0.05483729 |\n",
      "|    std                | 2.23       |\n",
      "|    value_loss         | 0.00586    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 62.3         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 1162         |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.8        |\n",
      "|    explained_variance | 0.407        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -1.4         |\n",
      "|    reward             | 0.0005591751 |\n",
      "|    std                | 2.27         |\n",
      "|    value_loss         | 0.000691     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1189        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -74.5       |\n",
      "|    explained_variance | -25.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.139      |\n",
      "|    reward             | 0.020307176 |\n",
      "|    std                | 2.32        |\n",
      "|    value_loss         | 0.000282    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 62.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1216        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -75.5       |\n",
      "|    explained_variance | -1.2e+04    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 0.296       |\n",
      "|    reward             | 0.022845253 |\n",
      "|    std                | 2.39        |\n",
      "|    value_loss         | 7.43e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1697643.125\n",
      "Final accumulative portfolio value: 1.697643125\n",
      "Maximum DrawDown: -0.5072732042674917\n",
      "Sharpe ratio: 0.38366117904785535\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 1245        |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.2       |\n",
      "|    explained_variance | -4.91       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.429       |\n",
      "|    reward             | 0.069221325 |\n",
      "|    std                | 2.44        |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1273        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.6       |\n",
      "|    explained_variance | -0.668      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -1.27       |\n",
      "|    reward             | 0.009158773 |\n",
      "|    std                | 2.47        |\n",
      "|    value_loss         | 0.000956    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1300        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.4       |\n",
      "|    explained_variance | -16.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -2.66       |\n",
      "|    reward             | 0.021164825 |\n",
      "|    std                | 2.53        |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 61.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 1327       |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -78.4      |\n",
      "|    explained_variance | -20.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 0.335      |\n",
      "|    reward             | 0.02287396 |\n",
      "|    std                | 2.61       |\n",
      "|    value_loss         | 8.68e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1720421.125\n",
      "Final accumulative portfolio value: 1.720421125\n",
      "Maximum DrawDown: -0.5140948048270362\n",
      "Sharpe ratio: 0.3898638273201683\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -78.9       |\n",
      "|    explained_variance | -28.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 1.88        |\n",
      "|    reward             | 0.057083305 |\n",
      "|    std                | 2.65        |\n",
      "|    value_loss         | 0.00162     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 61            |\n",
      "| time/                 |               |\n",
      "|    fps                | 18            |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 1384          |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -79.5         |\n",
      "|    explained_variance | -3.79         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4999          |\n",
      "|    policy_loss        | -3.91         |\n",
      "|    reward             | -0.0006183064 |\n",
      "|    std                | 2.69          |\n",
      "|    value_loss         | 0.0043        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80.2       |\n",
      "|    explained_variance | -2.34       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.341       |\n",
      "|    reward             | 0.014332389 |\n",
      "|    std                | 2.75        |\n",
      "|    value_loss         | 6.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 61          |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 1439        |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -81.2       |\n",
      "|    explained_variance | -47.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | 1.24        |\n",
      "|    reward             | 0.018311473 |\n",
      "|    std                | 2.84        |\n",
      "|    value_loss         | 0.000541    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1461561.0\n",
      "Final accumulative portfolio value: 1.461561\n",
      "Maximum DrawDown: -0.5275197058507157\n",
      "Sharpe ratio: 0.31253743646487436\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 1469       |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -81.8      |\n",
      "|    explained_variance | -4.68      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -2.29      |\n",
      "|    reward             | 0.08119809 |\n",
      "|    std                | 2.89       |\n",
      "|    value_loss         | 0.00144    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 1496       |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -82.3      |\n",
      "|    explained_variance | -1.78      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.02176746 |\n",
      "|    std                | 2.93       |\n",
      "|    value_loss         | 0.00165    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 1523        |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83         |\n",
      "|    explained_variance | -1.89       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -0.589      |\n",
      "|    reward             | 0.026303126 |\n",
      "|    std                | 2.99        |\n",
      "|    value_loss         | 9.95e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1550        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.9       |\n",
      "|    explained_variance | -1.34       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -2.77       |\n",
      "|    reward             | 0.027562503 |\n",
      "|    std                | 3.08        |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2081003.75\n",
      "Final accumulative portfolio value: 2.08100375\n",
      "Maximum DrawDown: -0.462540504013947\n",
      "Sharpe ratio: 0.48131303086684024\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 60.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 1580       |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -84.6      |\n",
      "|    explained_variance | -356       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | 8.44       |\n",
      "|    reward             | 0.05513403 |\n",
      "|    std                | 3.14       |\n",
      "|    value_loss         | 0.0122     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 60.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 1607         |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -85.1        |\n",
      "|    explained_variance | -7.03        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -1.8         |\n",
      "|    reward             | 0.0046214024 |\n",
      "|    std                | 3.2          |\n",
      "|    value_loss         | 0.00574      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 60.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1634        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85.9       |\n",
      "|    explained_variance | -3.31       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -0.317      |\n",
      "|    reward             | 0.013773263 |\n",
      "|    std                | 3.27        |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 60.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1661        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -86.9       |\n",
      "|    explained_variance | -6.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.907       |\n",
      "|    reward             | 0.017499782 |\n",
      "|    std                | 3.37        |\n",
      "|    value_loss         | 0.000332    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1420489.125\n",
      "Final accumulative portfolio value: 1.420489125\n",
      "Maximum DrawDown: -0.500447776198044\n",
      "Sharpe ratio: 0.29914098428741775\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 1691       |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -87.6      |\n",
      "|    explained_variance | -7.47      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.3      |\n",
      "|    reward             | 0.05749704 |\n",
      "|    std                | 3.44       |\n",
      "|    value_loss         | 0.0164     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 59.3         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 1718         |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -88.1        |\n",
      "|    explained_variance | -1.37        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 9.48         |\n",
      "|    reward             | 0.0059541306 |\n",
      "|    std                | 3.5          |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1744        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.8       |\n",
      "|    explained_variance | -18.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -2.15       |\n",
      "|    reward             | 0.020355452 |\n",
      "|    std                | 3.57        |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 1771       |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -89.8      |\n",
      "|    explained_variance | -32        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | -0.707     |\n",
      "|    reward             | 0.02054296 |\n",
      "|    std                | 3.68       |\n",
      "|    value_loss         | 9.98e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1611056.125\n",
      "Final accumulative portfolio value: 1.611056125\n",
      "Maximum DrawDown: -0.48671092163313023\n",
      "Sharpe ratio: 0.3594738724489803\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 1801       |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -90.3      |\n",
      "|    explained_variance | -23        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -1.98      |\n",
      "|    reward             | 0.07392938 |\n",
      "|    std                | 3.74       |\n",
      "|    value_loss         | 0.00649    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1828        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -90.9       |\n",
      "|    explained_variance | -0.172      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 4.65        |\n",
      "|    reward             | 0.021036735 |\n",
      "|    std                | 3.8         |\n",
      "|    value_loss         | 0.00297     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1855        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -91.6       |\n",
      "|    explained_variance | -10.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.633      |\n",
      "|    reward             | 0.029805582 |\n",
      "|    std                | 3.89        |\n",
      "|    value_loss         | 0.00025     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 1881        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92.6       |\n",
      "|    explained_variance | -3.31e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.366      |\n",
      "|    reward             | 0.029904328 |\n",
      "|    std                | 4.01        |\n",
      "|    value_loss         | 5.67e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2147975.5\n",
      "Final accumulative portfolio value: 2.1479755\n",
      "Maximum DrawDown: -0.4345679419296188\n",
      "Sharpe ratio: 0.4955631816899788\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 1911        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -93.5       |\n",
      "|    explained_variance | -831        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 2.55        |\n",
      "|    reward             | 0.065235704 |\n",
      "|    std                | 4.12        |\n",
      "|    value_loss         | 0.00146     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 1938        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -94         |\n",
      "|    explained_variance | -2.05       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -8.68       |\n",
      "|    reward             | 0.012776263 |\n",
      "|    std                | 4.19        |\n",
      "|    value_loss         | 0.0102      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 1963        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -94.7       |\n",
      "|    explained_variance | -3.11e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -0.718      |\n",
      "|    reward             | 0.021976925 |\n",
      "|    std                | 4.28        |\n",
      "|    value_loss         | 9.98e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 1990        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -95.7       |\n",
      "|    explained_variance | 0.606       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -1.13       |\n",
      "|    reward             | 0.024592318 |\n",
      "|    std                | 4.4         |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1707326.375\n",
      "Final accumulative portfolio value: 1.707326375\n",
      "Maximum DrawDown: -0.4878565871191125\n",
      "Sharpe ratio: 0.38649174399929714\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 2019       |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -96.4      |\n",
      "|    explained_variance | -4.92      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -0.979     |\n",
      "|    reward             | 0.07113974 |\n",
      "|    std                | 4.51       |\n",
      "|    value_loss         | 0.00308    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 2045       |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -97.1      |\n",
      "|    explained_variance | -15.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -2.67      |\n",
      "|    reward             | 0.01664522 |\n",
      "|    std                | 4.59       |\n",
      "|    value_loss         | 0.00444    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 2070        |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -97.8       |\n",
      "|    explained_variance | -1.48e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | 0.025361128 |\n",
      "|    std                | 4.7         |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.01e+03  |\n",
      "|    ep_rew_mean        | 59.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 18        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 2095      |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -98.8     |\n",
      "|    explained_variance | -10.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -2.19     |\n",
      "|    reward             | 0.0245266 |\n",
      "|    std                | 4.85      |\n",
      "|    value_loss         | 0.000623  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1736969.625\n",
      "Final accumulative portfolio value: 1.736969625\n",
      "Maximum DrawDown: -0.436783576074241\n",
      "Sharpe ratio: 0.39433616780976044\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2123        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.6       |\n",
      "|    explained_variance | -20.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.777       |\n",
      "|    reward             | 0.066321544 |\n",
      "|    std                | 4.96        |\n",
      "|    value_loss         | 0.00267     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2152        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -100        |\n",
      "|    explained_variance | -2.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 4.67        |\n",
      "|    reward             | 0.018143307 |\n",
      "|    std                | 5.06        |\n",
      "|    value_loss         | 0.00287     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2181        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -29.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -2.25       |\n",
      "|    reward             | 0.022645928 |\n",
      "|    std                | 5.18        |\n",
      "|    value_loss         | 0.000722    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 2207       |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -102       |\n",
      "|    explained_variance | -33.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 1.82       |\n",
      "|    reward             | 0.02127324 |\n",
      "|    std                | 5.34       |\n",
      "|    value_loss         | 0.00035    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1593051.0\n",
      "Final accumulative portfolio value: 1.593051\n",
      "Maximum DrawDown: -0.4622068137981292\n",
      "Sharpe ratio: 0.35257840157897896\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 2236       |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -103       |\n",
      "|    explained_variance | -46.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -0.402     |\n",
      "|    reward             | 0.07352655 |\n",
      "|    std                | 5.48       |\n",
      "|    value_loss         | 0.0126     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 2263        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -103        |\n",
      "|    explained_variance | -8.6        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -4.96       |\n",
      "|    reward             | 0.012316899 |\n",
      "|    std                | 5.58        |\n",
      "|    value_loss         | 0.00262     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2289        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | -288        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | 0.021848075 |\n",
      "|    std                | 5.69        |\n",
      "|    value_loss         | 0.000335    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2315        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | -78.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | 0.023830615 |\n",
      "|    std                | 5.86        |\n",
      "|    value_loss         | 0.000242    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1629547.125\n",
      "Final accumulative portfolio value: 1.629547125\n",
      "Maximum DrawDown: -0.5442576757778268\n",
      "Sharpe ratio: 0.3641618616463223\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 2348       |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | -690       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.08259807 |\n",
      "|    std                | 5.99       |\n",
      "|    value_loss         | 0.00535    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 2376       |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -106       |\n",
      "|    explained_variance | -4.57      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -2.31      |\n",
      "|    reward             | 0.02923208 |\n",
      "|    std                | 6.09       |\n",
      "|    value_loss         | 0.000626   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 2404       |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -107       |\n",
      "|    explained_variance | -3.46      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | -0.741     |\n",
      "|    reward             | 0.02637333 |\n",
      "|    std                | 6.23       |\n",
      "|    value_loss         | 9.53e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 59         |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 2430       |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -108       |\n",
      "|    explained_variance | -625       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -0.819     |\n",
      "|    reward             | 0.02742971 |\n",
      "|    std                | 6.41       |\n",
      "|    value_loss         | 0.000138   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1870793.625\n",
      "Final accumulative portfolio value: 1.870793625\n",
      "Maximum DrawDown: -0.4464932112397082\n",
      "Sharpe ratio: 0.4302456223250916\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2460        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | -34.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 15.7        |\n",
      "|    reward             | 0.048079796 |\n",
      "|    std                | 6.58        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 2486        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | -3.69       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -2.83       |\n",
      "|    reward             | 0.026607748 |\n",
      "|    std                | 6.67        |\n",
      "|    value_loss         | 0.000861    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2513        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -110        |\n",
      "|    explained_variance | -2.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | 0.016950043 |\n",
      "|    std                | 6.81        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 59.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2539        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -111        |\n",
      "|    explained_variance | -2.09e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -1.08       |\n",
      "|    reward             | 0.020983376 |\n",
      "|    std                | 7.02        |\n",
      "|    value_loss         | 0.000166    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1412745.875\n",
      "Final accumulative portfolio value: 1.412745875\n",
      "Maximum DrawDown: -0.4781277546914948\n",
      "Sharpe ratio: 0.2957433597317623\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 2568       |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -112       |\n",
      "|    explained_variance | -0.141     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -2.36      |\n",
      "|    reward             | 0.08287656 |\n",
      "|    std                | 7.19       |\n",
      "|    value_loss         | 0.00113    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 2595       |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -112       |\n",
      "|    explained_variance | -2.17      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -7.02      |\n",
      "|    reward             | 0.03329618 |\n",
      "|    std                | 7.31       |\n",
      "|    value_loss         | 0.00403    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2622        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -1.4e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.687      |\n",
      "|    reward             | 0.019614212 |\n",
      "|    std                | 7.46        |\n",
      "|    value_loss         | 0.000502    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2648        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | -24.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.022980904 |\n",
      "|    std                | 7.68        |\n",
      "|    value_loss         | 8e-05       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1487663.25\n",
      "Final accumulative portfolio value: 1.48766325\n",
      "Maximum DrawDown: -0.5071480112863951\n",
      "Sharpe ratio: 0.3200375845640539\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 2677       |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -115       |\n",
      "|    explained_variance | -22.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 21.6       |\n",
      "|    reward             | 0.09187298 |\n",
      "|    std                | 7.87       |\n",
      "|    value_loss         | 0.0567     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2705        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -115        |\n",
      "|    explained_variance | -21.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -2.28       |\n",
      "|    reward             | 0.026044648 |\n",
      "|    std                | 8           |\n",
      "|    value_loss         | 0.000731    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 58.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 2732       |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -116       |\n",
      "|    explained_variance | -143       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | 0.02353907 |\n",
      "|    std                | 8.18       |\n",
      "|    value_loss         | 0.0006     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 58.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2760        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -117        |\n",
      "|    explained_variance | -181        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | 0.026180042 |\n",
      "|    std                | 8.43        |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "Logging to ./data/tb\\a2c_27\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | -18.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | 0.945       |\n",
      "|    reward             | 0.033889603 |\n",
      "|    std                | 8.59        |\n",
      "|    value_loss         | 0.0054      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | -4.75e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.011823374 |\n",
      "|    std                | 8.76        |\n",
      "|    value_loss         | 0.000825    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 77         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -119       |\n",
      "|    explained_variance | -11        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10299      |\n",
      "|    policy_loss        | -2.13      |\n",
      "|    reward             | 0.02452848 |\n",
      "|    std                | 8.99       |\n",
      "|    value_loss         | 0.000376   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | -1.31e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | 0.45        |\n",
      "|    reward             | 0.022642542 |\n",
      "|    std                | 9.3         |\n",
      "|    value_loss         | 5.86e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1593511.875\n",
      "Final accumulative portfolio value: 1.593511875\n",
      "Maximum DrawDown: -0.4681700082428881\n",
      "Sharpe ratio: 0.353441306271312\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 50.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -121       |\n",
      "|    explained_variance | -18.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | -0.432     |\n",
      "|    reward             | 0.02420439 |\n",
      "|    std                | 9.42       |\n",
      "|    value_loss         | 0.00751    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 50.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -121         |\n",
      "|    explained_variance | -2.92e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | 0.0074041346 |\n",
      "|    std                | 9.61         |\n",
      "|    value_loss         | 0.000785     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 50.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -122        |\n",
      "|    explained_variance | -14.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 0.998       |\n",
      "|    reward             | 0.022028862 |\n",
      "|    std                | 9.85        |\n",
      "|    value_loss         | 8.73e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 50.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -123        |\n",
      "|    explained_variance | -472        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -0.835      |\n",
      "|    reward             | 0.020894479 |\n",
      "|    std                | 10.2        |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1492207.0\n",
      "Final accumulative portfolio value: 1.492207\n",
      "Maximum DrawDown: -0.5153628749427914\n",
      "Sharpe ratio: 0.3220748103315511\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 49.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -124       |\n",
      "|    explained_variance | -19.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -17.8      |\n",
      "|    reward             | 0.04207415 |\n",
      "|    std                | 10.4       |\n",
      "|    value_loss         | 0.0282     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | -98.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | -3.78       |\n",
      "|    reward             | 0.007926778 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.00166     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | -1.38       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | 1           |\n",
      "|    reward             | 0.018416965 |\n",
      "|    std                | 10.8        |\n",
      "|    value_loss         | 8.78e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 49.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | -3.24e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.017140346 |\n",
      "|    std                | 11.2        |\n",
      "|    value_loss         | 5.98e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1323898.25\n",
      "Final accumulative portfolio value: 1.32389825\n",
      "Maximum DrawDown: -0.5274820705469093\n",
      "Sharpe ratio: 0.26485553214791047\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 48.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 340        |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -127       |\n",
      "|    explained_variance | -9.67      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11299      |\n",
      "|    policy_loss        | -5.66      |\n",
      "|    reward             | 0.04716833 |\n",
      "|    std                | 11.4       |\n",
      "|    value_loss         | 0.0079     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -128        |\n",
      "|    explained_variance | -147        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 8.19        |\n",
      "|    reward             | 0.021967754 |\n",
      "|    std                | 11.6        |\n",
      "|    value_loss         | 0.00491     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -128        |\n",
      "|    explained_variance | -7.54       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 1.89        |\n",
      "|    reward             | 0.027103074 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.00033     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 48.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | -10.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | 0.026016867 |\n",
      "|    std                | 12.3        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1737311.375\n",
      "Final accumulative portfolio value: 1.737311375\n",
      "Maximum DrawDown: -0.4972095682522577\n",
      "Sharpe ratio: 0.39447234024012184\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 443        |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -130       |\n",
      "|    explained_variance | -8.89      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11699      |\n",
      "|    policy_loss        | -11        |\n",
      "|    reward             | 0.04273419 |\n",
      "|    std                | 12.5       |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | -31         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | -1.59       |\n",
      "|    reward             | 0.014236744 |\n",
      "|    std                | 12.7        |\n",
      "|    value_loss         | 0.000412    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | -3.65       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | 0.023924567 |\n",
      "|    std                | 13          |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -133        |\n",
      "|    explained_variance | -97.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | 0.0132      |\n",
      "|    reward             | 0.021372147 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 6.27e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1555436.75\n",
      "Final accumulative portfolio value: 1.55543675\n",
      "Maximum DrawDown: -0.4679380818611627\n",
      "Sharpe ratio: 0.34233510004706963\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 546         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -133        |\n",
      "|    explained_variance | 0.73        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -15         |\n",
      "|    reward             | 0.045948084 |\n",
      "|    std                | 13.8        |\n",
      "|    value_loss         | 0.0126      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -134        |\n",
      "|    explained_variance | -2.02e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 0.99        |\n",
      "|    reward             | 0.012818373 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 0.000718    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 596         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | -74.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 0.702       |\n",
      "|    reward             | 0.025080564 |\n",
      "|    std                | 14.3        |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 621        |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -136       |\n",
      "|    explained_variance | -4.3       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12399      |\n",
      "|    policy_loss        | 0.895      |\n",
      "|    reward             | 0.02484442 |\n",
      "|    std                | 14.8       |\n",
      "|    value_loss         | 5.44e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1726600.875\n",
      "Final accumulative portfolio value: 1.726600875\n",
      "Maximum DrawDown: -0.5105815438609912\n",
      "Sharpe ratio: 0.3920157182105907\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 649         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -136        |\n",
      "|    explained_variance | -0.422      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | 3.47        |\n",
      "|    reward             | 0.044438243 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 674         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -137        |\n",
      "|    explained_variance | -38.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 2.75        |\n",
      "|    reward             | 0.010364269 |\n",
      "|    std                | 15.4        |\n",
      "|    value_loss         | 0.00096     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 699         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | -3.7e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -1.56       |\n",
      "|    reward             | 0.020384308 |\n",
      "|    std                | 15.7        |\n",
      "|    value_loss         | 0.000469    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 54.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 727         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -139        |\n",
      "|    explained_variance | -4.63       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.026      |\n",
      "|    reward             | 0.022001514 |\n",
      "|    std                | 16.3        |\n",
      "|    value_loss         | 3e-05       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1571493.375\n",
      "Final accumulative portfolio value: 1.571493375\n",
      "Maximum DrawDown: -0.48248237585252807\n",
      "Sharpe ratio: 0.3472832672005384\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 756        |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -139       |\n",
      "|    explained_variance | -8.29      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | -24.7      |\n",
      "|    reward             | 0.04883474 |\n",
      "|    std                | 16.6       |\n",
      "|    value_loss         | 0.0378     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 783         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | -11.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | 10.4        |\n",
      "|    reward             | 0.009258845 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 0.00729     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 19         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 810        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -141       |\n",
      "|    explained_variance | -65.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13099      |\n",
      "|    policy_loss        | -1.72      |\n",
      "|    reward             | 0.01924505 |\n",
      "|    std                | 17.4       |\n",
      "|    value_loss         | 0.000414   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 839         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -142        |\n",
      "|    explained_variance | -5.78       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 2.34        |\n",
      "|    reward             | 0.022815764 |\n",
      "|    std                | 17.9        |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1599329.0\n",
      "Final accumulative portfolio value: 1.599329\n",
      "Maximum DrawDown: -0.5009726977779434\n",
      "Sharpe ratio: 0.35558950943992357\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 871         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -143        |\n",
      "|    explained_variance | -4.25       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | 1.12        |\n",
      "|    reward             | 0.034209386 |\n",
      "|    std                | 18.3        |\n",
      "|    value_loss         | 0.0022      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 900         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -143        |\n",
      "|    explained_variance | -12.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | -13.8       |\n",
      "|    reward             | 0.000765181 |\n",
      "|    std                | 18.7        |\n",
      "|    value_loss         | 0.0113      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 928         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -144        |\n",
      "|    explained_variance | -15.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | 2.29        |\n",
      "|    reward             | 0.013312458 |\n",
      "|    std                | 19.1        |\n",
      "|    value_loss         | 0.00031     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 957         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | -63.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | 0.016221171 |\n",
      "|    std                | 19.7        |\n",
      "|    value_loss         | 4.4e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1323806.875\n",
      "Final accumulative portfolio value: 1.323806875\n",
      "Maximum DrawDown: -0.5236763356612364\n",
      "Sharpe ratio: 0.26488389872382145\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 988        |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -146       |\n",
      "|    explained_variance | -101       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13699      |\n",
      "|    policy_loss        | -5.43      |\n",
      "|    reward             | 0.05633479 |\n",
      "|    std                | 20.1       |\n",
      "|    value_loss         | 0.0034     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1017        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | -0.512      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -2.95       |\n",
      "|    reward             | 0.007792964 |\n",
      "|    std                | 20.5        |\n",
      "|    value_loss         | 0.00055     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1045        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -147        |\n",
      "|    explained_variance | -76.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | 0.627       |\n",
      "|    reward             | 0.018943898 |\n",
      "|    std                | 21.1        |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1072        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -148        |\n",
      "|    explained_variance | -40.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | 0.023212483 |\n",
      "|    std                | 21.8        |\n",
      "|    value_loss         | 0.000144    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1688314.375\n",
      "Final accumulative portfolio value: 1.688314375\n",
      "Maximum DrawDown: -0.48418003467740545\n",
      "Sharpe ratio: 0.38036995112179733\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1103        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -149        |\n",
      "|    explained_variance | -3.68       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -5.84       |\n",
      "|    reward             | 0.061532278 |\n",
      "|    std                | 22.3        |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | -2.03       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | -2.85       |\n",
      "|    reward             | 0.004027212 |\n",
      "|    std                | 22.7        |\n",
      "|    value_loss         | 0.000673    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1161        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | -21.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | -2.39       |\n",
      "|    reward             | 0.021461682 |\n",
      "|    std                | 23.2        |\n",
      "|    value_loss         | 0.000606    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1188        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -152        |\n",
      "|    explained_variance | -1.07e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.021533916 |\n",
      "|    std                | 24          |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1608198.875\n",
      "Final accumulative portfolio value: 1.608198875\n",
      "Maximum DrawDown: -0.5065245285129647\n",
      "Sharpe ratio: 0.35771474531329706\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 1219        |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -152        |\n",
      "|    explained_variance | -97.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | -13.6       |\n",
      "|    reward             | 0.054348335 |\n",
      "|    std                | 24.5        |\n",
      "|    value_loss         | 0.0092      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1247        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -153        |\n",
      "|    explained_variance | -17.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | 0.004080645 |\n",
      "|    std                | 25          |\n",
      "|    value_loss         | 0.000341    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 53.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 1274       |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -154       |\n",
      "|    explained_variance | -5.24      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14699      |\n",
      "|    policy_loss        | -0.68      |\n",
      "|    reward             | 0.01594493 |\n",
      "|    std                | 25.6       |\n",
      "|    value_loss         | 7.38e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 53.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 1303        |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -155        |\n",
      "|    explained_variance | -88.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.775       |\n",
      "|    reward             | 0.019002836 |\n",
      "|    std                | 26.5        |\n",
      "|    value_loss         | 4.12e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1513998.0\n",
      "Final accumulative portfolio value: 1.513998\n",
      "Maximum DrawDown: -0.4989035053139965\n",
      "Sharpe ratio: 0.329621150349253\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1334        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -156        |\n",
      "|    explained_variance | -42.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -8.08       |\n",
      "|    reward             | 0.059318043 |\n",
      "|    std                | 27.2        |\n",
      "|    value_loss         | 0.00362     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 2.01e+03      |\n",
      "|    ep_rew_mean        | 52.5          |\n",
      "| time/                 |               |\n",
      "|    fps                | 18            |\n",
      "|    iterations         | 5000          |\n",
      "|    time_elapsed       | 1361          |\n",
      "|    total_timesteps    | 25000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -156          |\n",
      "|    explained_variance | -28.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -7.2          |\n",
      "|    reward             | 3.0364748e-05 |\n",
      "|    std                | 27.7          |\n",
      "|    value_loss         | 0.0028        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1389        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -157        |\n",
      "|    explained_variance | -29.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 2.71        |\n",
      "|    reward             | 0.013906658 |\n",
      "|    std                | 28.4        |\n",
      "|    value_loss         | 0.000325    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 1417       |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -158       |\n",
      "|    explained_variance | -19.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15199      |\n",
      "|    policy_loss        | 0.237      |\n",
      "|    reward             | 0.01885839 |\n",
      "|    std                | 29.4       |\n",
      "|    value_loss         | 3.06e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1517451.75\n",
      "Final accumulative portfolio value: 1.51745175\n",
      "Maximum DrawDown: -0.5405550299118858\n",
      "Sharpe ratio: 0.3305416531322524\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1449        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -159        |\n",
      "|    explained_variance | -5.97       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | -7.89       |\n",
      "|    reward             | 0.067805134 |\n",
      "|    std                | 30.1        |\n",
      "|    value_loss         | 0.00416     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1477        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -160        |\n",
      "|    explained_variance | -2.54       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | -4.29       |\n",
      "|    reward             | 0.018153017 |\n",
      "|    std                | 30.6        |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 1504       |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -160       |\n",
      "|    explained_variance | -52.1      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15499      |\n",
      "|    policy_loss        | 0.643      |\n",
      "|    reward             | 0.02264241 |\n",
      "|    std                | 31.4       |\n",
      "|    value_loss         | 0.000151   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 1533       |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -162       |\n",
      "|    explained_variance | -1.7       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15599      |\n",
      "|    policy_loss        | -4.31      |\n",
      "|    reward             | 0.02149674 |\n",
      "|    std                | 32.5       |\n",
      "|    value_loss         | 0.000752   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1690774.375\n",
      "Final accumulative portfolio value: 1.690774375\n",
      "Maximum DrawDown: -0.47817858814558334\n",
      "Sharpe ratio: 0.3817033969744138\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1566        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | -1.74e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | 0.052952513 |\n",
      "|    std                | 33.2        |\n",
      "|    value_loss         | 0.00568     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 52.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 1595         |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -163         |\n",
      "|    explained_variance | -8.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | -5.37        |\n",
      "|    reward             | 0.0113909105 |\n",
      "|    std                | 33.9         |\n",
      "|    value_loss         | 0.00623      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1622        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -1.56       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 0.307       |\n",
      "|    reward             | 0.022423018 |\n",
      "|    std                | 34.7        |\n",
      "|    value_loss         | 2.94e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 1650       |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -165       |\n",
      "|    explained_variance | -13.5      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | 0.407      |\n",
      "|    reward             | 0.02368537 |\n",
      "|    std                | 35.9       |\n",
      "|    value_loss         | 0.000145   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1775461.375\n",
      "Final accumulative portfolio value: 1.775461375\n",
      "Maximum DrawDown: -0.458055091913357\n",
      "Sharpe ratio: 0.40471935674969045\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 1681       |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -166       |\n",
      "|    explained_variance | -94.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16099      |\n",
      "|    policy_loss        | -17.2      |\n",
      "|    reward             | 0.06336445 |\n",
      "|    std                | 36.8       |\n",
      "|    value_loss         | 0.0163     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1710        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -166        |\n",
      "|    explained_variance | -2.45       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16199       |\n",
      "|    policy_loss        | 10.9        |\n",
      "|    reward             | 0.010154356 |\n",
      "|    std                | 37.4        |\n",
      "|    value_loss         | 0.00471     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 1739       |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -167       |\n",
      "|    explained_variance | -10.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16299      |\n",
      "|    policy_loss        | -4.36      |\n",
      "|    reward             | 0.02235978 |\n",
      "|    std                | 38.3       |\n",
      "|    value_loss         | 0.000968   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 1767       |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -168       |\n",
      "|    explained_variance | -62.9      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16399      |\n",
      "|    policy_loss        | -1.21      |\n",
      "|    reward             | 0.02171493 |\n",
      "|    std                | 39.5       |\n",
      "|    value_loss         | 6.19e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1701210.625\n",
      "Final accumulative portfolio value: 1.701210625\n",
      "Maximum DrawDown: -0.49406591379729536\n",
      "Sharpe ratio: 0.3852583032808083\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 1798        |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -169        |\n",
      "|    explained_variance | -58.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | 8.3         |\n",
      "|    reward             | 0.056203097 |\n",
      "|    std                | 40.4        |\n",
      "|    value_loss         | 0.00501     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 2.01e+03     |\n",
      "|    ep_rew_mean        | 52.9         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 1827         |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -169         |\n",
      "|    explained_variance | -5.63        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | 7.91         |\n",
      "|    reward             | 0.0068661906 |\n",
      "|    std                | 41.1         |\n",
      "|    value_loss         | 0.0027       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1855        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -170        |\n",
      "|    explained_variance | -206        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 1.51        |\n",
      "|    reward             | 0.016227465 |\n",
      "|    std                | 42.1        |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 1883        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -171        |\n",
      "|    explained_variance | -3.13       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | 0.598       |\n",
      "|    reward             | 0.016877268 |\n",
      "|    std                | 43.5        |\n",
      "|    value_loss         | 5.46e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1428915.75\n",
      "Final accumulative portfolio value: 1.42891575\n",
      "Maximum DrawDown: -0.47844202527948654\n",
      "Sharpe ratio: 0.30209312334098565\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.01e+03  |\n",
      "|    ep_rew_mean        | 52.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 18        |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 1914      |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -172      |\n",
      "|    explained_variance | -75.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 9.78      |\n",
      "|    reward             | 0.0765436 |\n",
      "|    std                | 44.6      |\n",
      "|    value_loss         | 0.00533   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 1941        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | -3.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -16.2       |\n",
      "|    reward             | 0.010728416 |\n",
      "|    std                | 45.6        |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 1968        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -174        |\n",
      "|    explained_variance | -49.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | 0.877       |\n",
      "|    reward             | 0.019384336 |\n",
      "|    std                | 46.7        |\n",
      "|    value_loss         | 9.44e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 1994       |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -175       |\n",
      "|    explained_variance | -5.07      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | -1.26      |\n",
      "|    reward             | 0.02135413 |\n",
      "|    std                | 48.3       |\n",
      "|    value_loss         | 7.37e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1526896.75\n",
      "Final accumulative portfolio value: 1.52689675\n",
      "Maximum DrawDown: -0.5267391629282951\n",
      "Sharpe ratio: 0.33367215045585197\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 52.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 2025       |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -176       |\n",
      "|    explained_variance | -81.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17299      |\n",
      "|    policy_loss        | -8.1       |\n",
      "|    reward             | 0.06963554 |\n",
      "|    std                | 49.6       |\n",
      "|    value_loss         | 0.00411    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 2051        |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | -5.99       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -0.875      |\n",
      "|    reward             | 0.011359698 |\n",
      "|    std                | 50.7        |\n",
      "|    value_loss         | 0.000847    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 2078        |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -177        |\n",
      "|    explained_variance | -247        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | -1.73       |\n",
      "|    reward             | 0.021587428 |\n",
      "|    std                | 51.9        |\n",
      "|    value_loss         | 0.000166    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 2104        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -178        |\n",
      "|    explained_variance | -0.861      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | -2.13       |\n",
      "|    reward             | 0.021798253 |\n",
      "|    std                | 53.7        |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1637258.375\n",
      "Final accumulative portfolio value: 1.637258375\n",
      "Maximum DrawDown: -0.4841713733651003\n",
      "Sharpe ratio: 0.367488607393347\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2132        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -179        |\n",
      "|    explained_variance | -2.14       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | 0.071487576 |\n",
      "|    std                | 55.1        |\n",
      "|    value_loss         | 0.00834     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2158        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -4.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 5.01        |\n",
      "|    reward             | 0.008732439 |\n",
      "|    std                | 56.2        |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2185        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -34.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | -1.78       |\n",
      "|    reward             | 0.018503718 |\n",
      "|    std                | 57.6        |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2212        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -182        |\n",
      "|    explained_variance | -38         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.017943362 |\n",
      "|    std                | 59.6        |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1489918.25\n",
      "Final accumulative portfolio value: 1.48991825\n",
      "Maximum DrawDown: -0.5499036837687983\n",
      "Sharpe ratio: 0.3218850384854996\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 2241       |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -182       |\n",
      "|    explained_variance | -76.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | 3.04       |\n",
      "|    reward             | 0.06520881 |\n",
      "|    std                | 61.2       |\n",
      "|    value_loss         | 0.00159    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 2267        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -183        |\n",
      "|    explained_variance | -36.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | -7.34       |\n",
      "|    reward             | 0.018672684 |\n",
      "|    std                | 62.5        |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2293        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -184        |\n",
      "|    explained_variance | -36.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 0.578       |\n",
      "|    reward             | 0.024467926 |\n",
      "|    std                | 64.1        |\n",
      "|    value_loss         | 8.46e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2321        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -185        |\n",
      "|    explained_variance | -177        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | -0.871      |\n",
      "|    reward             | 0.025183417 |\n",
      "|    std                | 66.4        |\n",
      "|    value_loss         | 5.02e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1695784.875\n",
      "Final accumulative portfolio value: 1.695784875\n",
      "Maximum DrawDown: -0.45198358092837665\n",
      "Sharpe ratio: 0.3834719358384842\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 2350        |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -186        |\n",
      "|    explained_variance | -425        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | 9.74        |\n",
      "|    reward             | 0.082975045 |\n",
      "|    std                | 68.5        |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2377        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -187        |\n",
      "|    explained_variance | -30.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | -2.03       |\n",
      "|    reward             | 0.017772827 |\n",
      "|    std                | 69.6        |\n",
      "|    value_loss         | 0.000495    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 2404        |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -187        |\n",
      "|    explained_variance | 0.164       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.018569456 |\n",
      "|    std                | 71.3        |\n",
      "|    value_loss         | 4.47e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2430        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -189        |\n",
      "|    explained_variance | -1.38       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -0.705      |\n",
      "|    reward             | 0.019818781 |\n",
      "|    std                | 73.6        |\n",
      "|    value_loss         | 2.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1484458.625\n",
      "Final accumulative portfolio value: 1.484458625\n",
      "Maximum DrawDown: -0.5517022594341414\n",
      "Sharpe ratio: 0.3203640242972524\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.01e+03  |\n",
      "|    ep_rew_mean        | 51.8      |\n",
      "| time/                 |           |\n",
      "|    fps                | 18        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 2459      |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -189      |\n",
      "|    explained_variance | -1.32e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 2.26      |\n",
      "|    reward             | 0.0786684 |\n",
      "|    std                | 75.6      |\n",
      "|    value_loss         | 0.0083    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 2484       |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -190       |\n",
      "|    explained_variance | -2.48      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18999      |\n",
      "|    policy_loss        | -1.64      |\n",
      "|    reward             | 0.03316921 |\n",
      "|    std                | 77.1       |\n",
      "|    value_loss         | 0.000556   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2508        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -191        |\n",
      "|    explained_variance | -46.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | -3.14       |\n",
      "|    reward             | 0.024420148 |\n",
      "|    std                | 78.9        |\n",
      "|    value_loss         | 0.000383    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.8       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 2534       |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -192       |\n",
      "|    explained_variance | -51.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19199      |\n",
      "|    policy_loss        | -0.109     |\n",
      "|    reward             | 0.02835811 |\n",
      "|    std                | 81.5       |\n",
      "|    value_loss         | 3.71e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1836737.25\n",
      "Final accumulative portfolio value: 1.83673725\n",
      "Maximum DrawDown: -0.5125260126359106\n",
      "Sharpe ratio: 0.4231731819934534\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 2561        |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -193        |\n",
      "|    explained_variance | -28.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | -10.2       |\n",
      "|    reward             | 0.043683454 |\n",
      "|    std                | 83.8        |\n",
      "|    value_loss         | 0.00879     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2588        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -194        |\n",
      "|    explained_variance | -1.7        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -4.4        |\n",
      "|    reward             | 0.011885341 |\n",
      "|    std                | 85.6        |\n",
      "|    value_loss         | 0.0007      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2613        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -194        |\n",
      "|    explained_variance | -191        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -0.0726     |\n",
      "|    reward             | 0.012572715 |\n",
      "|    std                | 87.8        |\n",
      "|    value_loss         | 0.000151    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 52.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2639        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -196        |\n",
      "|    explained_variance | -23.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | 0.702       |\n",
      "|    reward             | 0.017414369 |\n",
      "|    std                | 91          |\n",
      "|    value_loss         | 3.5e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1302210.0\n",
      "Final accumulative portfolio value: 1.30221\n",
      "Maximum DrawDown: -0.5555548616611568\n",
      "Sharpe ratio: 0.257012855724144\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 2.01e+03   |\n",
      "|    ep_rew_mean        | 51.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 2667       |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -196       |\n",
      "|    explained_variance | -77.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19699      |\n",
      "|    policy_loss        | 43.8       |\n",
      "|    reward             | 0.09474059 |\n",
      "|    std                | 93.3       |\n",
      "|    value_loss         | 0.0569     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2693        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -197        |\n",
      "|    explained_variance | -24.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | -5.98       |\n",
      "|    reward             | 0.030936936 |\n",
      "|    std                | 95          |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2720        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -198        |\n",
      "|    explained_variance | -2.7e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -0.495      |\n",
      "|    reward             | 0.024608122 |\n",
      "|    std                | 97.3        |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 2.01e+03    |\n",
      "|    ep_rew_mean        | 51.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2746        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -199        |\n",
      "|    explained_variance | -147        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.026687898 |\n",
      "|    std                | 101         |\n",
      "|    value_loss         | 4.9e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 616306.4375\n",
      "Final accumulative portfolio value: 0.6163064375\n",
      "Maximum DrawDown: -0.530145417629654\n",
      "Sharpe ratio: -0.6180202258817202\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "recession_result_dax = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_return')\n",
    "recession_result_dax_sharpe = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_sharpe',reward_sharpe=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_34\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 18          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 108         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.010134793 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075170984 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.9        |\n",
      "|    explained_variance   | -0.0138      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.405       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0295      |\n",
      "|    reward               | 0.013541506  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.289        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2327406.5\n",
      "Final accumulative portfolio value: 2.3274065\n",
      "Maximum DrawDown: -0.5507615060154167\n",
      "Sharpe ratio: 0.29913308462150145\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 79.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009634536 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | -0.801      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.507      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    reward               | 0.015006102 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00644     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 79.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661871 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.422      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    reward               | 0.012585302 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2507029.5\n",
      "Final accumulative portfolio value: 2.5070295\n",
      "Maximum DrawDown: -0.5424261412364979\n",
      "Sharpe ratio: 0.31572658025741995\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.03e+03   |\n",
      "|    ep_rew_mean          | 85.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 563        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01145598 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.2      |\n",
      "|    explained_variance   | -0.806     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.495     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    reward               | 0.03131714 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 0.00857    |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 85.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 677           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008114425   |\n",
      "|    clip_fraction        | 0.0478        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.4         |\n",
      "|    explained_variance   | 0.0682        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.439        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.0317       |\n",
      "|    reward               | -0.0013375556 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.231         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013740668 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.921      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.523      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    reward               | 0.018545687 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2877328.75\n",
      "Final accumulative portfolio value: 2.87732875\n",
      "Maximum DrawDown: -0.5411751350940608\n",
      "Sharpe ratio: 0.3459333595209572\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 86.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 905          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090173725 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.6        |\n",
      "|    explained_variance   | -0.85        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.526       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    reward               | 0.01576959   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00668      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 86.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012882876 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.463      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    reward               | 0.012077337 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2291296.25\n",
      "Final accumulative portfolio value: 2.29129625\n",
      "Maximum DrawDown: -0.5551629556559625\n",
      "Sharpe ratio: 0.29568022201914973\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1134        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010907098 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | -0.953      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.534      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    reward               | 0.025369026 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 85.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1244         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011818285  |\n",
      "|    clip_fraction        | 0.0921       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.7        |\n",
      "|    explained_variance   | 0.0889       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.459       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    reward               | 0.0076478776 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1354        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012457637 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | -0.624      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.537      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    reward               | 0.017096547 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0226      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2234715.75\n",
      "Final accumulative portfolio value: 2.23471575\n",
      "Maximum DrawDown: -0.5560927293345621\n",
      "Sharpe ratio: 0.2904954219743754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1469        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010808032 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | -1.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.522      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | 0.015049572 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00413     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01391933  |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.062       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    reward               | 0.012294983 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.377       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2356749.0\n",
      "Final accumulative portfolio value: 2.356749\n",
      "Maximum DrawDown: -0.588014595283537\n",
      "Sharpe ratio: 0.30230558685337416\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1701        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011314627 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | -1.98       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.527      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    reward               | 0.03011599  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0125      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1810        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010893892 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.417      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    reward               | 0.012631299 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1920        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012043461 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.535      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    reward               | 0.022980625 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.0221      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 3289173.75\n",
      "Final accumulative portfolio value: 3.28917375\n",
      "Maximum DrawDown: -0.5322810460094267\n",
      "Sharpe ratio: 0.3752699100992228\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009298605 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | -1.61       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.517      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | 0.01267587  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00699     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2137        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012534795 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0776      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | 0.015086665 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.402       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2500416.5\n",
      "Final accumulative portfolio value: 2.5004165\n",
      "Maximum DrawDown: -0.546132717570803\n",
      "Sharpe ratio: 0.3150828057787318\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 88.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 2244          |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011702511   |\n",
      "|    clip_fraction        | 0.102         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.7         |\n",
      "|    explained_variance   | -2.34         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.54         |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.0338       |\n",
      "|    reward               | -0.0023799657 |\n",
      "|    std                  | 1.06          |\n",
      "|    value_loss           | 0.0134        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2350        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013934374 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.436      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    reward               | 0.012135672 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2460        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012557626 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | -1.49       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.535      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    reward               | 0.017499924 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2283705.25\n",
      "Final accumulative portfolio value: 2.28370525\n",
      "Maximum DrawDown: -0.5640892256485398\n",
      "Sharpe ratio: 0.2950178458462021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2571        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011016203 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | -2.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.534      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    reward               | 0.018225275 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00665     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 88.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2679        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013243523 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0815      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.498      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    reward               | 0.015513242 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2396814.75\n",
      "Final accumulative portfolio value: 2.39681475\n",
      "Maximum DrawDown: -0.5568530579579497\n",
      "Sharpe ratio: 0.30587292049452874\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 89.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2789        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012549626 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | -2.08       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    reward               | 0.011542095 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "Logging to ./data/tb\\ppo_35\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 20         |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 101        |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.01202351 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013605211 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.398      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    reward               | 0.014749993 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2563928.5\n",
      "Final accumulative portfolio value: 2.5639285\n",
      "Maximum DrawDown: -0.5786129753990521\n",
      "Sharpe ratio: 0.3207868336520487\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01451081  |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | -2.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    reward               | 0.016838068 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 87.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013445696  |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.5        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.396       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    reward               | 0.0123695675 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.27         |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2721247.25\n",
      "Final accumulative portfolio value: 2.72124725\n",
      "Maximum DrawDown: -0.5704708567172845\n",
      "Sharpe ratio: 0.333231706864556\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014556552 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | -1.62       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.534      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    reward               | 0.056858517 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 92.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 651          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013453258  |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.357       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    reward               | 0.0032683215 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.369        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01382901  |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | -1.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.544      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    reward               | 0.016643368 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0488      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2516050.5\n",
      "Final accumulative portfolio value: 2.5160505\n",
      "Maximum DrawDown: -0.568468527926332\n",
      "Sharpe ratio: 0.31611347382800087\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 857         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012285879 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | -3.8        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.525      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    reward               | 0.019068394 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.00915     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016031802 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.382      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    reward               | 0.013893676 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2670238.0\n",
      "Final accumulative portfolio value: 2.670238\n",
      "Maximum DrawDown: -0.5600617343288581\n",
      "Sharpe ratio: 0.3293517611659743\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 99.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013186336 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | -1.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    reward               | 0.030725302 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 99.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1168         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013868356  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.2        |\n",
      "|    explained_variance   | 0.114        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.351       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    reward               | 0.0105507355 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.249        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 99.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1270        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016452715 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | -0.892      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.548      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    reward               | 0.02044394  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0285      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2881685.5\n",
      "Final accumulative portfolio value: 2.8816855\n",
      "Maximum DrawDown: -0.5235492013671035\n",
      "Sharpe ratio: 0.34621791320109585\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 98.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011165179 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | -2.36       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.547      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    reward               | 0.023931397 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.00679     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 98.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1477        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015472077 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.085       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.399      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    reward               | 0.01628657  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2935620.5\n",
      "Final accumulative portfolio value: 2.9356205\n",
      "Maximum DrawDown: -0.5719157876248058\n",
      "Sharpe ratio: 0.350155408150867\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013266394 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | -1.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    reward               | 0.021179557 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1683        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015330737 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.499      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    reward               | 0.009318497 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1785        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013172062 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | -0.815      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.539      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    reward               | 0.019611977 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0235      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2679288.5\n",
      "Final accumulative portfolio value: 2.6792885\n",
      "Maximum DrawDown: -0.5511281816562019\n",
      "Sharpe ratio: 0.3299369653964114\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 98.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1889        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012553673 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | -1.35       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    reward               | 0.015691381 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.00665     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 98.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01461879  |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.0849      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.368      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    reward               | 0.015840461 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2507084.25\n",
      "Final accumulative portfolio value: 2.50708425\n",
      "Maximum DrawDown: -0.5590076441157454\n",
      "Sharpe ratio: 0.3157925936569008\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 97.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2095         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012845044  |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51          |\n",
      "|    explained_variance   | -1.54        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.561       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0356      |\n",
      "|    reward               | -0.002048814 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.012        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 97.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2196        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015509272 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.375      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    reward               | 0.013954316 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 97.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2298        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014042253 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | -1.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    reward               | 0.018391583 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.0177      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2442616.0\n",
      "Final accumulative portfolio value: 2.442616\n",
      "Maximum DrawDown: -0.546802589140029\n",
      "Sharpe ratio: 0.3101555459500006\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 96.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2403        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012178471 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | -1.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    reward               | 0.01762319  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.006       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 96.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2505        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017109955 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.427      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    reward               | 0.016104758 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2578033.25\n",
      "Final accumulative portfolio value: 2.57803325\n",
      "Maximum DrawDown: -0.5289274863964089\n",
      "Sharpe ratio: 0.32214659759248987\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 96.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2609        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01516891  |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | -1.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    reward               | 0.015948238 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1788032.75\n",
      "Final accumulative portfolio value: 1.78803275\n",
      "Maximum DrawDown: -0.3114553072157138\n",
      "Sharpe ratio: 0.6318306631411931\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_28\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.9       |\n",
      "|    explained_variance | -83.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.026418118 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00723     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.4       |\n",
      "|    explained_variance | -25.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | 0.017468253 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.00253     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48         |\n",
      "|    explained_variance | -7.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.39        |\n",
      "|    reward             | 0.020791225 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.00094     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.8       |\n",
      "|    explained_variance | -2.05e+04   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -2.81       |\n",
      "|    reward             | 0.016598055 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00499     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.7       |\n",
      "|    explained_variance | -2.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.657       |\n",
      "|    reward             | 0.010164672 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00021     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.7       |\n",
      "|    explained_variance | -30.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.0513      |\n",
      "|    reward             | 0.009682946 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 1.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -52         |\n",
      "|    explained_variance | -32.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.177       |\n",
      "|    reward             | 0.013885677 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.000125    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.6       |\n",
      "|    explained_variance | -153        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.356       |\n",
      "|    reward             | 0.015266699 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55.3       |\n",
      "|    explained_variance | -18.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.096       |\n",
      "|    reward             | 0.018701673 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 5.03e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.7       |\n",
      "|    explained_variance | -1.45       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.486       |\n",
      "|    reward             | 0.019142646 |\n",
      "|    std                | 1.35        |\n",
      "|    value_loss         | 8.68e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2531076.75\n",
      "Final accumulative portfolio value: 2.53107675\n",
      "Maximum DrawDown: -0.5760080503535212\n",
      "Sharpe ratio: 0.3175688675866327\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.2       |\n",
      "|    explained_variance | -24         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -1.93       |\n",
      "|    reward             | 0.022196367 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 0.00249     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.8       |\n",
      "|    explained_variance | 0.16        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.208      |\n",
      "|    reward             | 0.012627957 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 6.65e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -58.5       |\n",
      "|    explained_variance | -121        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.241      |\n",
      "|    reward             | 0.014591089 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 357         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -59.6       |\n",
      "|    explained_variance | -665        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.678       |\n",
      "|    reward             | 0.012402545 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 0.00023     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 93.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.8        |\n",
      "|    explained_variance | -4.8         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | 0.0051483843 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 0.000753     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 93.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 408          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62          |\n",
      "|    explained_variance | -8.18        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -1.79        |\n",
      "|    reward             | 0.0062019587 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 0.000845     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 433         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.5       |\n",
      "|    explained_variance | -0.00963    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.584      |\n",
      "|    reward             | 0.010299306 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 9.47e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 459         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.2       |\n",
      "|    explained_variance | -163        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0585      |\n",
      "|    reward             | 0.011718611 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 3.56e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 484         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.2       |\n",
      "|    explained_variance | -51.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.214      |\n",
      "|    reward             | 0.014914721 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 1.99e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69         |\n",
      "|    explained_variance | -16.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.11       |\n",
      "|    reward             | 0.015450059 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 4.49e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1935559.75\n",
      "Final accumulative portfolio value: 1.93555975\n",
      "Maximum DrawDown: -0.5982349353460577\n",
      "Sharpe ratio: 0.258703984350428\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 538         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.5       |\n",
      "|    explained_variance | 0.266       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 1.92        |\n",
      "|    reward             | 0.004255987 |\n",
      "|    std                | 1.99        |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 563         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.1       |\n",
      "|    explained_variance | -0.0866     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 3.26        |\n",
      "|    reward             | 0.014303234 |\n",
      "|    std                | 2.03        |\n",
      "|    value_loss         | 0.00234     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 589         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70.9       |\n",
      "|    explained_variance | -53.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.867       |\n",
      "|    reward             | 0.015007478 |\n",
      "|    std                | 2.07        |\n",
      "|    value_loss         | 0.00016     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 615         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.9       |\n",
      "|    explained_variance | -197        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.364       |\n",
      "|    reward             | 0.016254174 |\n",
      "|    std                | 2.14        |\n",
      "|    value_loss         | 6.29e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 644         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -73.1       |\n",
      "|    explained_variance | -2.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.006812598 |\n",
      "|    std                | 2.22        |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 86.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 19           |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 672          |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.4        |\n",
      "|    explained_variance | -153         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | 0.0074085067 |\n",
      "|    std                | 2.31         |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 701         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76         |\n",
      "|    explained_variance | -6.01       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.244       |\n",
      "|    reward             | 0.011191238 |\n",
      "|    std                | 2.42        |\n",
      "|    value_loss         | 1.72e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 19          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 733         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.8       |\n",
      "|    explained_variance | -1.23e+04   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.304       |\n",
      "|    reward             | 0.012657269 |\n",
      "|    std                | 2.56        |\n",
      "|    value_loss         | 0.00076     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 764         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -79.7       |\n",
      "|    explained_variance | -843        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.521       |\n",
      "|    reward             | 0.016533928 |\n",
      "|    std                | 2.71        |\n",
      "|    value_loss         | 5.92e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 793         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -81.5       |\n",
      "|    explained_variance | -6.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.708      |\n",
      "|    reward             | 0.017429844 |\n",
      "|    std                | 2.87        |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2279863.0\n",
      "Final accumulative portfolio value: 2.279863\n",
      "Maximum DrawDown: -0.5742661110734535\n",
      "Sharpe ratio: 0.2942170991029663\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 825         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -82.1       |\n",
      "|    explained_variance | -14.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -0.532      |\n",
      "|    reward             | 0.019364899 |\n",
      "|    std                | 2.92        |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 854         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -82.7       |\n",
      "|    explained_variance | -4.85       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 1.24        |\n",
      "|    reward             | 0.014545053 |\n",
      "|    std                | 2.97        |\n",
      "|    value_loss         | 0.000548    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 883         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.5       |\n",
      "|    explained_variance | -731        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.0144      |\n",
      "|    reward             | 0.016254315 |\n",
      "|    std                | 3.04        |\n",
      "|    value_loss         | 3.11e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 912         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84.6       |\n",
      "|    explained_variance | -9.26       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.386       |\n",
      "|    reward             | 0.015323037 |\n",
      "|    std                | 3.14        |\n",
      "|    value_loss         | 6.73e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 941         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85.8       |\n",
      "|    explained_variance | -5.18       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 2.59        |\n",
      "|    reward             | 0.006076222 |\n",
      "|    std                | 3.27        |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 83.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 970          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -87.2        |\n",
      "|    explained_variance | -29.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.246        |\n",
      "|    reward             | 0.0067621763 |\n",
      "|    std                | 3.41         |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 999         |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.9       |\n",
      "|    explained_variance | -4.82e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.010263552 |\n",
      "|    std                | 3.58        |\n",
      "|    value_loss         | 1.84e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1028        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -90.7       |\n",
      "|    explained_variance | -34.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.518      |\n",
      "|    reward             | 0.012373955 |\n",
      "|    std                | 3.79        |\n",
      "|    value_loss         | 6.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1057        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92.8       |\n",
      "|    explained_variance | -89.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.13        |\n",
      "|    reward             | 0.015737467 |\n",
      "|    std                | 4.03        |\n",
      "|    value_loss         | 1.15e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 83.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 18         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 1086       |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -94.7      |\n",
      "|    explained_variance | -124       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | 0.0392     |\n",
      "|    reward             | 0.01706379 |\n",
      "|    std                | 4.28       |\n",
      "|    value_loss         | 1e-05      |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2147669.0\n",
      "Final accumulative portfolio value: 2.147669\n",
      "Maximum DrawDown: -0.5791913706877997\n",
      "Sharpe ratio: 0.2811786554718091\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1119        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -95.5       |\n",
      "|    explained_variance | -13         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 3.18        |\n",
      "|    reward             | 0.020004157 |\n",
      "|    std                | 4.37        |\n",
      "|    value_loss         | 0.00309     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 1148        |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.1       |\n",
      "|    explained_variance | -5.78       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 1.48        |\n",
      "|    reward             | 0.004376551 |\n",
      "|    std                | 4.45        |\n",
      "|    value_loss         | 0.000372    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1177        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.9       |\n",
      "|    explained_variance | -2.15       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | 0.011267161 |\n",
      "|    std                | 4.56        |\n",
      "|    value_loss         | 0.000231    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1206        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98         |\n",
      "|    explained_variance | -77.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 3.09        |\n",
      "|    reward             | 0.014593255 |\n",
      "|    std                | 4.72        |\n",
      "|    value_loss         | 0.00117     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 84.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -99.4        |\n",
      "|    explained_variance | -76.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.529        |\n",
      "|    reward             | 0.0033266118 |\n",
      "|    std                | 4.93         |\n",
      "|    value_loss         | 6.3e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1264        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -48.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -0.148      |\n",
      "|    reward             | 0.009503536 |\n",
      "|    std                | 5.14        |\n",
      "|    value_loss         | 2.43e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1293        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -102        |\n",
      "|    explained_variance | -319        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -0.61       |\n",
      "|    reward             | 0.011286912 |\n",
      "|    std                | 5.41        |\n",
      "|    value_loss         | 5.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 1322        |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -104        |\n",
      "|    explained_variance | -63.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 0.724       |\n",
      "|    reward             | 0.013760364 |\n",
      "|    std                | 5.72        |\n",
      "|    value_loss         | 7.45e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1351        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -106        |\n",
      "|    explained_variance | -15.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | -0.959      |\n",
      "|    reward             | 0.017038116 |\n",
      "|    std                | 6.08        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 1381        |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -108        |\n",
      "|    explained_variance | -153        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.99       |\n",
      "|    reward             | 0.017255777 |\n",
      "|    std                | 6.44        |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2302280.25\n",
      "Final accumulative portfolio value: 2.30228025\n",
      "Maximum DrawDown: -0.5744671676872897\n",
      "Sharpe ratio: 0.296513521230166\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | -12.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 3.61        |\n",
      "|    reward             | 0.029962627 |\n",
      "|    std                | 6.61        |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81.8         |\n",
      "| time/                 |              |\n",
      "|    fps                | 18           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 1441         |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -110         |\n",
      "|    explained_variance | -8.08        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | 1.67         |\n",
      "|    reward             | 0.0060588904 |\n",
      "|    std                | 6.73         |\n",
      "|    value_loss         | 0.000507     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1470        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -110        |\n",
      "|    explained_variance | -8.36       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 0.489       |\n",
      "|    reward             | 0.016665379 |\n",
      "|    std                | 6.9         |\n",
      "|    value_loss         | 9.16e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 18          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1499        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -112        |\n",
      "|    explained_variance | -13.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.329       |\n",
      "|    reward             | 0.016631998 |\n",
      "|    std                | 7.12        |\n",
      "|    value_loss         | 6.18e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81.8         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 1528         |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -113         |\n",
      "|    explained_variance | -12.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 2.85         |\n",
      "|    reward             | 0.0057693445 |\n",
      "|    std                | 7.4          |\n",
      "|    value_loss         | 0.000771     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1558        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -114        |\n",
      "|    explained_variance | -9.73       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -0.173      |\n",
      "|    reward             | 0.011527853 |\n",
      "|    std                | 7.73        |\n",
      "|    value_loss         | 7.4e-06     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1586        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -116        |\n",
      "|    explained_variance | -0.483      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.241      |\n",
      "|    reward             | 0.010522467 |\n",
      "|    std                | 8.15        |\n",
      "|    value_loss         | 1.05e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1616        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | -73.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.291       |\n",
      "|    reward             | 0.013368486 |\n",
      "|    std                | 8.64        |\n",
      "|    value_loss         | 1.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1645        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | -12.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 0.819       |\n",
      "|    reward             | 0.014553745 |\n",
      "|    std                | 9.21        |\n",
      "|    value_loss         | 8.81e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1674        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -122        |\n",
      "|    explained_variance | -12.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.482       |\n",
      "|    reward             | 0.014493693 |\n",
      "|    std                | 9.8         |\n",
      "|    value_loss         | 7.33e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1891021.25\n",
      "Final accumulative portfolio value: 1.89102125\n",
      "Maximum DrawDown: -0.5658918564043617\n",
      "Sharpe ratio: 0.2537325670462551\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 81.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 1706       |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -123       |\n",
      "|    explained_variance | -471       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -0.114     |\n",
      "|    reward             | 0.02651162 |\n",
      "|    std                | 10.1       |\n",
      "|    value_loss         | 0.00121    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 1735         |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -124         |\n",
      "|    explained_variance | -28.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 1.96         |\n",
      "|    reward             | 0.0018991877 |\n",
      "|    std                | 10.3         |\n",
      "|    value_loss         | 0.000543     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1764        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -124        |\n",
      "|    explained_variance | -20.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.706       |\n",
      "|    reward             | 0.009713782 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.000174    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1793        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | 0.469       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 3.12        |\n",
      "|    reward             | 0.012297042 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.000625    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 81.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 1822          |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -127          |\n",
      "|    explained_variance | -9.44         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | 0.834         |\n",
      "|    reward             | -0.0014056173 |\n",
      "|    std                | 11.4          |\n",
      "|    value_loss         | 0.000344      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 1851         |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -128         |\n",
      "|    explained_variance | -8.73        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -0.424       |\n",
      "|    reward             | 0.0070736716 |\n",
      "|    std                | 11.9         |\n",
      "|    value_loss         | 2.45e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1880        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -130        |\n",
      "|    explained_variance | -89.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 0.175       |\n",
      "|    reward             | 0.007203512 |\n",
      "|    std                | 12.5        |\n",
      "|    value_loss         | 2e-05       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 1909        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -132        |\n",
      "|    explained_variance | -686        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.0947     |\n",
      "|    reward             | 0.012115027 |\n",
      "|    std                | 13.2        |\n",
      "|    value_loss         | 1.34e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 1938        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -134        |\n",
      "|    explained_variance | -6.01       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.499       |\n",
      "|    reward             | 0.013964174 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 3.45e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 1967        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -136        |\n",
      "|    explained_variance | -22.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -0.241      |\n",
      "|    reward             | 0.014694767 |\n",
      "|    std                | 14.9        |\n",
      "|    value_loss         | 1.68e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1872403.875\n",
      "Final accumulative portfolio value: 1.872403875\n",
      "Maximum DrawDown: -0.6045814175402964\n",
      "Sharpe ratio: 0.25156545789263346\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 78.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 1999       |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -137       |\n",
      "|    explained_variance | -1.26      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | -23.8      |\n",
      "|    reward             | 0.00421929 |\n",
      "|    std                | 15.4       |\n",
      "|    value_loss         | 0.035      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 78.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 2028          |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -138          |\n",
      "|    explained_variance | -3.93         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | -2            |\n",
      "|    reward             | -0.0014468994 |\n",
      "|    std                | 15.6          |\n",
      "|    value_loss         | 0.000289      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 2057        |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | -185        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 0.53        |\n",
      "|    reward             | 0.012212358 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 6.63e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 2086        |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -139        |\n",
      "|    explained_variance | -2.2        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.884      |\n",
      "|    reward             | 0.013277432 |\n",
      "|    std                | 16.5        |\n",
      "|    value_loss         | 4.77e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 78.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 2115          |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -141          |\n",
      "|    explained_variance | -553          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 1.35          |\n",
      "|    reward             | -0.0033920736 |\n",
      "|    std                | 17.3          |\n",
      "|    value_loss         | 0.000391      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 78.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 2144       |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -142       |\n",
      "|    explained_variance | -10.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -0.487     |\n",
      "|    reward             | 0.00757626 |\n",
      "|    std                | 18         |\n",
      "|    value_loss         | 2.21e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 78.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 2173       |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -144       |\n",
      "|    explained_variance | -621       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 0.457      |\n",
      "|    reward             | 0.00655018 |\n",
      "|    std                | 18.9       |\n",
      "|    value_loss         | 2e-05      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2202        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | -19.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 0.0735      |\n",
      "|    reward             | 0.011540223 |\n",
      "|    std                | 20          |\n",
      "|    value_loss         | 2.87e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 78.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 2231       |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -148       |\n",
      "|    explained_variance | -1.19e+03  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 0.482      |\n",
      "|    reward             | 0.01352636 |\n",
      "|    std                | 21.3       |\n",
      "|    value_loss         | 1.46e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2260        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | -357        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.28        |\n",
      "|    reward             | 0.014693986 |\n",
      "|    std                | 22.7        |\n",
      "|    value_loss         | 7.93e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1954794.5\n",
      "Final accumulative portfolio value: 1.9547945\n",
      "Maximum DrawDown: -0.6091750797550428\n",
      "Sharpe ratio: 0.2609426238836217\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 2292        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | 0.485       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -9.27       |\n",
      "|    reward             | 0.020141546 |\n",
      "|    std                | 23.6        |\n",
      "|    value_loss         | 0.00439     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 78.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 2320         |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -152         |\n",
      "|    explained_variance | -4.17        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -6.5         |\n",
      "|    reward             | -0.013117332 |\n",
      "|    std                | 24.1         |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2349        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -153        |\n",
      "|    explained_variance | -109        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.986       |\n",
      "|    reward             | 0.011873289 |\n",
      "|    std                | 24.6        |\n",
      "|    value_loss         | 9.43e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2378        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -29.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.871       |\n",
      "|    reward             | 0.013980106 |\n",
      "|    std                | 25.5        |\n",
      "|    value_loss         | 3.57e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 78.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 2407          |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -155          |\n",
      "|    explained_variance | -569          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -0.614        |\n",
      "|    reward             | -0.0022234009 |\n",
      "|    std                | 26.6          |\n",
      "|    value_loss         | 0.000173      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2436        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -157        |\n",
      "|    explained_variance | -3.92       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | 0.008792556 |\n",
      "|    std                | 27.8        |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 78.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 2465         |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -158         |\n",
      "|    explained_variance | -32.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 1.4          |\n",
      "|    reward             | 0.0070312787 |\n",
      "|    std                | 29.4         |\n",
      "|    value_loss         | 8.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 78.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 2494         |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -160         |\n",
      "|    explained_variance | -12.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -1.75        |\n",
      "|    reward             | 0.0123614585 |\n",
      "|    std                | 31.2         |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 78.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2523        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | -11.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 0.0854      |\n",
      "|    reward             | 0.012657859 |\n",
      "|    std                | 33.2        |\n",
      "|    value_loss         | 1.9e-06     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 78.1       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 2552       |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -164       |\n",
      "|    explained_variance | -205       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -1.34      |\n",
      "|    reward             | 0.01212521 |\n",
      "|    std                | 35.4       |\n",
      "|    value_loss         | 0.000114   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1829652.875\n",
      "Final accumulative portfolio value: 1.829652875\n",
      "Maximum DrawDown: -0.6060078695017173\n",
      "Sharpe ratio: 0.2465590941117489\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2584        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -166        |\n",
      "|    explained_variance | 0.577       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -17         |\n",
      "|    reward             | 0.029236084 |\n",
      "|    std                | 36.7        |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 77.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 9200          |\n",
      "|    time_elapsed       | 2612          |\n",
      "|    total_timesteps    | 46000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -166          |\n",
      "|    explained_variance | -96.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9199          |\n",
      "|    policy_loss        | -0.197        |\n",
      "|    reward             | -0.0022549087 |\n",
      "|    std                | 37.4          |\n",
      "|    value_loss         | 6.75e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 2642        |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -167        |\n",
      "|    explained_variance | -2.5        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | 0.012369686 |\n",
      "|    std                | 38.3        |\n",
      "|    value_loss         | 8.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2670        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -168        |\n",
      "|    explained_variance | -73.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -0.513      |\n",
      "|    reward             | 0.013931675 |\n",
      "|    std                | 39.6        |\n",
      "|    value_loss         | 3.27e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 77.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 2700          |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -170          |\n",
      "|    explained_variance | -76.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | -1.5          |\n",
      "|    reward             | -0.0032597976 |\n",
      "|    std                | 41.4          |\n",
      "|    value_loss         | 0.000746      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2728        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -171        |\n",
      "|    explained_variance | -1.64       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.921       |\n",
      "|    reward             | 0.008602052 |\n",
      "|    std                | 43.3        |\n",
      "|    value_loss         | 3.25e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 77.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 2757         |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -173         |\n",
      "|    explained_variance | -349         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.615        |\n",
      "|    reward             | 0.0064814053 |\n",
      "|    std                | 45.7         |\n",
      "|    value_loss         | 2.34e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2786        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -175        |\n",
      "|    explained_variance | -129        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.853      |\n",
      "|    reward             | 0.012182484 |\n",
      "|    std                | 48.5        |\n",
      "|    value_loss         | 3.74e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.03e+03  |\n",
      "|    ep_rew_mean        | 77.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 17        |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 2816      |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -177      |\n",
      "|    explained_variance | -709      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0.285    |\n",
      "|    reward             | 0.0120943 |\n",
      "|    std                | 51.7      |\n",
      "|    value_loss         | 1.17e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2845        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -179        |\n",
      "|    explained_variance | -4.74       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -0.809      |\n",
      "|    reward             | 0.012567608 |\n",
      "|    std                | 55.1        |\n",
      "|    value_loss         | 3.33e-05    |\n",
      "---------------------------------------\n",
      "Logging to ./data/tb\\a2c_29\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -75.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -2.22       |\n",
      "|    reward             | 0.025993828 |\n",
      "|    std                | 55.9        |\n",
      "|    value_loss         | 0.000902    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -180        |\n",
      "|    explained_variance | -8.88       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 3.99        |\n",
      "|    reward             | 0.014198448 |\n",
      "|    std                | 57.1        |\n",
      "|    value_loss         | 0.000615    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -181        |\n",
      "|    explained_variance | -6.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | 1.98        |\n",
      "|    reward             | 0.015293561 |\n",
      "|    std                | 58.8        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -182        |\n",
      "|    explained_variance | -21.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -0.0171     |\n",
      "|    reward             | 0.012074015 |\n",
      "|    std                | 61.1        |\n",
      "|    value_loss         | 2.53e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -184        |\n",
      "|    explained_variance | -64.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | -1.11       |\n",
      "|    reward             | 0.007699869 |\n",
      "|    std                | 63.9        |\n",
      "|    value_loss         | 6.76e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -186        |\n",
      "|    explained_variance | -47.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 0.17        |\n",
      "|    reward             | 0.008611513 |\n",
      "|    std                | 67.3        |\n",
      "|    value_loss         | 6.62e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -188        |\n",
      "|    explained_variance | -4.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 0.732       |\n",
      "|    reward             | 0.012324796 |\n",
      "|    std                | 71.4        |\n",
      "|    value_loss         | 3.15e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -190        |\n",
      "|    explained_variance | -153        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -0.68       |\n",
      "|    reward             | 0.013395082 |\n",
      "|    std                | 75.8        |\n",
      "|    value_loss         | 2.14e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -192       |\n",
      "|    explained_variance | -4.11e+03  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -0.838     |\n",
      "|    reward             | 0.01717942 |\n",
      "|    std                | 80.8       |\n",
      "|    value_loss         | 2.36e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -194       |\n",
      "|    explained_variance | -23.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10999      |\n",
      "|    policy_loss        | -0.325     |\n",
      "|    reward             | 0.01724067 |\n",
      "|    std                | 85.9       |\n",
      "|    value_loss         | 2.65e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2187445.75\n",
      "Final accumulative portfolio value: 2.18744575\n",
      "Maximum DrawDown: -0.5687301031632795\n",
      "Sharpe ratio: 0.28558443155629476\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -194        |\n",
      "|    explained_variance | -52         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | -9.58       |\n",
      "|    reward             | 0.020792682 |\n",
      "|    std                | 87.1        |\n",
      "|    value_loss         | 0.00413     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -195        |\n",
      "|    explained_variance | -1.48       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 0.346       |\n",
      "|    reward             | 0.015327602 |\n",
      "|    std                | 88.9        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -196        |\n",
      "|    explained_variance | -20.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | 1.88        |\n",
      "|    reward             | 0.018461091 |\n",
      "|    std                | 91.4        |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -197        |\n",
      "|    explained_variance | -1.04e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 3.05        |\n",
      "|    reward             | 0.015146403 |\n",
      "|    std                | 95          |\n",
      "|    value_loss         | 0.000304    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -198        |\n",
      "|    explained_variance | -42         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 0.435       |\n",
      "|    reward             | 0.007822826 |\n",
      "|    std                | 98.9        |\n",
      "|    value_loss         | 1.38e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -200        |\n",
      "|    explained_variance | -477        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | 2.07        |\n",
      "|    reward             | 0.008784153 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 495         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -202        |\n",
      "|    explained_variance | -2.14e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | -1.39       |\n",
      "|    reward             | 0.012510206 |\n",
      "|    std                | 109         |\n",
      "|    value_loss         | 5.75e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -204        |\n",
      "|    explained_variance | -21.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.014230166 |\n",
      "|    std                | 116         |\n",
      "|    value_loss         | 4.08e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 554         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -206        |\n",
      "|    explained_variance | -15         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.017106084 |\n",
      "|    std                | 124         |\n",
      "|    value_loss         | 6.12e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -208        |\n",
      "|    explained_variance | -97.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -1.23       |\n",
      "|    reward             | 0.016714165 |\n",
      "|    std                | 132         |\n",
      "|    value_loss         | 5.62e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2125087.75\n",
      "Final accumulative portfolio value: 2.12508775\n",
      "Maximum DrawDown: -0.585470467218528\n",
      "Sharpe ratio: 0.27926899820424755\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 614         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -208        |\n",
      "|    explained_variance | -0.494      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -3.87       |\n",
      "|    reward             | 0.005092031 |\n",
      "|    std                | 134         |\n",
      "|    value_loss         | 0.000964    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -209        |\n",
      "|    explained_variance | -7.84       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 4.07        |\n",
      "|    reward             | 0.013402361 |\n",
      "|    std                | 136         |\n",
      "|    value_loss         | 0.000577    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 672         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -210        |\n",
      "|    explained_variance | -13.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | -0.381      |\n",
      "|    reward             | 0.012902857 |\n",
      "|    std                | 140         |\n",
      "|    value_loss         | 3.26e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 701         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -211        |\n",
      "|    explained_variance | -58.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 0.179       |\n",
      "|    reward             | 0.015127366 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 7.07e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 91.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 730          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -213         |\n",
      "|    explained_variance | -4.39        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | 0.0059735174 |\n",
      "|    std                | 152          |\n",
      "|    value_loss         | 6.74e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 759         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -214        |\n",
      "|    explained_variance | -3.55       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | 0.006077726 |\n",
      "|    std                | 160         |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 788         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -216        |\n",
      "|    explained_variance | -186        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -1.22       |\n",
      "|    reward             | 0.009597561 |\n",
      "|    std                | 169         |\n",
      "|    value_loss         | 4.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 817         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -218        |\n",
      "|    explained_variance | -0.232      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | 2.01        |\n",
      "|    reward             | 0.010591451 |\n",
      "|    std                | 179         |\n",
      "|    value_loss         | 9.86e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 847         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -220        |\n",
      "|    explained_variance | -38.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | 0.785       |\n",
      "|    reward             | 0.014566021 |\n",
      "|    std                | 191         |\n",
      "|    value_loss         | 1.49e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 876         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -222        |\n",
      "|    explained_variance | -109        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | -1.81       |\n",
      "|    reward             | 0.015644647 |\n",
      "|    std                | 204         |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1947547.625\n",
      "Final accumulative portfolio value: 1.947547625\n",
      "Maximum DrawDown: -0.5863194629913495\n",
      "Sharpe ratio: 0.26014830231445996\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 908         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -223        |\n",
      "|    explained_variance | -5.35       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | -6.1        |\n",
      "|    reward             | 0.010165394 |\n",
      "|    std                | 209         |\n",
      "|    value_loss         | 0.000853    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 937         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -224        |\n",
      "|    explained_variance | -0.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 5.24        |\n",
      "|    reward             | 0.014896289 |\n",
      "|    std                | 213         |\n",
      "|    value_loss         | 0.000717    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 965         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -225        |\n",
      "|    explained_variance | -40.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | -2.06       |\n",
      "|    reward             | 0.017811185 |\n",
      "|    std                | 219         |\n",
      "|    value_loss         | 9.66e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 995         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -226        |\n",
      "|    explained_variance | -1.61e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | 0.016436478 |\n",
      "|    std                | 228         |\n",
      "|    value_loss         | 7.84e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 86.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 1024         |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -227         |\n",
      "|    explained_variance | -0.638       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 3.51         |\n",
      "|    reward             | 0.0070545324 |\n",
      "|    std                | 238          |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -229        |\n",
      "|    explained_variance | -22.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | 0.133       |\n",
      "|    reward             | 0.008189856 |\n",
      "|    std                | 250         |\n",
      "|    value_loss         | 4.22e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 86.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 1082         |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -231         |\n",
      "|    explained_variance | -10.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -0.598       |\n",
      "|    reward             | 0.0120232515 |\n",
      "|    std                | 265          |\n",
      "|    value_loss         | 2.11e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1111        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -233        |\n",
      "|    explained_variance | -34.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -2.66       |\n",
      "|    reward             | 0.013995563 |\n",
      "|    std                | 282         |\n",
      "|    value_loss         | 0.0002      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1140        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -235        |\n",
      "|    explained_variance | -13.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | 0.016523385 |\n",
      "|    std                | 301         |\n",
      "|    value_loss         | 1.84e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1169        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -237        |\n",
      "|    explained_variance | -154        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.584      |\n",
      "|    reward             | 0.017662035 |\n",
      "|    std                | 319         |\n",
      "|    value_loss         | 9.62e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2194215.25\n",
      "Final accumulative portfolio value: 2.19421525\n",
      "Maximum DrawDown: -0.5747360056562341\n",
      "Sharpe ratio: 0.28633038999263044\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1200        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -238        |\n",
      "|    explained_variance | -7.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 0.371       |\n",
      "|    reward             | 0.017520895 |\n",
      "|    std                | 327         |\n",
      "|    value_loss         | 0.000297    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 85.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 1229         |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -239         |\n",
      "|    explained_variance | -17.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | 3.08         |\n",
      "|    reward             | 0.0052852356 |\n",
      "|    std                | 335          |\n",
      "|    value_loss         | 0.000389     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 1258        |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -239        |\n",
      "|    explained_variance | -2.59       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | -0.875      |\n",
      "|    reward             | 0.014440689 |\n",
      "|    std                | 344         |\n",
      "|    value_loss         | 3.51e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1287        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -241        |\n",
      "|    explained_variance | -520        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | 2.42        |\n",
      "|    reward             | 0.016274229 |\n",
      "|    std                | 358         |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 85.2          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 1316          |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -242          |\n",
      "|    explained_variance | -115          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14499         |\n",
      "|    policy_loss        | -7.45         |\n",
      "|    reward             | 0.00083964894 |\n",
      "|    std                | 374           |\n",
      "|    value_loss         | 0.00114       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1345        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -244        |\n",
      "|    explained_variance | -29         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | 1.5         |\n",
      "|    reward             | 0.006133975 |\n",
      "|    std                | 391         |\n",
      "|    value_loss         | 5.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1374        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -245        |\n",
      "|    explained_variance | -307        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 1.97        |\n",
      "|    reward             | 0.006752789 |\n",
      "|    std                | 412         |\n",
      "|    value_loss         | 7.33e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 1403        |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -247        |\n",
      "|    explained_variance | -85.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.81        |\n",
      "|    reward             | 0.009823663 |\n",
      "|    std                | 438         |\n",
      "|    value_loss         | 2.51e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -250        |\n",
      "|    explained_variance | -146        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -1.36       |\n",
      "|    reward             | 0.012416685 |\n",
      "|    std                | 467         |\n",
      "|    value_loss         | 3.78e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 1461        |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -252        |\n",
      "|    explained_variance | -39.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 0.461       |\n",
      "|    reward             | 0.012947661 |\n",
      "|    std                | 498         |\n",
      "|    value_loss         | 1.2e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1710217.875\n",
      "Final accumulative portfolio value: 1.710217875\n",
      "Maximum DrawDown: -0.6067320341206819\n",
      "Sharpe ratio: 0.23181954398840077\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1494        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -253        |\n",
      "|    explained_variance | -5.26       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 6.15        |\n",
      "|    reward             | 0.019272989 |\n",
      "|    std                | 511         |\n",
      "|    value_loss         | 0.000818    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81.3         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 1523         |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -253         |\n",
      "|    explained_variance | -4.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | 3.1          |\n",
      "|    reward             | 0.0046513746 |\n",
      "|    std                | 522          |\n",
      "|    value_loss         | 0.000415     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1551        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -254        |\n",
      "|    explained_variance | -1.77       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 2.69        |\n",
      "|    reward             | 0.015286417 |\n",
      "|    std                | 537         |\n",
      "|    value_loss         | 0.000144    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1581        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -255        |\n",
      "|    explained_variance | -4.55       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | 0.016548408 |\n",
      "|    std                | 558         |\n",
      "|    value_loss         | 4.93e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 81.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 1609       |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -257       |\n",
      "|    explained_variance | -2.16      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15499      |\n",
      "|    policy_loss        | 4.94       |\n",
      "|    reward             | 0.00506605 |\n",
      "|    std                | 584        |\n",
      "|    value_loss         | 0.000415   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 1639        |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -259        |\n",
      "|    explained_variance | -5.9        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -0.295      |\n",
      "|    reward             | 0.011846762 |\n",
      "|    std                | 614         |\n",
      "|    value_loss         | 7.79e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1667        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -260        |\n",
      "|    explained_variance | 0.355       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 0.802       |\n",
      "|    reward             | 0.011823327 |\n",
      "|    std                | 651         |\n",
      "|    value_loss         | 1.28e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1696        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -263        |\n",
      "|    explained_variance | -6.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -0.496      |\n",
      "|    reward             | 0.015215708 |\n",
      "|    std                | 692         |\n",
      "|    value_loss         | 1.44e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81.3        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1726        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -265        |\n",
      "|    explained_variance | -55.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 1.76        |\n",
      "|    reward             | 0.016802806 |\n",
      "|    std                | 738         |\n",
      "|    value_loss         | 7.82e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 81.3       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 1755       |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -267       |\n",
      "|    explained_variance | -7.59      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | 1.78       |\n",
      "|    reward             | 0.01672244 |\n",
      "|    std                | 787        |\n",
      "|    value_loss         | 0.000156   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2266667.5\n",
      "Final accumulative portfolio value: 2.2666675\n",
      "Maximum DrawDown: -0.5557637968320873\n",
      "Sharpe ratio: 0.29338904039711416\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 1786        |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -268        |\n",
      "|    explained_variance | -6.7        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | -7.95       |\n",
      "|    reward             | 0.034052752 |\n",
      "|    std                | 810         |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 80.6         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 1815         |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -268         |\n",
      "|    explained_variance | -0.385       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | -2.92        |\n",
      "|    reward             | 0.0073579615 |\n",
      "|    std                | 826          |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 80.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 1844       |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -269       |\n",
      "|    explained_variance | -4.49      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16299      |\n",
      "|    policy_loss        | 4.12       |\n",
      "|    reward             | 0.01813415 |\n",
      "|    std                | 848        |\n",
      "|    value_loss         | 0.000278   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1873        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -270        |\n",
      "|    explained_variance | -54.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | 2.6         |\n",
      "|    reward             | 0.021344347 |\n",
      "|    std                | 877         |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 1902        |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -272        |\n",
      "|    explained_variance | -5.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | 4.02        |\n",
      "|    reward             | 0.006637155 |\n",
      "|    std                | 914         |\n",
      "|    value_loss         | 0.000409    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1931        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -273        |\n",
      "|    explained_variance | -42         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | 1.49        |\n",
      "|    reward             | 0.014446539 |\n",
      "|    std                | 952         |\n",
      "|    value_loss         | 6e-05       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 1960        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -275        |\n",
      "|    explained_variance | -174        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 0.455       |\n",
      "|    reward             | 0.011847613 |\n",
      "|    std                | 1e+03       |\n",
      "|    value_loss         | 7.47e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 80.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 1989       |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -277       |\n",
      "|    explained_variance | -10.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16799      |\n",
      "|    policy_loss        | -3.83      |\n",
      "|    reward             | 0.01704918 |\n",
      "|    std                | 1.07e+03   |\n",
      "|    value_loss         | 0.000292   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 2018        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -279        |\n",
      "|    explained_variance | -19.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | 0.821       |\n",
      "|    reward             | 0.017146988 |\n",
      "|    std                | 1.13e+03    |\n",
      "|    value_loss         | 1.79e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 2047        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -281        |\n",
      "|    explained_variance | -220        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -1.83       |\n",
      "|    reward             | 0.017275708 |\n",
      "|    std                | 1.21e+03    |\n",
      "|    value_loss         | 5.86e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2300937.0\n",
      "Final accumulative portfolio value: 2.300937\n",
      "Maximum DrawDown: -0.5643835050580035\n",
      "Sharpe ratio: 0.29637488216422464\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 2079        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -282        |\n",
      "|    explained_variance | -1.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | -78.5       |\n",
      "|    reward             | 0.024697373 |\n",
      "|    std                | 1.24e+03    |\n",
      "|    value_loss         | 0.0829      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 2108        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -282        |\n",
      "|    explained_variance | -11.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17199       |\n",
      "|    policy_loss        | 8.69        |\n",
      "|    reward             | 0.004440517 |\n",
      "|    std                | 1.26e+03    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 2137        |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -283        |\n",
      "|    explained_variance | -225        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 2.53        |\n",
      "|    reward             | 0.017780526 |\n",
      "|    std                | 1.3e+03     |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 83.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 2166       |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -284       |\n",
      "|    explained_variance | -2.66      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | -3.36      |\n",
      "|    reward             | 0.01892982 |\n",
      "|    std                | 1.34e+03   |\n",
      "|    value_loss         | 0.000149   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 83.6         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 2196         |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -286         |\n",
      "|    explained_variance | -166         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | 8.69         |\n",
      "|    reward             | 0.0017663555 |\n",
      "|    std                | 1.4e+03      |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 2225        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -287        |\n",
      "|    explained_variance | -1.95       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | -5.02       |\n",
      "|    reward             | 0.012485886 |\n",
      "|    std                | 1.46e+03    |\n",
      "|    value_loss         | 0.00031     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2254        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -289        |\n",
      "|    explained_variance | -10.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | 0.010995124 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 1.99e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2283        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -291        |\n",
      "|    explained_variance | -28.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | -0.904      |\n",
      "|    reward             | 0.015733406 |\n",
      "|    std                | 1.63e+03    |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2313        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -293        |\n",
      "|    explained_variance | -22.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.016498568 |\n",
      "|    std                | 1.73e+03    |\n",
      "|    value_loss         | 1.4e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 83.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2342        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -295        |\n",
      "|    explained_variance | -2.31       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 0.875       |\n",
      "|    reward             | 0.016822498 |\n",
      "|    std                | 1.85e+03    |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2267663.25\n",
      "Final accumulative portfolio value: 2.26766325\n",
      "Maximum DrawDown: -0.5701599372268966\n",
      "Sharpe ratio: 0.2929350385218371\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 2373        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -296        |\n",
      "|    explained_variance | -0.377      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | -22         |\n",
      "|    reward             | 0.013016184 |\n",
      "|    std                | 1.91e+03    |\n",
      "|    value_loss         | 0.00645     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 86.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 2402         |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -297         |\n",
      "|    explained_variance | -6.77        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | 6.26         |\n",
      "|    reward             | -0.012163504 |\n",
      "|    std                | 1.95e+03     |\n",
      "|    value_loss         | 0.000814     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2431        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -298        |\n",
      "|    explained_variance | -101        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | -3.33       |\n",
      "|    reward             | 0.011301492 |\n",
      "|    std                | 2e+03       |\n",
      "|    value_loss         | 0.000173    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2460        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -299        |\n",
      "|    explained_variance | -345        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 0.951       |\n",
      "|    reward             | 0.014318063 |\n",
      "|    std                | 2.07e+03    |\n",
      "|    value_loss         | 3.09e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 86.2          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 2489          |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -300          |\n",
      "|    explained_variance | -35.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18499         |\n",
      "|    policy_loss        | -6.94         |\n",
      "|    reward             | 0.00078044215 |\n",
      "|    std                | 2.17e+03      |\n",
      "|    value_loss         | 0.00109       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2518        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -302        |\n",
      "|    explained_variance | -2.93       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | 1.88        |\n",
      "|    reward             | 0.010794679 |\n",
      "|    std                | 2.26e+03    |\n",
      "|    value_loss         | 5.39e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 86.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 2548       |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -303       |\n",
      "|    explained_variance | -91.8      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18699      |\n",
      "|    policy_loss        | 1.8        |\n",
      "|    reward             | 0.01023942 |\n",
      "|    std                | 2.39e+03   |\n",
      "|    value_loss         | 4.8e-05    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2577        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -305        |\n",
      "|    explained_variance | -149        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -3.77       |\n",
      "|    reward             | 0.015876839 |\n",
      "|    std                | 2.54e+03    |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2606        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -307        |\n",
      "|    explained_variance | -10.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 0.191       |\n",
      "|    reward             | 0.015770327 |\n",
      "|    std                | 2.7e+03     |\n",
      "|    value_loss         | 3.78e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 86.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 2635        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -309        |\n",
      "|    explained_variance | -13.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | -0.717      |\n",
      "|    reward             | 0.015883796 |\n",
      "|    std                | 2.87e+03    |\n",
      "|    value_loss         | 4.32e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2339712.75\n",
      "Final accumulative portfolio value: 2.33971275\n",
      "Maximum DrawDown: -0.5639338765990637\n",
      "Sharpe ratio: 0.3003749275107095\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 2667        |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -311        |\n",
      "|    explained_variance | -1.7        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | -21.1       |\n",
      "|    reward             | 0.035017822 |\n",
      "|    std                | 2.98e+03    |\n",
      "|    value_loss         | 0.00742     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 84.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 2695       |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -311       |\n",
      "|    explained_variance | -4.8       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19199      |\n",
      "|    policy_loss        | 3.07       |\n",
      "|    reward             | 0.00436032 |\n",
      "|    std                | 3.03e+03   |\n",
      "|    value_loss         | 0.000199   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 2724        |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -312        |\n",
      "|    explained_variance | -3.86       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | 0.342       |\n",
      "|    reward             | 0.017548777 |\n",
      "|    std                | 3.11e+03    |\n",
      "|    value_loss         | 3.87e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2753        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -313        |\n",
      "|    explained_variance | -14.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -2.39       |\n",
      "|    reward             | 0.017299632 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 7.75e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 84.7          |\n",
      "| time/                 |               |\n",
      "|    fps                | 17            |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 2782          |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -315          |\n",
      "|    explained_variance | -125          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19499         |\n",
      "|    policy_loss        | 1.73          |\n",
      "|    reward             | -0.0005322706 |\n",
      "|    std                | 3.37e+03      |\n",
      "|    value_loss         | 0.000727      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2811        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -316        |\n",
      "|    explained_variance | -8.56       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | 0.933       |\n",
      "|    reward             | 0.009974409 |\n",
      "|    std                | 3.53e+03    |\n",
      "|    value_loss         | 1.02e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 2840        |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -318        |\n",
      "|    explained_variance | -611        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | -0.362      |\n",
      "|    reward             | 0.008127746 |\n",
      "|    std                | 3.72e+03    |\n",
      "|    value_loss         | 6.34e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2869        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -320        |\n",
      "|    explained_variance | -3.8e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | 0.013832118 |\n",
      "|    std                | 3.95e+03    |\n",
      "|    value_loss         | 2.12e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2898        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -322        |\n",
      "|    explained_variance | -8.27       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -4.4        |\n",
      "|    reward             | 0.014784093 |\n",
      "|    std                | 4.21e+03    |\n",
      "|    value_loss         | 0.000186    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2928        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -324        |\n",
      "|    explained_variance | -12.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -2.64       |\n",
      "|    reward             | 0.015470627 |\n",
      "|    std                | 4.48e+03    |\n",
      "|    value_loss         | 8.8e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1808685.25\n",
      "Final accumulative portfolio value: 1.80868525\n",
      "Maximum DrawDown: -0.32273411125985585\n",
      "Sharpe ratio: 0.6431561467737624\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_36\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 45          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 45          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.008230815 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008725733  |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.9        |\n",
      "|    explained_variance   | -1.81        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.532       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0274      |\n",
      "|    reward               | -0.007069664 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.00253      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2593633.0\n",
      "Final accumulative portfolio value: 2.593633\n",
      "Maximum DrawDown: -0.5402808283308164\n",
      "Sharpe ratio: 0.3224749533570709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009068876 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | -0.0875     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.518      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    reward               | 0.01058146  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011323486 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | -0.0501     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.519      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    reward               | 0.010058194 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00167     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2389112.0\n",
      "Final accumulative portfolio value: 2.389112\n",
      "Maximum DrawDown: -0.5673218993022681\n",
      "Sharpe ratio: 0.3047994866882821\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.914        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009614308  |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.2        |\n",
      "|    explained_variance   | -0.00843     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.525       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0265      |\n",
      "|    reward               | -0.012415815 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0014       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010209666 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | -0.0254     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.516      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    reward               | -0.00947991 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000687    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.914        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 329          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013304936  |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.3        |\n",
      "|    explained_variance   | 0.000715     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.525       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0364      |\n",
      "|    reward               | -0.009758246 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00195      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2511190.5\n",
      "Final accumulative portfolio value: 2.5111905\n",
      "Maximum DrawDown: -0.5826797898842138\n",
      "Sharpe ratio: 0.3161075197880237\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.916        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009808127  |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | -0.00735     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.536       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0268      |\n",
      "|    reward               | 0.0039016092 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.000906     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.916        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 425          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013449429  |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | 0.0348       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.548       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0414      |\n",
      "|    reward               | 0.0029181535 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.00158      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2598228.5\n",
      "Final accumulative portfolio value: 2.5982285\n",
      "Maximum DrawDown: -0.5783583139841129\n",
      "Sharpe ratio: 0.3232548541977723\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.926       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012667948 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.00693     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    reward               | 0.001434727 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00146     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.926         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 521           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011383369   |\n",
      "|    clip_fraction        | 0.0977        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.6         |\n",
      "|    explained_variance   | 0.00827       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.523        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.0352       |\n",
      "|    reward               | -0.0017884263 |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.000812      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.926        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 568          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011408264  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.7        |\n",
      "|    explained_variance   | 0.0103       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.526       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    reward               | 0.0015230495 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00192      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2227265.0\n",
      "Final accumulative portfolio value: 2.227265\n",
      "Maximum DrawDown: -0.5453577985394313\n",
      "Sharpe ratio: 0.29005613246379386\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.902       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009324385 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.00394     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.53       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    reward               | 0.004898333 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.000671    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.902        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014041016  |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.8        |\n",
      "|    explained_variance   | 0.043        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.532       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0402      |\n",
      "|    reward               | -0.006617639 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2437233.75\n",
      "Final accumulative portfolio value: 2.43723375\n",
      "Maximum DrawDown: -0.5358117547476664\n",
      "Sharpe ratio: 0.3095856832881593\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012626955 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.522      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    reward               | -0.01860492 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00134     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 764          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01099222   |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48          |\n",
      "|    explained_variance   | 0.0109       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.532       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0367      |\n",
      "|    reward               | -0.036369417 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.00123      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014247665 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.549      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    reward               | 0.005101402 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.00168     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2683664.75\n",
      "Final accumulative portfolio value: 2.68366475\n",
      "Maximum DrawDown: -0.5475390497002127\n",
      "Sharpe ratio: 0.3303628574663426\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.913        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 862          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010614761  |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.1        |\n",
      "|    explained_variance   | -0.00363     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.535       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    reward               | -0.003932689 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.000662     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.913        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 909          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014780251  |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.2        |\n",
      "|    explained_variance   | 0.0475       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.548       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0428      |\n",
      "|    reward               | 0.0008372139 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00166      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1900211.625\n",
      "Final accumulative portfolio value: 1.900211625\n",
      "Maximum DrawDown: -0.6246736893300322\n",
      "Sharpe ratio: 0.25491242752249965\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.879         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 960           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013465779   |\n",
      "|    clip_fraction        | 0.108         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.4         |\n",
      "|    explained_variance   | 0.0222        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.55         |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.0346       |\n",
      "|    reward               | -0.0048862672 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.0014        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.879        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1007         |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015349539  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.5        |\n",
      "|    explained_variance   | 0.0362       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.551       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    reward               | 0.0032351082 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.00153      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.879       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012986357 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.542      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    reward               | 0.006197402 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00138     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2310496.0\n",
      "Final accumulative portfolio value: 2.310496\n",
      "Maximum DrawDown: -0.5395346580346676\n",
      "Sharpe ratio: 0.29762647335263237\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.875        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1103         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011888406  |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.8        |\n",
      "|    explained_variance   | -0.0012      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.528       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0287      |\n",
      "|    reward               | -0.009968268 |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.000683     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.875         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 1151          |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014872407   |\n",
      "|    clip_fraction        | 0.14          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.9         |\n",
      "|    explained_variance   | 0.0461        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.552        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.0453       |\n",
      "|    reward               | -0.0121445805 |\n",
      "|    std                  | 1.07          |\n",
      "|    value_loss           | 0.00146       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2881685.0\n",
      "Final accumulative portfolio value: 2.881685\n",
      "Maximum DrawDown: -0.5636059035506173\n",
      "Sharpe ratio: 0.34569815773941714\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.893       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1201        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01303723  |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.548      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    reward               | 0.012242531 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.00138     |\n",
      "-----------------------------------------\n",
      "Logging to ./data/tb\\ppo_37\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 45          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 45          |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.005038778 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014802302  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.1        |\n",
      "|    explained_variance   | 0.0592       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.551       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0425      |\n",
      "|    reward               | -0.008382426 |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.00153      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2379853.25\n",
      "Final accumulative portfolio value: 2.37985325\n",
      "Maximum DrawDown: -0.5741242149671031\n",
      "Sharpe ratio: 0.3040268536156757\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.869       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013705546 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.0345      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    reward               | 0.010951887 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00136     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.869       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015866295 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0415      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.564      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    reward               | 0.012340618 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2213871.5\n",
      "Final accumulative portfolio value: 2.2138715\n",
      "Maximum DrawDown: -0.5522485010081457\n",
      "Sharpe ratio: 0.2879378544465591\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.832         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 241           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013900459   |\n",
      "|    clip_fraction        | 0.118         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49.4         |\n",
      "|    explained_variance   | 0.0196        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.535        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.0364       |\n",
      "|    reward               | -0.0124610765 |\n",
      "|    std                  | 1.08          |\n",
      "|    value_loss           | 0.00142       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.832         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 290           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.013809597   |\n",
      "|    clip_fraction        | 0.125         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49.5         |\n",
      "|    explained_variance   | 0.0149        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.564        |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.0386       |\n",
      "|    reward               | -0.0052426555 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.000734      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.832         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 338           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015160416   |\n",
      "|    clip_fraction        | 0.148         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49.5         |\n",
      "|    explained_variance   | 0.0236        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.549        |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.043        |\n",
      "|    reward               | -0.0071914666 |\n",
      "|    std                  | 1.09          |\n",
      "|    value_loss           | 0.002         |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2589421.75\n",
      "Final accumulative portfolio value: 2.58942175\n",
      "Maximum DrawDown: -0.5784490135406966\n",
      "Sharpe ratio: 0.32279776824583917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.873       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013113423 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | -0.00436    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.542      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    reward               | 0.003097738 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.000903    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.873        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014422679  |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.0572       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.563       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0426      |\n",
      "|    reward               | 0.0039481563 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.0015       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2086268.125\n",
      "Final accumulative portfolio value: 2.086268125\n",
      "Maximum DrawDown: -0.5558293355226596\n",
      "Sharpe ratio: 0.2755803016143452\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.839        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 484          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015410349  |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.8        |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.534       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    reward               | 0.0057264795 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.00139      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.839         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 530           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012788509   |\n",
      "|    clip_fraction        | 0.121         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49.9         |\n",
      "|    explained_variance   | 0.0322        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.569        |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.0385       |\n",
      "|    reward               | -0.0046956344 |\n",
      "|    std                  | 1.1           |\n",
      "|    value_loss           | 0.000854      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 5.03e+03       |\n",
      "|    ep_rew_mean          | 0.839          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 42             |\n",
      "|    iterations           | 12             |\n",
      "|    time_elapsed         | 576            |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.01605514     |\n",
      "|    clip_fraction        | 0.138          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -50            |\n",
      "|    explained_variance   | 0.0199         |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | -0.56          |\n",
      "|    n_updates            | 360            |\n",
      "|    policy_gradient_loss | -0.0408        |\n",
      "|    reward               | -0.00018842804 |\n",
      "|    std                  | 1.1            |\n",
      "|    value_loss           | 0.00199        |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2771035.5\n",
      "Final accumulative portfolio value: 2.7710355\n",
      "Maximum DrawDown: -0.5593510011760927\n",
      "Sharpe ratio: 0.33721220165821936\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.875        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 629          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012135511  |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.1        |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.56        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0317      |\n",
      "|    reward               | 0.0056029656 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.00068      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.875         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 677           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.015751636   |\n",
      "|    clip_fraction        | 0.149         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -50.2         |\n",
      "|    explained_variance   | 0.0561        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.546        |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.0447       |\n",
      "|    reward               | -0.0059055677 |\n",
      "|    std                  | 1.11          |\n",
      "|    value_loss           | 0.00161       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2850780.0\n",
      "Final accumulative portfolio value: 2.85078\n",
      "Maximum DrawDown: -0.5802779725963707\n",
      "Sharpe ratio: 0.34294740102034715\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.904        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 726          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014223998  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.3        |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.547       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0373      |\n",
      "|    reward               | -0.014095418 |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.00146      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.904        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 775          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015273688  |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.4        |\n",
      "|    explained_variance   | 0.0163       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.556       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0441      |\n",
      "|    reward               | -0.039185345 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.00115      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.904        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016364995  |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.5        |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.573       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0447      |\n",
      "|    reward               | 0.0050352192 |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.00175      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2031834.125\n",
      "Final accumulative portfolio value: 2.031834125\n",
      "Maximum DrawDown: -0.5979460844121358\n",
      "Sharpe ratio: 0.2695358545567459\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 0.877         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 42            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 873           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012385306   |\n",
      "|    clip_fraction        | 0.11          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -50.6         |\n",
      "|    explained_variance   | 0.00547       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.556        |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.0328       |\n",
      "|    reward               | -0.0028107888 |\n",
      "|    std                  | 1.12          |\n",
      "|    value_loss           | 0.000657      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.877       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 921         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017104283 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    reward               | 0.002214957 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.00166     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2779956.0\n",
      "Final accumulative portfolio value: 2.779956\n",
      "Maximum DrawDown: -0.551477032331128\n",
      "Sharpe ratio: 0.33819743000563557\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.895        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 972          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014120704  |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.8        |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.573       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0383      |\n",
      "|    reward               | -0.004753904 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.00137      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.895        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1020         |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01378086   |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.9        |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.574       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.043       |\n",
      "|    reward               | 0.0030131198 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.00151      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 0.895       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014112122 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.571      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | 0.004610503 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.00143     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2540720.0\n",
      "Final accumulative portfolio value: 2.54072\n",
      "Maximum DrawDown: -0.5473347642188371\n",
      "Sharpe ratio: 0.3183565199105171\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.899        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011409033  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.1        |\n",
      "|    explained_variance   | 0.00235      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.557       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0326      |\n",
      "|    reward               | -0.010732219 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.000689     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.899        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1165         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016068432  |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.2        |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.587       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0459      |\n",
      "|    reward               | -0.011921977 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.00152      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2571422.25\n",
      "Final accumulative portfolio value: 2.57142225\n",
      "Maximum DrawDown: -0.6046191656386155\n",
      "Sharpe ratio: 0.3207630631659514\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 0.904        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1215         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125154685 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.3        |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.574       |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    reward               | 0.012446469  |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 0.00153      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1742684.75\n",
      "Final accumulative portfolio value: 1.74268475\n",
      "Maximum DrawDown: -0.32180836510006816\n",
      "Sharpe ratio: 0.6062987848060102\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_30\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -47.9        |\n",
      "|    explained_variance | -5.83        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | 1.93         |\n",
      "|    reward             | 0.0035204834 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.00252      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 40            |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.6         |\n",
      "|    explained_variance | 0.262         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | 0.954         |\n",
      "|    reward             | -0.0033062454 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000422      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -49.6        |\n",
      "|    explained_variance | -0.494       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.697       |\n",
      "|    reward             | -0.008235357 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.000211     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.8       |\n",
      "|    explained_variance | -0.152      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.409       |\n",
      "|    reward             | 0.009067902 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.000145    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52          |\n",
      "|    explained_variance | -0.0765      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.35         |\n",
      "|    reward             | 0.0049714046 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.2       |\n",
      "|    explained_variance | 0.407       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | 0.015522966 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.00105     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -54.6       |\n",
      "|    explained_variance | 0.653       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.271       |\n",
      "|    reward             | 0.010617788 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 3.2e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.2        |\n",
      "|    explained_variance | -0.134       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.611        |\n",
      "|    reward             | -0.011259829 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -57.7        |\n",
      "|    explained_variance | 0.352        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | -0.008590236 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 2.35e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 40            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 122           |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.2         |\n",
      "|    explained_variance | -4.35         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.17          |\n",
      "|    reward             | -0.0046384456 |\n",
      "|    std                | 1.46          |\n",
      "|    value_loss         | 1.62e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2188643.0\n",
      "Final accumulative portfolio value: 2.188643\n",
      "Maximum DrawDown: -0.5796497794002009\n",
      "Sharpe ratio: 0.28543387447281005\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.785        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.4        |\n",
      "|    explained_variance | -1.85        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.971       |\n",
      "|    reward             | -0.024211643 |\n",
      "|    std                | 1.51         |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.785       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -61.4       |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -1.4        |\n",
      "|    reward             | 0.015541395 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 0.000605    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.785         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.6         |\n",
      "|    explained_variance | -3.41         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.593         |\n",
      "|    reward             | 0.00035970894 |\n",
      "|    std                | 1.61          |\n",
      "|    value_loss         | 0.000117      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.785       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -64         |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0293      |\n",
      "|    reward             | 0.025429321 |\n",
      "|    std                | 1.68        |\n",
      "|    value_loss         | 7.34e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.785        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.3        |\n",
      "|    explained_variance | 0.0676       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -2.09        |\n",
      "|    reward             | 0.0027287889 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.785        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.5        |\n",
      "|    explained_variance | -0.644       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 0.487        |\n",
      "|    reward             | -0.026671268 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.785        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 213          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.8        |\n",
      "|    explained_variance | 0.502        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.713        |\n",
      "|    reward             | 0.0048715235 |\n",
      "|    std                | 1.89         |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.785       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.3       |\n",
      "|    explained_variance | 0.552       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.414       |\n",
      "|    reward             | 0.008817901 |\n",
      "|    std                | 1.98        |\n",
      "|    value_loss         | 4.94e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.785        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.9        |\n",
      "|    explained_variance | -1.23        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.049       |\n",
      "|    reward             | 0.0013587776 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 4.26e-06     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 0.785      |\n",
      "| time/                 |            |\n",
      "|    fps                | 40         |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72.5      |\n",
      "|    explained_variance | 0.227      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -0.884     |\n",
      "|    reward             | 0.01177433 |\n",
      "|    std                | 2.18       |\n",
      "|    value_loss         | 0.000203   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2058974.125\n",
      "Final accumulative portfolio value: 2.058974125\n",
      "Maximum DrawDown: -0.5747209260279633\n",
      "Sharpe ratio: 0.27280224385339313\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.755       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -73.8       |\n",
      "|    explained_variance | -0.533      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 3.25        |\n",
      "|    reward             | 0.010001426 |\n",
      "|    std                | 2.27        |\n",
      "|    value_loss         | 0.00326     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.755         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.9         |\n",
      "|    explained_variance | 0.371         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | 1.69          |\n",
      "|    reward             | -0.0023116942 |\n",
      "|    std                | 2.34          |\n",
      "|    value_loss         | 0.000721      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.755        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.1        |\n",
      "|    explained_variance | 0.0789       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 1.78         |\n",
      "|    reward             | -0.010972517 |\n",
      "|    std                | 2.43         |\n",
      "|    value_loss         | 0.00065      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.755       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.5       |\n",
      "|    explained_variance | -0.216      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.321       |\n",
      "|    reward             | 0.017834188 |\n",
      "|    std                | 2.53        |\n",
      "|    value_loss         | 5.94e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.755         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 314           |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -78.8         |\n",
      "|    explained_variance | -1.86         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | 0.163         |\n",
      "|    reward             | -0.0022495638 |\n",
      "|    std                | 2.63          |\n",
      "|    value_loss         | 4.82e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.755       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80         |\n",
      "|    explained_variance | 0.0386      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 2.94        |\n",
      "|    reward             | 0.012526878 |\n",
      "|    std                | 2.73        |\n",
      "|    value_loss         | 0.00191     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.755        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -81.3        |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | 0.231        |\n",
      "|    reward             | -0.008146597 |\n",
      "|    std                | 2.85         |\n",
      "|    value_loss         | 2.29e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.755        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -82.9        |\n",
      "|    explained_variance | -0.148       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.0252      |\n",
      "|    reward             | 0.0067955097 |\n",
      "|    std                | 2.98         |\n",
      "|    value_loss         | 0.000234     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.755       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84.4       |\n",
      "|    explained_variance | -0.127      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.012031837 |\n",
      "|    std                | 3.12        |\n",
      "|    value_loss         | 0.000257    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.755         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 377           |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -86           |\n",
      "|    explained_variance | 0.228         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.476         |\n",
      "|    reward             | -0.0011562235 |\n",
      "|    std                | 3.28          |\n",
      "|    value_loss         | 0.000128      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2355709.5\n",
      "Final accumulative portfolio value: 2.3557095\n",
      "Maximum DrawDown: -0.5577014977703909\n",
      "Sharpe ratio: 0.30167479035609374\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.789        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -87.4        |\n",
      "|    explained_variance | 0.584        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -1.15        |\n",
      "|    reward             | -0.029414615 |\n",
      "|    std                | 3.42         |\n",
      "|    value_loss         | 0.00023      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.789       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -88.4       |\n",
      "|    explained_variance | -0.225      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 2.43        |\n",
      "|    reward             | 0.018569319 |\n",
      "|    std                | 3.53        |\n",
      "|    value_loss         | 0.000956    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.789       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -89.5       |\n",
      "|    explained_variance | -0.338      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.475      |\n",
      "|    reward             | 0.009892959 |\n",
      "|    std                | 3.65        |\n",
      "|    value_loss         | 3.51e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.789        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -91          |\n",
      "|    explained_variance | 0.396        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | 0.795        |\n",
      "|    reward             | -0.023915216 |\n",
      "|    std                | 3.82         |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.789       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -92.3       |\n",
      "|    explained_variance | -0.201      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -0.251      |\n",
      "|    reward             | 0.018244548 |\n",
      "|    std                | 3.97        |\n",
      "|    value_loss         | 7.51e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.789        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 455          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -93.5        |\n",
      "|    explained_variance | -0.0159      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | -2.14        |\n",
      "|    reward             | -0.012788419 |\n",
      "|    std                | 4.12         |\n",
      "|    value_loss         | 0.00214      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.789        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -94.9        |\n",
      "|    explained_variance | 0.637        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -0.853       |\n",
      "|    reward             | 0.0046381513 |\n",
      "|    std                | 4.29         |\n",
      "|    value_loss         | 9.91e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.789         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 479           |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -96.4         |\n",
      "|    explained_variance | 0.622         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 0.421         |\n",
      "|    reward             | 0.00038961924 |\n",
      "|    std                | 4.5           |\n",
      "|    value_loss         | 6.36e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.789        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 492          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -98.1        |\n",
      "|    explained_variance | 0.366        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.004260963 |\n",
      "|    std                | 4.73         |\n",
      "|    value_loss         | 7.82e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.789         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 504           |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -99.8         |\n",
      "|    explained_variance | -0.333        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | 1.02          |\n",
      "|    reward             | -0.0023293186 |\n",
      "|    std                | 4.98          |\n",
      "|    value_loss         | 0.000136      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1938822.0\n",
      "Final accumulative portfolio value: 1.938822\n",
      "Maximum DrawDown: -0.5452040769921884\n",
      "Sharpe ratio: 0.25917231194515955\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.758        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 519          |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -101         |\n",
      "|    explained_variance | -0.987       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -1.03        |\n",
      "|    reward             | -0.003272458 |\n",
      "|    std                | 5.2          |\n",
      "|    value_loss         | 0.000244     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.758       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 531         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -102        |\n",
      "|    explained_variance | -0.207      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 1.25        |\n",
      "|    reward             | -0.00510048 |\n",
      "|    std                | 5.38        |\n",
      "|    value_loss         | 0.000389    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.758         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 543           |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -103          |\n",
      "|    explained_variance | -0.266        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | 0.411         |\n",
      "|    reward             | -0.0067798328 |\n",
      "|    std                | 5.58          |\n",
      "|    value_loss         | 4.89e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.758         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 556           |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -105          |\n",
      "|    explained_variance | 0.567         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 1.41          |\n",
      "|    reward             | -0.0072991154 |\n",
      "|    std                | 5.82          |\n",
      "|    value_loss         | 0.000209      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.758       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 569         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -106        |\n",
      "|    explained_variance | -0.336      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -4.09       |\n",
      "|    reward             | 0.031643916 |\n",
      "|    std                | 6.05        |\n",
      "|    value_loss         | 0.00184     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.758        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 581          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -107         |\n",
      "|    explained_variance | 0.177        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.010116014 |\n",
      "|    std                | 6.27         |\n",
      "|    value_loss         | 0.00021      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.758       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 594         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | 0.154       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.010493934 |\n",
      "|    std                | 6.52        |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.758        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 606          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -110         |\n",
      "|    explained_variance | 0.21         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.901        |\n",
      "|    reward             | 0.0014294895 |\n",
      "|    std                | 6.83         |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.758        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -112         |\n",
      "|    explained_variance | 0.236        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.766       |\n",
      "|    reward             | 0.0022463584 |\n",
      "|    std                | 7.16         |\n",
      "|    value_loss         | 5.76e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.758       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 631         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | 0.26        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.539       |\n",
      "|    reward             | 0.010387286 |\n",
      "|    std                | 7.5         |\n",
      "|    value_loss         | 6.63e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1967879.5\n",
      "Final accumulative portfolio value: 1.9678795\n",
      "Maximum DrawDown: -0.5904910009568062\n",
      "Sharpe ratio: 0.2624759285865237\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.742       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 647         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -115        |\n",
      "|    explained_variance | 0.433       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -3.92       |\n",
      "|    reward             | 0.011019447 |\n",
      "|    std                | 7.84        |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.742        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 659          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -116         |\n",
      "|    explained_variance | 0.471        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | 0.601        |\n",
      "|    reward             | -0.004924961 |\n",
      "|    std                | 8.11         |\n",
      "|    value_loss         | 6.63e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.742        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 672          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -117         |\n",
      "|    explained_variance | -0.094       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | 0.0028847528 |\n",
      "|    std                | 8.42         |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.742       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 684         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -118        |\n",
      "|    explained_variance | 0.199       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.183       |\n",
      "|    reward             | -0.00887536 |\n",
      "|    std                | 8.79        |\n",
      "|    value_loss         | 3.56e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.742        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 696          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -120         |\n",
      "|    explained_variance | 0.248        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 3.72         |\n",
      "|    reward             | -0.013179887 |\n",
      "|    std                | 9.19         |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.742       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 708         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -121        |\n",
      "|    explained_variance | 0.381       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.013594076 |\n",
      "|    std                | 9.55        |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.742        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 720          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -123         |\n",
      "|    explained_variance | -0.532       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.461        |\n",
      "|    reward             | 0.0056846384 |\n",
      "|    std                | 9.96         |\n",
      "|    value_loss         | 8.52e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.742        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -124         |\n",
      "|    explained_variance | -2.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | 0.0032251272 |\n",
      "|    std                | 10.4         |\n",
      "|    value_loss         | 0.000157     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.742       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 745         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -126        |\n",
      "|    explained_variance | -6.62       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 0.442       |\n",
      "|    reward             | 0.002902226 |\n",
      "|    std                | 11          |\n",
      "|    value_loss         | 3.5e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.742       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 757         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -127        |\n",
      "|    explained_variance | 0.711       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | -0.03407554 |\n",
      "|    std                | 11.5        |\n",
      "|    value_loss         | 1.55e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2338370.0\n",
      "Final accumulative portfolio value: 2.33837\n",
      "Maximum DrawDown: -0.5703627913364713\n",
      "Sharpe ratio: 0.3002902816114169\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -129         |\n",
      "|    explained_variance | 0.229        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | -0.005869114 |\n",
      "|    std                | 12           |\n",
      "|    value_loss         | 9.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 785          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -130         |\n",
      "|    explained_variance | -0.0831      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 3.86         |\n",
      "|    reward             | 0.0015315005 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 0.000983     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 797          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -131         |\n",
      "|    explained_variance | 0.154        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | 0.0053941887 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.76        |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 809         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -132        |\n",
      "|    explained_variance | -0.777      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.002785495 |\n",
      "|    std                | 13.4        |\n",
      "|    value_loss         | 0.000134    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 822          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -134         |\n",
      "|    explained_variance | 0.592        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.973        |\n",
      "|    reward             | -0.005729427 |\n",
      "|    std                | 14           |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.76        |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 834         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | 0.359       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -1.83       |\n",
      "|    reward             | 0.021378668 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 0.000238    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 846          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -136         |\n",
      "|    explained_variance | 0.469        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 2.26         |\n",
      "|    reward             | -0.005293527 |\n",
      "|    std                | 15.1         |\n",
      "|    value_loss         | 0.000343     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.76          |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 859           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -138          |\n",
      "|    explained_variance | 0.338         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | -0.236        |\n",
      "|    reward             | -0.0013091785 |\n",
      "|    std                | 15.9          |\n",
      "|    value_loss         | 1.97e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.76         |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 871          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -140         |\n",
      "|    explained_variance | -4.64        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 1.31         |\n",
      "|    reward             | 0.0023693363 |\n",
      "|    std                | 16.6         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.76        |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 883         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | 0.175       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -0.898      |\n",
      "|    reward             | 0.011387001 |\n",
      "|    std                | 17.5        |\n",
      "|    value_loss         | 0.000125    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1906339.75\n",
      "Final accumulative portfolio value: 1.90633975\n",
      "Maximum DrawDown: -0.5801005669501258\n",
      "Sharpe ratio: 0.2554066782943309\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.744        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 898          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -143         |\n",
      "|    explained_variance | 0.538        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 3.74         |\n",
      "|    reward             | -0.038975548 |\n",
      "|    std                | 18.4         |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.744        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 910          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -144         |\n",
      "|    explained_variance | 0.105        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -1.47        |\n",
      "|    reward             | 0.0024622146 |\n",
      "|    std                | 19           |\n",
      "|    value_loss         | 0.000267     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.744       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 922         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -145        |\n",
      "|    explained_variance | -1.16       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -1.01       |\n",
      "|    reward             | 0.017475089 |\n",
      "|    std                | 19.7        |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.744         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 935           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -146          |\n",
      "|    explained_variance | -0.134        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.825         |\n",
      "|    reward             | 6.1629304e-05 |\n",
      "|    std                | 20.6          |\n",
      "|    value_loss         | 8.46e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.744         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 947           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -148          |\n",
      "|    explained_variance | 0.352         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 8.49          |\n",
      "|    reward             | -0.0076219495 |\n",
      "|    std                | 21.5          |\n",
      "|    value_loss         | 0.00402       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.744        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 959          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -149         |\n",
      "|    explained_variance | -0.0116      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -0.751       |\n",
      "|    reward             | -0.005996288 |\n",
      "|    std                | 22.3         |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.744        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 971          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -150         |\n",
      "|    explained_variance | -0.534       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.968        |\n",
      "|    reward             | 0.0022562302 |\n",
      "|    std                | 23.2         |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.744          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 7800           |\n",
      "|    time_elapsed       | 984            |\n",
      "|    total_timesteps    | 39000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -152           |\n",
      "|    explained_variance | 0.204          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7799           |\n",
      "|    policy_loss        | -0.553         |\n",
      "|    reward             | -0.00024417043 |\n",
      "|    std                | 24.3           |\n",
      "|    value_loss         | 2.3e-05        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.744         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 996           |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -154          |\n",
      "|    explained_variance | -0.3          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | 1.65          |\n",
      "|    reward             | -0.0062854113 |\n",
      "|    std                | 25.4          |\n",
      "|    value_loss         | 0.000118      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.744       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 1009        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -155        |\n",
      "|    explained_variance | 0.343       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 1.56        |\n",
      "|    reward             | 0.003108671 |\n",
      "|    std                | 26.7        |\n",
      "|    value_loss         | 0.000157    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1864732.0\n",
      "Final accumulative portfolio value: 1.864732\n",
      "Maximum DrawDown: -0.5964814744497634\n",
      "Sharpe ratio: 0.25057789945264775\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.729       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 1024        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -157        |\n",
      "|    explained_variance | 0.135       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 2.41        |\n",
      "|    reward             | 0.003300697 |\n",
      "|    std                | 28          |\n",
      "|    value_loss         | 0.000346    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.729       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 1036        |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -158        |\n",
      "|    explained_variance | 0.168       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 3.64        |\n",
      "|    reward             | 0.005442564 |\n",
      "|    std                | 28.9        |\n",
      "|    value_loss         | 0.000632    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.729        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 1048         |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -159         |\n",
      "|    explained_variance | 0.221        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.133        |\n",
      "|    reward             | -0.015187028 |\n",
      "|    std                | 30           |\n",
      "|    value_loss         | 6.28e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.729       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 1061        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -160        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | 0.016003845 |\n",
      "|    std                | 31.2        |\n",
      "|    value_loss         | 6.7e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.729         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 1073          |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -162          |\n",
      "|    explained_variance | 0.379         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -2.97         |\n",
      "|    reward             | -0.0015109861 |\n",
      "|    std                | 32.7          |\n",
      "|    value_loss         | 0.000552      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.729        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 1085         |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -163         |\n",
      "|    explained_variance | -2.57        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 2.23         |\n",
      "|    reward             | 0.0019446765 |\n",
      "|    std                | 33.9         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.729         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 1097          |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -164          |\n",
      "|    explained_variance | -1            |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 2.29          |\n",
      "|    reward             | -0.0022343306 |\n",
      "|    std                | 35.3          |\n",
      "|    value_loss         | 0.000273      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.729       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 1110        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -166        |\n",
      "|    explained_variance | 0.199       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.153      |\n",
      "|    reward             | 0.002829241 |\n",
      "|    std                | 37          |\n",
      "|    value_loss         | 8.81e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.729         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 1122          |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -168          |\n",
      "|    explained_variance | -12           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | 1.42          |\n",
      "|    reward             | -0.0019091101 |\n",
      "|    std                | 38.9          |\n",
      "|    value_loss         | 8.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.729        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 1134         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -169         |\n",
      "|    explained_variance | 0.401        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | 3.82         |\n",
      "|    reward             | 0.0058195204 |\n",
      "|    std                | 41           |\n",
      "|    value_loss         | 0.000733     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2188777.0\n",
      "Final accumulative portfolio value: 2.188777\n",
      "Maximum DrawDown: -0.5636572499002774\n",
      "Sharpe ratio: 0.2854694255935253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.735         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 1149          |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -171          |\n",
      "|    explained_variance | 0.66          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9099          |\n",
      "|    policy_loss        | 5.22          |\n",
      "|    reward             | -0.0026974073 |\n",
      "|    std                | 43            |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.735        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -172         |\n",
      "|    explained_variance | 0.232        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -2.24        |\n",
      "|    reward             | -0.019175643 |\n",
      "|    std                | 44.7         |\n",
      "|    value_loss         | 0.000467     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.735        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 1174         |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -173         |\n",
      "|    explained_variance | -0.39        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -1.99        |\n",
      "|    reward             | 0.0030551925 |\n",
      "|    std                | 46.4         |\n",
      "|    value_loss         | 0.000155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.735        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 1186         |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -175         |\n",
      "|    explained_variance | -0.316       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.255       |\n",
      "|    reward             | -0.007979674 |\n",
      "|    std                | 48.5         |\n",
      "|    value_loss         | 4.08e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.735       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 1198        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -176        |\n",
      "|    explained_variance | 0.205       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -5.46       |\n",
      "|    reward             | 0.028398763 |\n",
      "|    std                | 50.7        |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.735         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 1211          |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -178          |\n",
      "|    explained_variance | -1.2          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9599          |\n",
      "|    policy_loss        | 0.586         |\n",
      "|    reward             | -0.0050570467 |\n",
      "|    std                | 52.6          |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.735         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 1223          |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -179          |\n",
      "|    explained_variance | 0.279         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | 1.13          |\n",
      "|    reward             | -0.0023643887 |\n",
      "|    std                | 54.8          |\n",
      "|    value_loss         | 6.14e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.735        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -180         |\n",
      "|    explained_variance | -0.9         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -1.2         |\n",
      "|    reward             | -0.005463897 |\n",
      "|    std                | 57.3         |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.735       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 1248        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -182        |\n",
      "|    explained_variance | -0.491      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -3.51       |\n",
      "|    reward             | 0.003606484 |\n",
      "|    std                | 60.1        |\n",
      "|    value_loss         | 0.000383    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.735        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 1260         |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -184         |\n",
      "|    explained_variance | 0.501        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 1.75         |\n",
      "|    reward             | -0.041380532 |\n",
      "|    std                | 63.3         |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "Logging to ./data/tb\\a2c_31\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -185        |\n",
      "|    explained_variance | 0.552       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -2.99       |\n",
      "|    reward             | 0.003330401 |\n",
      "|    std                | 66          |\n",
      "|    value_loss         | 0.0003      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 40            |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -186          |\n",
      "|    explained_variance | -0.542        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10199         |\n",
      "|    policy_loss        | 0.864         |\n",
      "|    reward             | -0.0021646784 |\n",
      "|    std                | 68.5          |\n",
      "|    value_loss         | 0.00015       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -187         |\n",
      "|    explained_variance | -0.555       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -2.21        |\n",
      "|    reward             | -0.010032927 |\n",
      "|    std                | 71.2         |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -189        |\n",
      "|    explained_variance | -0.5        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -2.99       |\n",
      "|    reward             | 0.010617907 |\n",
      "|    std                | 74.6        |\n",
      "|    value_loss         | 0.000395    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -190         |\n",
      "|    explained_variance | 0.44         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10499        |\n",
      "|    policy_loss        | -0.119       |\n",
      "|    reward             | 0.0067565558 |\n",
      "|    std                | 77.7         |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -192        |\n",
      "|    explained_variance | 0.0254      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 4.64        |\n",
      "|    reward             | 0.014753406 |\n",
      "|    std                | 80.8        |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -193        |\n",
      "|    explained_variance | -0.00236    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.010195555 |\n",
      "|    std                | 84.3        |\n",
      "|    value_loss         | 9.91e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -195         |\n",
      "|    explained_variance | -0.0479      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | 1.38         |\n",
      "|    reward             | -0.010766983 |\n",
      "|    std                | 88.4         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -196         |\n",
      "|    explained_variance | 0.427        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | 0.405        |\n",
      "|    reward             | -0.008307356 |\n",
      "|    std                | 92.8         |\n",
      "|    value_loss         | 1.18e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 40            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 122           |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -198          |\n",
      "|    explained_variance | 0.149         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10999         |\n",
      "|    policy_loss        | 0.179         |\n",
      "|    reward             | -0.0070419917 |\n",
      "|    std                | 97.2          |\n",
      "|    value_loss         | 1.69e-06      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1723829.5\n",
      "Final accumulative portfolio value: 1.7238295\n",
      "Maximum DrawDown: -0.5855242676544334\n",
      "Sharpe ratio: 0.23358046662981471\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.547        |\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -199         |\n",
      "|    explained_variance | -0.547       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -5.18        |\n",
      "|    reward             | -0.024933087 |\n",
      "|    std                | 101          |\n",
      "|    value_loss         | 0.000697     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -200        |\n",
      "|    explained_variance | 0.468       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | -3.74       |\n",
      "|    reward             | 0.012570435 |\n",
      "|    std                | 105         |\n",
      "|    value_loss         | 0.000403    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -201        |\n",
      "|    explained_variance | -2.25       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | 0.004446382 |\n",
      "|    std                | 109         |\n",
      "|    value_loss         | 5.22e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -203        |\n",
      "|    explained_variance | 0.19        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | -0.337      |\n",
      "|    reward             | 0.027463244 |\n",
      "|    std                | 114         |\n",
      "|    value_loss         | 6.98e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.547        |\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -204         |\n",
      "|    explained_variance | -0.0365      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | -7.53        |\n",
      "|    reward             | 0.0049045025 |\n",
      "|    std                | 118          |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.547        |\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -206         |\n",
      "|    explained_variance | 0.057        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 2.41         |\n",
      "|    reward             | -0.028891824 |\n",
      "|    std                | 123          |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -207        |\n",
      "|    explained_variance | -0.269      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 2.76        |\n",
      "|    reward             | 0.006144324 |\n",
      "|    std                | 128         |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -208        |\n",
      "|    explained_variance | 0.389       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | 0.642       |\n",
      "|    reward             | 0.011950211 |\n",
      "|    std                | 135         |\n",
      "|    value_loss         | 2.21e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.547        |\n",
      "| time/                 |              |\n",
      "|    fps                | 40           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -210         |\n",
      "|    explained_variance | -0.787       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | 0.219        |\n",
      "|    reward             | 0.0023629144 |\n",
      "|    std                | 141          |\n",
      "|    value_loss         | 3.91e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.547       |\n",
      "| time/                 |             |\n",
      "|    fps                | 40          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -212        |\n",
      "|    explained_variance | 0.49        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -2.85       |\n",
      "|    reward             | 0.009791678 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 0.000225    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1987012.25\n",
      "Final accumulative portfolio value: 1.98701225\n",
      "Maximum DrawDown: -0.5553147357266411\n",
      "Sharpe ratio: 0.2645811494744379\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.617        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -213         |\n",
      "|    explained_variance | -0.203       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | 8.06         |\n",
      "|    reward             | 0.0150485495 |\n",
      "|    std                | 155          |\n",
      "|    value_loss         | 0.00231      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.617         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 277           |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -214          |\n",
      "|    explained_variance | 0.263         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12199         |\n",
      "|    policy_loss        | 3.56          |\n",
      "|    reward             | -0.0024136202 |\n",
      "|    std                | 160           |\n",
      "|    value_loss         | 0.000507      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.617        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -215         |\n",
      "|    explained_variance | 0.209        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | 4.13         |\n",
      "|    reward             | -0.009040628 |\n",
      "|    std                | 166          |\n",
      "|    value_loss         | 0.00045      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.617       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -217        |\n",
      "|    explained_variance | -0.289      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 0.543       |\n",
      "|    reward             | 0.015090119 |\n",
      "|    std                | 173         |\n",
      "|    value_loss         | 3.31e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.617          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 2500           |\n",
      "|    time_elapsed       | 314            |\n",
      "|    total_timesteps    | 12500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -218           |\n",
      "|    explained_variance | 0.278          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12499          |\n",
      "|    policy_loss        | 0.853          |\n",
      "|    reward             | -0.00092573086 |\n",
      "|    std                | 180            |\n",
      "|    value_loss         | 2.96e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.617       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -219        |\n",
      "|    explained_variance | 0.176       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 7.83        |\n",
      "|    reward             | 0.011985311 |\n",
      "|    std                | 187         |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.617         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -221          |\n",
      "|    explained_variance | 0.598         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12699         |\n",
      "|    policy_loss        | 0.838         |\n",
      "|    reward             | -0.0071534654 |\n",
      "|    std                | 195           |\n",
      "|    value_loss         | 3.75e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.617       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -222        |\n",
      "|    explained_variance | 0.0661      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | 0.536       |\n",
      "|    reward             | 0.005753504 |\n",
      "|    std                | 204         |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.617       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -224        |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | 2.41        |\n",
      "|    reward             | 0.011705525 |\n",
      "|    std                | 214         |\n",
      "|    value_loss         | 0.000157    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.617        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 377          |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -225         |\n",
      "|    explained_variance | 0.187        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | 3.28         |\n",
      "|    reward             | 0.0015053143 |\n",
      "|    std                | 224          |\n",
      "|    value_loss         | 0.00031      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2237225.0\n",
      "Final accumulative portfolio value: 2.237225\n",
      "Maximum DrawDown: -0.5979834277125026\n",
      "Sharpe ratio: 0.29007396083793063\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.681        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -227         |\n",
      "|    explained_variance | 0.397        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13099        |\n",
      "|    policy_loss        | -1.49        |\n",
      "|    reward             | -0.025518382 |\n",
      "|    std                | 234          |\n",
      "|    value_loss         | 0.000146     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.681       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -228        |\n",
      "|    explained_variance | -0.145      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 6.5         |\n",
      "|    reward             | 0.013894026 |\n",
      "|    std                | 242         |\n",
      "|    value_loss         | 0.000977    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 0.681      |\n",
      "| time/                 |            |\n",
      "|    fps                | 39         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -229       |\n",
      "|    explained_variance | -0.88      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | -1.04      |\n",
      "|    reward             | 0.01056353 |\n",
      "|    std                | 250        |\n",
      "|    value_loss         | 4e-05      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.681        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 429          |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -230         |\n",
      "|    explained_variance | 0.741        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | 0.547        |\n",
      "|    reward             | -0.022749282 |\n",
      "|    std                | 261          |\n",
      "|    value_loss         | 3.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.681       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -232        |\n",
      "|    explained_variance | 0.353       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.020021722 |\n",
      "|    std                | 272         |\n",
      "|    value_loss         | 6.65e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.681        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -233         |\n",
      "|    explained_variance | 0.0882       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | -6.77        |\n",
      "|    reward             | -0.012999863 |\n",
      "|    std                | 283          |\n",
      "|    value_loss         | 0.00232      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.681        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -234         |\n",
      "|    explained_variance | 0.541        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | 0.0039380626 |\n",
      "|    std                | 296          |\n",
      "|    value_loss         | 5.03e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.681         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 479           |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -236          |\n",
      "|    explained_variance | 0.541         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13799         |\n",
      "|    policy_loss        | 1.17          |\n",
      "|    reward             | -0.0008390488 |\n",
      "|    std                | 310           |\n",
      "|    value_loss         | 6.44e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.681         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 491           |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -238          |\n",
      "|    explained_variance | -0.807        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | 1.06          |\n",
      "|    reward             | -0.0041046226 |\n",
      "|    std                | 326           |\n",
      "|    value_loss         | 2.87e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.681          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 4000           |\n",
      "|    time_elapsed       | 503            |\n",
      "|    total_timesteps    | 20000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -239           |\n",
      "|    explained_variance | 0.058          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 13999          |\n",
      "|    policy_loss        | 1.84           |\n",
      "|    reward             | -0.00057755696 |\n",
      "|    std                | 343            |\n",
      "|    value_loss         | 7.2e-05        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2134179.5\n",
      "Final accumulative portfolio value: 2.1341795\n",
      "Maximum DrawDown: -0.5621759811417617\n",
      "Sharpe ratio: 0.2800547465028468\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.7           |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 518           |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -241          |\n",
      "|    explained_variance | -0.447        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14099         |\n",
      "|    policy_loss        | -4.53         |\n",
      "|    reward             | -0.0008786007 |\n",
      "|    std                | 358           |\n",
      "|    value_loss         | 0.000468      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 530          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -242         |\n",
      "|    explained_variance | -0.0783      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | 3            |\n",
      "|    reward             | -0.004324535 |\n",
      "|    std                | 371          |\n",
      "|    value_loss         | 0.000341     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 543          |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -243         |\n",
      "|    explained_variance | -0.83        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | -0.005330379 |\n",
      "|    std                | 385          |\n",
      "|    value_loss         | 4.33e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 555          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -245         |\n",
      "|    explained_variance | 0.494        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 3.4          |\n",
      "|    reward             | -0.011558739 |\n",
      "|    std                | 402          |\n",
      "|    value_loss         | 0.000231     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.7         |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 567         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -246        |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | -6.67       |\n",
      "|    reward             | 0.028631754 |\n",
      "|    std                | 420         |\n",
      "|    value_loss         | 0.00105     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 580          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -247         |\n",
      "|    explained_variance | -0.0474      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | 4.46         |\n",
      "|    reward             | -0.009936542 |\n",
      "|    std                | 436          |\n",
      "|    value_loss         | 0.000411     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 592          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -249         |\n",
      "|    explained_variance | -0.132       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14699        |\n",
      "|    policy_loss        | 2.15         |\n",
      "|    reward             | 0.0105894795 |\n",
      "|    std                | 453          |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 605          |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -250         |\n",
      "|    explained_variance | 0.0969       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14799        |\n",
      "|    policy_loss        | 2.45         |\n",
      "|    reward             | 0.0012054328 |\n",
      "|    std                | 475          |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.7          |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -252         |\n",
      "|    explained_variance | -0.286       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | -2.5         |\n",
      "|    reward             | 0.0027611246 |\n",
      "|    std                | 498          |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.7         |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 630         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -253        |\n",
      "|    explained_variance | 0.303       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 2.19        |\n",
      "|    reward             | 0.011228819 |\n",
      "|    std                | 524         |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2278667.75\n",
      "Final accumulative portfolio value: 2.27866775\n",
      "Maximum DrawDown: -0.575402655834094\n",
      "Sharpe ratio: 0.2946139835773573\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.725        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -255         |\n",
      "|    explained_variance | 0.284        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | -8.01        |\n",
      "|    reward             | 0.0062630335 |\n",
      "|    std                | 548          |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.725        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 657          |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -256         |\n",
      "|    explained_variance | 0.000408     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | -1.84        |\n",
      "|    reward             | -0.005869234 |\n",
      "|    std                | 568          |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.725        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -257         |\n",
      "|    explained_variance | -0.648       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15299        |\n",
      "|    policy_loss        | -2.99        |\n",
      "|    reward             | 0.0033522623 |\n",
      "|    std                | 591          |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.725         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 682           |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -259          |\n",
      "|    explained_variance | -0.51         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15399         |\n",
      "|    policy_loss        | 0.322         |\n",
      "|    reward             | -0.0074428646 |\n",
      "|    std                | 617           |\n",
      "|    value_loss         | 4.74e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.725        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 694          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -260         |\n",
      "|    explained_variance | -0.0692      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | 7.93         |\n",
      "|    reward             | -0.013647456 |\n",
      "|    std                | 644          |\n",
      "|    value_loss         | 0.00122      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.725       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 706         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -261        |\n",
      "|    explained_variance | 0.314       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -3.22       |\n",
      "|    reward             | 0.013586314 |\n",
      "|    std                | 669         |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.725       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 719         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -263        |\n",
      "|    explained_variance | -1.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 1.42        |\n",
      "|    reward             | 0.006455283 |\n",
      "|    std                | 696         |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.725        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 731          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -264         |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | 1.98         |\n",
      "|    reward             | 0.0027291456 |\n",
      "|    std                | 730          |\n",
      "|    value_loss         | 9.27e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.725       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -266        |\n",
      "|    explained_variance | -5.04       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | -0.718      |\n",
      "|    reward             | 0.006088282 |\n",
      "|    std                | 764         |\n",
      "|    value_loss         | 2.2e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.725       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 756         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -267        |\n",
      "|    explained_variance | 0.569       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | 0.1         |\n",
      "|    reward             | -0.03775652 |\n",
      "|    std                | 801         |\n",
      "|    value_loss         | 1.43e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1734423.75\n",
      "Final accumulative portfolio value: 1.73442375\n",
      "Maximum DrawDown: -0.5544733801009545\n",
      "Sharpe ratio: 0.23493734643780345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.696         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 770           |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -269          |\n",
      "|    explained_variance | 0.465         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16099         |\n",
      "|    policy_loss        | -2.77         |\n",
      "|    reward             | -0.0065455213 |\n",
      "|    std                | 835           |\n",
      "|    value_loss         | 0.000172      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.696          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 6200           |\n",
      "|    time_elapsed       | 782            |\n",
      "|    total_timesteps    | 31000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -270           |\n",
      "|    explained_variance | 0.0495         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16199          |\n",
      "|    policy_loss        | 7.22           |\n",
      "|    reward             | -0.00014955923 |\n",
      "|    std                | 864            |\n",
      "|    value_loss         | 0.000847       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.696       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -271        |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -0.886      |\n",
      "|    reward             | 0.006111979 |\n",
      "|    std                | 895         |\n",
      "|    value_loss         | 4.64e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.696        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -272         |\n",
      "|    explained_variance | -0.539       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16399        |\n",
      "|    policy_loss        | 3.92         |\n",
      "|    reward             | 0.0027742016 |\n",
      "|    std                | 935          |\n",
      "|    value_loss         | 0.000347     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.696         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 820           |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -274          |\n",
      "|    explained_variance | 0.328         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16499         |\n",
      "|    policy_loss        | -1.12         |\n",
      "|    reward             | -0.0070278253 |\n",
      "|    std                | 977           |\n",
      "|    value_loss         | 0.000188      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 0.696      |\n",
      "| time/                 |            |\n",
      "|    fps                | 39         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 832        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -275       |\n",
      "|    explained_variance | 0.109      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | -3.86      |\n",
      "|    reward             | 0.02367408 |\n",
      "|    std                | 1.01e+03   |\n",
      "|    value_loss         | 0.00029    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.696         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 844           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -276          |\n",
      "|    explained_variance | 0.595         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16699         |\n",
      "|    policy_loss        | 5.3           |\n",
      "|    reward             | -0.0046975506 |\n",
      "|    std                | 1.06e+03      |\n",
      "|    value_loss         | 0.000415      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.696         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 856           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -278          |\n",
      "|    explained_variance | 0.382         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16799         |\n",
      "|    policy_loss        | -0.178        |\n",
      "|    reward             | -0.0008918447 |\n",
      "|    std                | 1.11e+03      |\n",
      "|    value_loss         | 1.39e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.696        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 869          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -280         |\n",
      "|    explained_variance | -3.47        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 1.92         |\n",
      "|    reward             | 0.0011659021 |\n",
      "|    std                | 1.16e+03     |\n",
      "|    value_loss         | 6.1e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.696       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 881         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -281        |\n",
      "|    explained_variance | 0.0148      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -1.93       |\n",
      "|    reward             | 0.009113382 |\n",
      "|    std                | 1.22e+03    |\n",
      "|    value_loss         | 0.000139    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2040052.25\n",
      "Final accumulative portfolio value: 2.04005225\n",
      "Maximum DrawDown: -0.5894623600098141\n",
      "Sharpe ratio: 0.2703007071602104\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.699       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 896         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -283        |\n",
      "|    explained_variance | 0.723       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | 5.67        |\n",
      "|    reward             | -0.03883153 |\n",
      "|    std                | 1.29e+03    |\n",
      "|    value_loss         | 0.000599    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.699        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 908          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -284         |\n",
      "|    explained_variance | -0.11        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | -5.08        |\n",
      "|    reward             | 0.0055860137 |\n",
      "|    std                | 1.34e+03     |\n",
      "|    value_loss         | 0.000505     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.699       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 921         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -285        |\n",
      "|    explained_variance | -0.995      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | -2.05       |\n",
      "|    reward             | 0.018508468 |\n",
      "|    std                | 1.38e+03    |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.699         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 933           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -287          |\n",
      "|    explained_variance | -0.316        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17399         |\n",
      "|    policy_loss        | 0.682         |\n",
      "|    reward             | -0.0014421007 |\n",
      "|    std                | 1.44e+03      |\n",
      "|    value_loss         | 6.44e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.699        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -288         |\n",
      "|    explained_variance | 0.438        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | 19           |\n",
      "|    reward             | -0.003937177 |\n",
      "|    std                | 1.51e+03     |\n",
      "|    value_loss         | 0.00468      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.699        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 957          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -289         |\n",
      "|    explained_variance | 0.107        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | -1.19        |\n",
      "|    reward             | -0.004367996 |\n",
      "|    std                | 1.56e+03     |\n",
      "|    value_loss         | 8.82e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.699       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 969         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -291        |\n",
      "|    explained_variance | -0.16       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 3.55        |\n",
      "|    reward             | 0.003339668 |\n",
      "|    std                | 1.63e+03    |\n",
      "|    value_loss         | 0.000232    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.699          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 7800           |\n",
      "|    time_elapsed       | 981            |\n",
      "|    total_timesteps    | 39000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -292           |\n",
      "|    explained_variance | -0.159         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17799          |\n",
      "|    policy_loss        | -1.26          |\n",
      "|    reward             | -0.00092555187 |\n",
      "|    std                | 1.7e+03        |\n",
      "|    value_loss         | 3.06e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.699       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 994         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -294        |\n",
      "|    explained_variance | -0.461      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 2.37        |\n",
      "|    reward             | -0.00756171 |\n",
      "|    std                | 1.79e+03    |\n",
      "|    value_loss         | 7.31e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.699       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 1006        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -296        |\n",
      "|    explained_variance | 0.399       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 3.33        |\n",
      "|    reward             | 0.003949106 |\n",
      "|    std                | 1.88e+03    |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1968200.75\n",
      "Final accumulative portfolio value: 1.96820075\n",
      "Maximum DrawDown: -0.5753545235357591\n",
      "Sharpe ratio: 0.2626274838520577\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 0.697      |\n",
      "| time/                 |            |\n",
      "|    fps                | 39         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 1022       |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -297       |\n",
      "|    explained_variance | 0.0631     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | 4.47       |\n",
      "|    reward             | 0.00386171 |\n",
      "|    std                | 1.97e+03   |\n",
      "|    value_loss         | 0.000367   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.697        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 1034         |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -298         |\n",
      "|    explained_variance | 0.4          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | 7.95         |\n",
      "|    reward             | 0.0067616464 |\n",
      "|    std                | 2.04e+03     |\n",
      "|    value_loss         | 0.000762     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.697        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 1047         |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -299         |\n",
      "|    explained_variance | 0.335        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | 0.0167       |\n",
      "|    reward             | -0.015886242 |\n",
      "|    std                | 2.11e+03     |\n",
      "|    value_loss         | 6.18e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.697       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 1060        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -301        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 2.86        |\n",
      "|    reward             | 0.017010618 |\n",
      "|    std                | 2.2e+03     |\n",
      "|    value_loss         | 9.2e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.697        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 1072         |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -302         |\n",
      "|    explained_variance | 0.361        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | -9.85        |\n",
      "|    reward             | -0.001561549 |\n",
      "|    std                | 2.3e+03      |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.697       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 1084        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -303        |\n",
      "|    explained_variance | -1.58       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | 3.81        |\n",
      "|    reward             | 0.005888614 |\n",
      "|    std                | 2.39e+03    |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.697         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 1097          |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -305          |\n",
      "|    explained_variance | -0.886        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | 4.91          |\n",
      "|    reward             | -0.0030827904 |\n",
      "|    std                | 2.49e+03      |\n",
      "|    value_loss         | 0.000299      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 5.03e+03       |\n",
      "|    ep_rew_mean        | 0.697          |\n",
      "| time/                 |                |\n",
      "|    fps                | 39             |\n",
      "|    iterations         | 8800           |\n",
      "|    time_elapsed       | 1109           |\n",
      "|    total_timesteps    | 44000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -306           |\n",
      "|    explained_variance | 0.0905         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18799          |\n",
      "|    policy_loss        | 0.208          |\n",
      "|    reward             | -7.3313977e-06 |\n",
      "|    std                | 2.61e+03       |\n",
      "|    value_loss         | 8.41e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.697         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 1122          |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -308          |\n",
      "|    explained_variance | -1.08         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18899         |\n",
      "|    policy_loss        | 2.14          |\n",
      "|    reward             | -0.0030814153 |\n",
      "|    std                | 2.74e+03      |\n",
      "|    value_loss         | 5.58e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.697       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 1134        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -310        |\n",
      "|    explained_variance | 0.313       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 8.31        |\n",
      "|    reward             | 0.006691074 |\n",
      "|    std                | 2.89e+03    |\n",
      "|    value_loss         | 0.000967    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2178439.25\n",
      "Final accumulative portfolio value: 2.17843925\n",
      "Maximum DrawDown: -0.5684543015860404\n",
      "Sharpe ratio: 0.2845055704074327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.706         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 1148          |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -311          |\n",
      "|    explained_variance | 0.577         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19099         |\n",
      "|    policy_loss        | 6.45          |\n",
      "|    reward             | -0.0038267188 |\n",
      "|    std                | 3.02e+03      |\n",
      "|    value_loss         | 0.00071       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -312         |\n",
      "|    explained_variance | 0.0606       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19199        |\n",
      "|    policy_loss        | -1.83        |\n",
      "|    reward             | -0.018787106 |\n",
      "|    std                | 3.14e+03     |\n",
      "|    value_loss         | 0.000468     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 1174         |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -314         |\n",
      "|    explained_variance | -0.432       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | -3.37        |\n",
      "|    reward             | 0.0029220763 |\n",
      "|    std                | 3.25e+03     |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 1186         |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -315         |\n",
      "|    explained_variance | -0.129       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | 0.0304       |\n",
      "|    reward             | -0.011225347 |\n",
      "|    std                | 3.39e+03     |\n",
      "|    value_loss         | 3.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.706       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 1199        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -316        |\n",
      "|    explained_variance | 0.412       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -6.52       |\n",
      "|    reward             | 0.029147247 |\n",
      "|    std                | 3.55e+03    |\n",
      "|    value_loss         | 0.000703    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 1211         |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -318         |\n",
      "|    explained_variance | -0.805       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.003670686 |\n",
      "|    std                | 3.69e+03     |\n",
      "|    value_loss         | 5.68e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 1223         |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -319         |\n",
      "|    explained_variance | -0.0556      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | 2.94         |\n",
      "|    reward             | -0.002254821 |\n",
      "|    std                | 3.85e+03     |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 0.706         |\n",
      "| time/                 |               |\n",
      "|    fps                | 39            |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 1236          |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -321          |\n",
      "|    explained_variance | 0.0248        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | -1.84         |\n",
      "|    reward             | -0.0069875494 |\n",
      "|    std                | 4.03e+03      |\n",
      "|    value_loss         | 7.7e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 0.706       |\n",
      "| time/                 |             |\n",
      "|    fps                | 39          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 1249        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -322        |\n",
      "|    explained_variance | 0.487       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -4.98       |\n",
      "|    reward             | 0.002611324 |\n",
      "|    std                | 4.23e+03    |\n",
      "|    value_loss         | 0.000243    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 0.706        |\n",
      "| time/                 |              |\n",
      "|    fps                | 39           |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 1261         |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -324         |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19999        |\n",
      "|    policy_loss        | 3.27         |\n",
      "|    reward             | -0.042659838 |\n",
      "|    std                | 4.45e+03     |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1701346.375\n",
      "Final accumulative portfolio value: 1.701346375\n",
      "Maximum DrawDown: -0.3191001406741031\n",
      "Sharpe ratio: 0.5834796996898945\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.0003, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\ppo_38\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 17          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 116         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.013190866 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056077526 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.8        |\n",
      "|    explained_variance   | -0.0252      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.338       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    reward               | 0.01596743   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.346        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 3009012.75\n",
      "Final accumulative portfolio value: 3.00901275\n",
      "Maximum DrawDown: -0.5649688372918139\n",
      "Sharpe ratio: 0.35514524024678934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 99.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011443542 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | -0.78       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.508      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    reward               | 0.009700908 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00754     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 99.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008921587 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.372      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    reward               | 0.010762004 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2430284.75\n",
      "Final accumulative portfolio value: 2.43028475\n",
      "Maximum DrawDown: -0.5517834500448309\n",
      "Sharpe ratio: 0.30870124496513307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010656467 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | -0.756      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.518      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    reward               | 0.01888537  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.00689     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 87.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 710          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008566482  |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.3        |\n",
      "|    explained_variance   | 0.0634       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.461       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0337      |\n",
      "|    reward               | -0.002239089 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.181        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012538814 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | -0.782      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.519      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    reward               | 0.016494555 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.0234      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2365195.75\n",
      "Final accumulative portfolio value: 2.36519575\n",
      "Maximum DrawDown: -0.5712694377306625\n",
      "Sharpe ratio: 0.3024798400239528\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 945         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011862635 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.659      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.531      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    reward               | 0.013903368 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.00567     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011221983 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.0516      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.435      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    reward               | 0.012399642 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2280939.25\n",
      "Final accumulative portfolio value: 2.28093925\n",
      "Maximum DrawDown: -0.5664056751929588\n",
      "Sharpe ratio: 0.29453259983056396\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1182        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012132582 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | -0.932      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.522      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    reward               | 0.03851938  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.00967     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 84.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 1299         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011629139  |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.7        |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.479       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    reward               | 0.0110591035 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.29         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1416        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012462363 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | -0.665      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.519      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    reward               | 0.021049075 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 3052621.75\n",
      "Final accumulative portfolio value: 3.05262175\n",
      "Maximum DrawDown: -0.5771437438651088\n",
      "Sharpe ratio: 0.35830309581814873\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 90.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1535         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094183115 |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.9        |\n",
      "|    explained_variance   | -2.02        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.512       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0248      |\n",
      "|    reward               | 0.019406373  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.00443      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 90.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1652         |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117832795 |\n",
      "|    clip_fraction        | 0.0953       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.9        |\n",
      "|    explained_variance   | 0.0709       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.295       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    reward               | 0.013951222  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.282        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2548993.75\n",
      "Final accumulative portfolio value: 2.54899375\n",
      "Maximum DrawDown: -0.5479580173105061\n",
      "Sharpe ratio: 0.3192635105423688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1771        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011391402 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | -1.63       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    reward               | 0.026701258 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 90           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1888         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114158075 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.1        |\n",
      "|    explained_variance   | 0.0893       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.388       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0362      |\n",
      "|    reward               | 0.011852613  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.283        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2006        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012558278 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | -1.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.515      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0372     |\n",
      "|    reward               | 0.020431075 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2851306.25\n",
      "Final accumulative portfolio value: 2.85130625\n",
      "Maximum DrawDown: -0.5667551095666996\n",
      "Sharpe ratio: 0.34332468688871204\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2126        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010953007 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | -1.94       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    reward               | 0.016438415 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.00544     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2243        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014034609 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0761      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.374      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    reward               | 0.014785246 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.308       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2236480.5\n",
      "Final accumulative portfolio value: 2.2364805\n",
      "Maximum DrawDown: -0.5851641769619503\n",
      "Sharpe ratio: 0.2904683854891191\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.03e+03      |\n",
      "|    ep_rew_mean          | 92            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 17            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 2364          |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014483046   |\n",
      "|    clip_fraction        | 0.136         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.5         |\n",
      "|    explained_variance   | -1.44         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.517        |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.0368       |\n",
      "|    reward               | -0.0050585885 |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 0.0129        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2480        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014186741 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.442      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    reward               | 0.012525925 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 92           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2599         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132672535 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.7        |\n",
      "|    explained_variance   | -1.33        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.555       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    reward               | 0.018489854  |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.0176       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2463683.75\n",
      "Final accumulative portfolio value: 2.46368375\n",
      "Maximum DrawDown: -0.5517244901071993\n",
      "Sharpe ratio: 0.31149105808172395\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 90.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2721        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011235395 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    reward               | 0.022517473 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.00666     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 90.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2838        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016111657 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.0927      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.462      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    reward               | 0.016147422 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2681281.0\n",
      "Final accumulative portfolio value: 2.681281\n",
      "Maximum DrawDown: -0.579214236962566\n",
      "Sharpe ratio: 0.3302696354766367\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 92.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2962         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0145550035 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49          |\n",
      "|    explained_variance   | -1.69        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.541       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    reward               | 0.013617696  |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "Logging to ./data/tb\\ppo_39\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 17          |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 115         |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.013010494 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013212293 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    reward               | 0.013995257 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2423383.75\n",
      "Final accumulative portfolio value: 2.42338375\n",
      "Maximum DrawDown: -0.5757403564560207\n",
      "Sharpe ratio: 0.30800332077995146\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 89.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013782745 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | -3.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.521      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    reward               | 0.016673949 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 89.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013555752 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.415      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    reward               | 0.012735707 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2702264.25\n",
      "Final accumulative portfolio value: 2.70226425\n",
      "Maximum DrawDown: -0.5598502553937008\n",
      "Sharpe ratio: 0.33177390094317655\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013581842 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | -1.67       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.532      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    reward               | 0.02607001  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 92.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 708          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012287585  |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.33        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    reward               | -0.006939707 |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.225        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 92.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015176248 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | -1.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.55       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    reward               | 0.013535845 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0398      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2097360.25\n",
      "Final accumulative portfolio value: 2.09736025\n",
      "Maximum DrawDown: -0.607750973899484\n",
      "Sharpe ratio: 0.27646376820792623\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 945         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014633868 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.55       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    reward               | 0.017029706 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 84.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013302399 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0828      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.48       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    reward               | 0.011672463 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2344455.5\n",
      "Final accumulative portfolio value: 2.3444555\n",
      "Maximum DrawDown: -0.5779963070963255\n",
      "Sharpe ratio: 0.3009487559101994\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013093676 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | -1.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    reward               | 0.029168611 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0136      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013636556 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.0986      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.46       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    reward               | 0.007943728 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1417        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014989666 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | -0.666      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.537      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    reward               | 0.017704725 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0268      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2441869.25\n",
      "Final accumulative portfolio value: 2.44186925\n",
      "Maximum DrawDown: -0.5516026080785175\n",
      "Sharpe ratio: 0.3099175351455015\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 86.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1538        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012055161 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | -2.2        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    reward               | 0.01934477  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.00556     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 86.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1655        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015990779 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.483      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0443     |\n",
      "|    reward               | 0.012682558 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2291109.0\n",
      "Final accumulative portfolio value: 2.291109\n",
      "Maximum DrawDown: -0.5579302000862181\n",
      "Sharpe ratio: 0.29583103543059536\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1776        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013970235 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.538      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    reward               | 0.022628827 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1893        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013934304 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0964      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.449      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    reward               | 0.008129711 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2012        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01279354  |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | -0.771      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    reward               | 0.017810829 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2246132.5\n",
      "Final accumulative portfolio value: 2.2461325\n",
      "Maximum DrawDown: -0.5717968052624532\n",
      "Sharpe ratio: 0.29146316136991157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2130        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012133896 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | -1.6        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    reward               | 0.014697986 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 0.0055      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2249        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016802432 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.0932      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.465      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    reward               | 0.017390862 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2630199.25\n",
      "Final accumulative portfolio value: 2.63019925\n",
      "Maximum DrawDown: -0.5371688176939\n",
      "Sharpe ratio: 0.3263823485832816\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.03e+03     |\n",
      "|    ep_rew_mean          | 85.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 2369         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013887126  |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.1        |\n",
      "|    explained_variance   | -1.29        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.57        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    reward               | -0.012472568 |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.00948      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2487        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017346203 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.499      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    reward               | 0.008729843 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 85.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2604        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0140041   |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | -0.754      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    reward               | 0.016259722 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0148      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2153420.25\n",
      "Final accumulative portfolio value: 2.15342025\n",
      "Maximum DrawDown: -0.5693842157422144\n",
      "Sharpe ratio: 0.2823620593674348\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 81.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2723        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0111226   |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | -0.817      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    reward               | 0.012653737 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.00544     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 81.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2840        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016128384 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.0891      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.484      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    reward               | 0.012165501 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1989203.125\n",
      "Final accumulative portfolio value: 1.989203125\n",
      "Maximum DrawDown: -0.5743059468308946\n",
      "Sharpe ratio: 0.2647686045912353\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03e+03    |\n",
      "|    ep_rew_mean          | 80.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2958        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014312821 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | -0.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.567      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    reward               | 0.014940671 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.00851     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1748792.375\n",
      "Final accumulative portfolio value: 1.748792375\n",
      "Maximum DrawDown: -0.3107045999729511\n",
      "Sharpe ratio: 0.6117718228000671\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./data/tb\\a2c_32\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -46.9       |\n",
      "|    explained_variance | -4.7e+03    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.556       |\n",
      "|    reward             | 0.025493188 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.0041      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -47.4       |\n",
      "|    explained_variance | -10.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 3.31        |\n",
      "|    reward             | 0.019647487 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.00457     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.1       |\n",
      "|    explained_variance | -17.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | 0.025315741 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.00249     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -48.8      |\n",
      "|    explained_variance | -98.4      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.964     |\n",
      "|    reward             | 0.02091927 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.000653   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -49.6       |\n",
      "|    explained_variance | -10.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | 0.358       |\n",
      "|    reward             | 0.014321529 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -50.6       |\n",
      "|    explained_variance | -498        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.612      |\n",
      "|    reward             | 0.014449092 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.0003      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -51.9       |\n",
      "|    explained_variance | -72.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.697      |\n",
      "|    reward             | 0.017659938 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.000223    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -53.5       |\n",
      "|    explained_variance | -1.55e+05   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.894      |\n",
      "|    reward             | 0.018151823 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.000315    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -55         |\n",
      "|    explained_variance | -33.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.932      |\n",
      "|    reward             | 0.021572238 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 0.000333    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -56.4      |\n",
      "|    explained_variance | -6.47      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 0.0361     |\n",
      "|    reward             | 0.02186145 |\n",
      "|    std                | 1.34       |\n",
      "|    value_loss         | 1.67e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 3071809.0\n",
      "Final accumulative portfolio value: 3.071809\n",
      "Maximum DrawDown: -0.558141160007326\n",
      "Sharpe ratio: 0.3599660018736544\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -56.9       |\n",
      "|    explained_variance | -18.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | 0.019347087 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.00407     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -57.6       |\n",
      "|    explained_variance | 0.0425      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.236      |\n",
      "|    reward             | 0.018815244 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 0.000154    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -58.4       |\n",
      "|    explained_variance | -63.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 0.591       |\n",
      "|    reward             | 0.023632705 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 0.00031     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 111        |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -59.6      |\n",
      "|    explained_variance | -258       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 1.17       |\n",
      "|    reward             | 0.01974386 |\n",
      "|    std                | 1.47       |\n",
      "|    value_loss         | 0.000433   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -60.7       |\n",
      "|    explained_variance | -0.121      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.172       |\n",
      "|    reward             | 0.011786188 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 1.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 111          |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 477          |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.1        |\n",
      "|    explained_variance | -16.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.173       |\n",
      "|    reward             | 0.0115786325 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 2.64e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 507         |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -63.6       |\n",
      "|    explained_variance | -24.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.128      |\n",
      "|    reward             | 0.016065424 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 3.08e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 536         |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.5       |\n",
      "|    explained_variance | -38.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | 0.016783558 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 2.59e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 567         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -67.4       |\n",
      "|    explained_variance | -28.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.1        |\n",
      "|    reward             | 0.019793475 |\n",
      "|    std                | 1.87        |\n",
      "|    value_loss         | 1.04e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 111         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 597         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -69.2       |\n",
      "|    explained_variance | -10.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 0.489       |\n",
      "|    reward             | 0.019548777 |\n",
      "|    std                | 1.97        |\n",
      "|    value_loss         | 0.00011     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2599299.75\n",
      "Final accumulative portfolio value: 2.59929975\n",
      "Maximum DrawDown: -0.5555082276863625\n",
      "Sharpe ratio: 0.3234904002166785\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 109           |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 2100          |\n",
      "|    time_elapsed       | 629           |\n",
      "|    total_timesteps    | 10500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.8         |\n",
      "|    explained_variance | -0.755        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2099          |\n",
      "|    policy_loss        | 0.0873        |\n",
      "|    reward             | -0.0042452817 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 0.00253       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 109          |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 659          |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.4        |\n",
      "|    explained_variance | 0.602        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 2.2          |\n",
      "|    reward             | 0.0123122735 |\n",
      "|    std                | 2.05         |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 688         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -71.2       |\n",
      "|    explained_variance | -141        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.588       |\n",
      "|    reward             | 0.012535839 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 109          |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 718          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.3        |\n",
      "|    explained_variance | -932         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.308        |\n",
      "|    reward             | 0.0150695965 |\n",
      "|    std                | 2.17         |\n",
      "|    value_loss         | 3.95e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 109          |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.5        |\n",
      "|    explained_variance | -6.3         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 2.22         |\n",
      "|    reward             | 0.0061361254 |\n",
      "|    std                | 2.25         |\n",
      "|    value_loss         | 0.00109      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 777         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -74.8       |\n",
      "|    explained_variance | -18.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 0.611       |\n",
      "|    reward             | 0.005259723 |\n",
      "|    std                | 2.34        |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -76.4       |\n",
      "|    explained_variance | -0.278      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.356       |\n",
      "|    reward             | 0.009809161 |\n",
      "|    std                | 2.45        |\n",
      "|    value_loss         | 2.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 836         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -78.3       |\n",
      "|    explained_variance | -1.12e+04   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.0837      |\n",
      "|    reward             | 0.010976606 |\n",
      "|    std                | 2.59        |\n",
      "|    value_loss         | 0.000629    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 866         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -80.2       |\n",
      "|    explained_variance | -125        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.572       |\n",
      "|    reward             | 0.014825394 |\n",
      "|    std                | 2.75        |\n",
      "|    value_loss         | 7.67e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 109         |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 896         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -82.1       |\n",
      "|    explained_variance | -65.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 0.612       |\n",
      "|    reward             | 0.015035674 |\n",
      "|    std                | 2.91        |\n",
      "|    value_loss         | 7.71e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1877462.0\n",
      "Final accumulative portfolio value: 1.877462\n",
      "Maximum DrawDown: -0.5677875303240026\n",
      "Sharpe ratio: 0.2522862055075573\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 93.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 928        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -82.7      |\n",
      "|    explained_variance | -12.6      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -2.48      |\n",
      "|    reward             | 0.01744953 |\n",
      "|    std                | 2.96       |\n",
      "|    value_loss         | 0.0026     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 958         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -83.2       |\n",
      "|    explained_variance | -1.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 0.396       |\n",
      "|    reward             | 0.014466481 |\n",
      "|    std                | 3.02        |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 988         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -84         |\n",
      "|    explained_variance | -68.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.748       |\n",
      "|    reward             | 0.016806394 |\n",
      "|    std                | 3.09        |\n",
      "|    value_loss         | 9.8e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 1017        |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -85         |\n",
      "|    explained_variance | -6.81       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.495      |\n",
      "|    reward             | 0.014229616 |\n",
      "|    std                | 3.18        |\n",
      "|    value_loss         | 8e-05       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 93.9         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 1046         |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -86.3        |\n",
      "|    explained_variance | -4.55        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 1.64         |\n",
      "|    reward             | 0.0060392236 |\n",
      "|    std                | 3.31         |\n",
      "|    value_loss         | 0.000444     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 1075        |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -87.7       |\n",
      "|    explained_variance | -27.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 0.0653      |\n",
      "|    reward             | 0.006900037 |\n",
      "|    std                | 3.45        |\n",
      "|    value_loss         | 0.000199    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 1105        |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -89.3       |\n",
      "|    explained_variance | -224        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 0.0756      |\n",
      "|    reward             | 0.010347385 |\n",
      "|    std                | 3.63        |\n",
      "|    value_loss         | 3.79e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1135        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -91.3       |\n",
      "|    explained_variance | -59.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.468      |\n",
      "|    reward             | 0.011901144 |\n",
      "|    std                | 3.85        |\n",
      "|    value_loss         | 3e-05       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 93.9       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 1164       |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -93.3      |\n",
      "|    explained_variance | -2.12      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -0.172     |\n",
      "|    reward             | 0.01506211 |\n",
      "|    std                | 4.09       |\n",
      "|    value_loss         | 6.58e-06   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 93.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1194        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -95.3       |\n",
      "|    explained_variance | -1.06e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.352       |\n",
      "|    reward             | 0.016502688 |\n",
      "|    std                | 4.35        |\n",
      "|    value_loss         | 3.34e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2052363.5\n",
      "Final accumulative portfolio value: 2.0523635\n",
      "Maximum DrawDown: -0.5732727240582204\n",
      "Sharpe ratio: 0.27171830375066985\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1226        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.1       |\n",
      "|    explained_variance | -112        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.030187177 |\n",
      "|    std                | 4.45        |\n",
      "|    value_loss         | 0.00275     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 1255        |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -96.7       |\n",
      "|    explained_variance | -9.37       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 3.16        |\n",
      "|    reward             | 0.009509147 |\n",
      "|    std                | 4.53        |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.03e+03  |\n",
      "|    ep_rew_mean        | 90.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 16        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 1284      |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -97.5     |\n",
      "|    explained_variance | -1.87     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 0.377     |\n",
      "|    reward             | 0.0171623 |\n",
      "|    std                | 4.64      |\n",
      "|    value_loss         | 4.52e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1314        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -98.6       |\n",
      "|    explained_variance | -1.11e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | 1.67        |\n",
      "|    reward             | 0.017536737 |\n",
      "|    std                | 4.81        |\n",
      "|    value_loss         | 0.000381    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 1343        |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -99.9       |\n",
      "|    explained_variance | -31         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.003100647 |\n",
      "|    std                | 5           |\n",
      "|    value_loss         | 0.000201    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -101        |\n",
      "|    explained_variance | -11         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -0.257      |\n",
      "|    reward             | 0.008773506 |\n",
      "|    std                | 5.23        |\n",
      "|    value_loss         | 1.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1402        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -103        |\n",
      "|    explained_variance | -2.29e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | 0.008805918 |\n",
      "|    std                | 5.51        |\n",
      "|    value_loss         | 1.18e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 1431        |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -105        |\n",
      "|    explained_variance | -2.09e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 0.496       |\n",
      "|    reward             | 0.011931797 |\n",
      "|    std                | 5.86        |\n",
      "|    value_loss         | 3.78e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1462        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -107        |\n",
      "|    explained_variance | 0.0812      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | -0.494      |\n",
      "|    reward             | 0.014043641 |\n",
      "|    std                | 6.24        |\n",
      "|    value_loss         | 2.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 1492        |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -109        |\n",
      "|    explained_variance | -237        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -1.23       |\n",
      "|    reward             | 0.014669067 |\n",
      "|    std                | 6.64        |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1918342.5\n",
      "Final accumulative portfolio value: 1.9183425\n",
      "Maximum DrawDown: -0.5855179006249743\n",
      "Sharpe ratio: 0.256824200360702\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1524        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -110        |\n",
      "|    explained_variance | -23.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -2.34       |\n",
      "|    reward             | 0.019767407 |\n",
      "|    std                | 6.81        |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 1554        |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -111        |\n",
      "|    explained_variance | -14.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | 2.64        |\n",
      "|    reward             | 0.001101192 |\n",
      "|    std                | 6.93        |\n",
      "|    value_loss         | 0.000882    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1583        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -111        |\n",
      "|    explained_variance | -6.96       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 0.762       |\n",
      "|    reward             | 0.012451203 |\n",
      "|    std                | 7.1         |\n",
      "|    value_loss         | 9.15e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1613        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -113        |\n",
      "|    explained_variance | -15         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.014435721 |\n",
      "|    std                | 7.35        |\n",
      "|    value_loss         | 9.5e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 88.2         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 1642         |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -114         |\n",
      "|    explained_variance | -31.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 3.77         |\n",
      "|    reward             | 0.0024226452 |\n",
      "|    std                | 7.65         |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 88.2       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 1671       |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -115       |\n",
      "|    explained_variance | -9.98      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -0.955     |\n",
      "|    reward             | 0.00992514 |\n",
      "|    std                | 8.02       |\n",
      "|    value_loss         | 7.48e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1700        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -117        |\n",
      "|    explained_variance | -1.36       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 0.0969      |\n",
      "|    reward             | 0.010316433 |\n",
      "|    std                | 8.47        |\n",
      "|    value_loss         | 4.28e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1730        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -119        |\n",
      "|    explained_variance | -49.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.113       |\n",
      "|    reward             | 0.013648575 |\n",
      "|    std                | 9.01        |\n",
      "|    value_loss         | 2.69e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1760        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -121        |\n",
      "|    explained_variance | -19.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 1.3         |\n",
      "|    reward             | 0.015186751 |\n",
      "|    std                | 9.6         |\n",
      "|    value_loss         | 0.000153    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.2        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1790        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -123        |\n",
      "|    explained_variance | -17.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.798       |\n",
      "|    reward             | 0.015180696 |\n",
      "|    std                | 10.2        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2073109.0\n",
      "Final accumulative portfolio value: 2.073109\n",
      "Maximum DrawDown: -0.5780379344238356\n",
      "Sharpe ratio: 0.2740986464629123\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 85.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 1822       |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -124       |\n",
      "|    explained_variance | -2.52      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 0.788      |\n",
      "|    reward             | 0.04158258 |\n",
      "|    std                | 10.5       |\n",
      "|    value_loss         | 0.0022     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 1851        |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -125        |\n",
      "|    explained_variance | -834        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 0.697       |\n",
      "|    reward             | 0.013180233 |\n",
      "|    std                | 10.7        |\n",
      "|    value_loss         | 0.000351    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.03e+03  |\n",
      "|    ep_rew_mean        | 85.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 16        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 1881      |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -126      |\n",
      "|    explained_variance | -5.64     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 0.989     |\n",
      "|    reward             | 0.0187986 |\n",
      "|    std                | 10.9      |\n",
      "|    value_loss         | 0.000179  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1911        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -127        |\n",
      "|    explained_variance | -416        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 2.13        |\n",
      "|    reward             | 0.024106277 |\n",
      "|    std                | 11.3        |\n",
      "|    value_loss         | 0.000358    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 85.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 1940         |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -128         |\n",
      "|    explained_variance | -2.01        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 3.48         |\n",
      "|    reward             | 0.0094204955 |\n",
      "|    std                | 11.7         |\n",
      "|    value_loss         | 0.000795     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1972        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -129        |\n",
      "|    explained_variance | -30.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.661       |\n",
      "|    reward             | 0.015696181 |\n",
      "|    std                | 12.3        |\n",
      "|    value_loss         | 3.6e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 2001        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -131        |\n",
      "|    explained_variance | -20.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 0.502       |\n",
      "|    reward             | 0.014292993 |\n",
      "|    std                | 12.9        |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 85.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 2032       |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -133       |\n",
      "|    explained_variance | -38.3      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -0.56      |\n",
      "|    reward             | 0.01809782 |\n",
      "|    std                | 13.7       |\n",
      "|    value_loss         | 2.3e-05    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 2062        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -135        |\n",
      "|    explained_variance | -6.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.751       |\n",
      "|    reward             | 0.017973738 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 4.58e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 85.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 2092        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -137        |\n",
      "|    explained_variance | -17.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | 0.018663326 |\n",
      "|    std                | 15.6        |\n",
      "|    value_loss         | 0.000134    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2515451.5\n",
      "Final accumulative portfolio value: 2.5154515\n",
      "Maximum DrawDown: -0.5630590138355707\n",
      "Sharpe ratio: 0.3161854085629917\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 2124        |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -138        |\n",
      "|    explained_variance | -1.67       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -22.4       |\n",
      "|    reward             | 0.012412237 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 0.0313      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 2153        |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -139        |\n",
      "|    explained_variance | -34.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -0.909      |\n",
      "|    reward             | 0.005467081 |\n",
      "|    std                | 16.4        |\n",
      "|    value_loss         | 0.000193    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 2182        |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -140        |\n",
      "|    explained_variance | -71.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | 0.018990861 |\n",
      "|    std                | 16.8        |\n",
      "|    value_loss         | 0.000138    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 2213        |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -141        |\n",
      "|    explained_variance | -1.53       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -1.14       |\n",
      "|    reward             | 0.018475361 |\n",
      "|    std                | 17.4        |\n",
      "|    value_loss         | 7.47e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 90.4          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 2242          |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -142          |\n",
      "|    explained_variance | -307          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.93          |\n",
      "|    reward             | 0.00079952925 |\n",
      "|    std                | 18.1          |\n",
      "|    value_loss         | 0.000221      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 2272        |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -144        |\n",
      "|    explained_variance | -44.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | -2          |\n",
      "|    reward             | 0.011779587 |\n",
      "|    std                | 18.9        |\n",
      "|    value_loss         | 0.000205    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2301        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -146        |\n",
      "|    explained_variance | -98.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.807       |\n",
      "|    reward             | 0.011138517 |\n",
      "|    std                | 20          |\n",
      "|    value_loss         | 3.8e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2330        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -148        |\n",
      "|    explained_variance | -375        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -0.0808     |\n",
      "|    reward             | 0.015571133 |\n",
      "|    std                | 21.2        |\n",
      "|    value_loss         | 1.03e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2361        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -150        |\n",
      "|    explained_variance | -222        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.242       |\n",
      "|    reward             | 0.016177908 |\n",
      "|    std                | 22.6        |\n",
      "|    value_loss         | 5.02e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2391        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -152        |\n",
      "|    explained_variance | -8.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 0.742       |\n",
      "|    reward             | 0.016718047 |\n",
      "|    std                | 24.1        |\n",
      "|    value_loss         | 6.2e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2217088.0\n",
      "Final accumulative portfolio value: 2.217088\n",
      "Maximum DrawDown: -0.5851435299572512\n",
      "Sharpe ratio: 0.28854328549334424\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 2422        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -153        |\n",
      "|    explained_variance | 0.554       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -8.35       |\n",
      "|    reward             | 0.030734854 |\n",
      "|    std                | 25          |\n",
      "|    value_loss         | 0.00331     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 91.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8200          |\n",
      "|    time_elapsed       | 2452          |\n",
      "|    total_timesteps    | 41000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -154          |\n",
      "|    explained_variance | -5.87         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8199          |\n",
      "|    policy_loss        | -3.31         |\n",
      "|    reward             | -0.0058288057 |\n",
      "|    std                | 25.5          |\n",
      "|    value_loss         | 0.000994      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2481        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -154        |\n",
      "|    explained_variance | -220        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.503      |\n",
      "|    reward             | 0.012044008 |\n",
      "|    std                | 26.1        |\n",
      "|    value_loss         | 7.59e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2510        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -156        |\n",
      "|    explained_variance | -22.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.454       |\n",
      "|    reward             | 0.013903844 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 1.68e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 91.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 2540          |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -157          |\n",
      "|    explained_variance | -351          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -1.03         |\n",
      "|    reward             | -0.0008921617 |\n",
      "|    std                | 28.2          |\n",
      "|    value_loss         | 0.000115      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2570        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -159        |\n",
      "|    explained_variance | -4.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 0.491       |\n",
      "|    reward             | 0.007622237 |\n",
      "|    std                | 29.6        |\n",
      "|    value_loss         | 1.93e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 91.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 2600         |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -160         |\n",
      "|    explained_variance | -14.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | 0.0063492972 |\n",
      "|    std                | 31.2         |\n",
      "|    value_loss         | 5.6e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2629        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -162        |\n",
      "|    explained_variance | -3.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -1.71       |\n",
      "|    reward             | 0.011853343 |\n",
      "|    std                | 33.2        |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2658        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -164        |\n",
      "|    explained_variance | -0.606      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | -0.217      |\n",
      "|    reward             | 0.012595883 |\n",
      "|    std                | 35.4        |\n",
      "|    value_loss         | 2.55e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 91.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 2687        |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -167        |\n",
      "|    explained_variance | -14.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.354      |\n",
      "|    reward             | 0.012995628 |\n",
      "|    std                | 37.7        |\n",
      "|    value_loss         | 4.97e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1896085.25\n",
      "Final accumulative portfolio value: 1.89608525\n",
      "Maximum DrawDown: -0.5868419332862868\n",
      "Sharpe ratio: 0.25445990678011926\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 89.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 2720       |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -168       |\n",
      "|    explained_variance | -1.52      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -34.9      |\n",
      "|    reward             | 0.04120979 |\n",
      "|    std                | 39         |\n",
      "|    value_loss         | 0.0471     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2751        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -168        |\n",
      "|    explained_variance | -27.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -2.72       |\n",
      "|    reward             | 0.011080387 |\n",
      "|    std                | 39.7        |\n",
      "|    value_loss         | 0.00033     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 89.5       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 2780       |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -169       |\n",
      "|    explained_variance | -4.56      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 0.464      |\n",
      "|    reward             | 0.02300706 |\n",
      "|    std                | 40.6       |\n",
      "|    value_loss         | 6.89e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2810        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -170        |\n",
      "|    explained_variance | -104        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | -1.99       |\n",
      "|    reward             | 0.023766499 |\n",
      "|    std                | 42          |\n",
      "|    value_loss         | 0.000232    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2839        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -171        |\n",
      "|    explained_variance | -7.85e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.228       |\n",
      "|    reward             | 0.004241375 |\n",
      "|    std                | 43.7        |\n",
      "|    value_loss         | 0.000284    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2868        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -173        |\n",
      "|    explained_variance | -4.07       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.013763309 |\n",
      "|    std                | 45.7        |\n",
      "|    value_loss         | 4.79e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 2899        |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -175        |\n",
      "|    explained_variance | -406        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.317       |\n",
      "|    reward             | 0.012289085 |\n",
      "|    std                | 48.3        |\n",
      "|    value_loss         | 1.01e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 2929        |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -177        |\n",
      "|    explained_variance | -48.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.76       |\n",
      "|    reward             | 0.017477116 |\n",
      "|    std                | 51.3        |\n",
      "|    value_loss         | 2.91e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2958        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -179        |\n",
      "|    explained_variance | -405        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -0.441      |\n",
      "|    reward             | 0.017898703 |\n",
      "|    std                | 54.7        |\n",
      "|    value_loss         | 1.89e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 89.5        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2988        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -181        |\n",
      "|    explained_variance | -1.95       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -1.87       |\n",
      "|    reward             | 0.018281808 |\n",
      "|    std                | 58.3        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "Logging to ./data/tb\\a2c_33\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -181        |\n",
      "|    explained_variance | -222        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -2.91       |\n",
      "|    reward             | 0.031424474 |\n",
      "|    std                | 59.1        |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -182        |\n",
      "|    explained_variance | -12.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 4.04        |\n",
      "|    reward             | 0.017742569 |\n",
      "|    std                | 60.4        |\n",
      "|    value_loss         | 0.000616    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -183        |\n",
      "|    explained_variance | -98.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -0.959      |\n",
      "|    reward             | 0.017150758 |\n",
      "|    std                | 62.3        |\n",
      "|    value_loss         | 3.91e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -184        |\n",
      "|    explained_variance | -13.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -0.805      |\n",
      "|    reward             | 0.013659831 |\n",
      "|    std                | 64.9        |\n",
      "|    value_loss         | 5.2e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -186        |\n",
      "|    explained_variance | -34.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 0.0819      |\n",
      "|    reward             | 0.008346611 |\n",
      "|    std                | 67.8        |\n",
      "|    value_loss         | 9.71e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -188        |\n",
      "|    explained_variance | -19.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.009163002 |\n",
      "|    std                | 71.2        |\n",
      "|    value_loss         | 4.36e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -189        |\n",
      "|    explained_variance | -10.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 0.92        |\n",
      "|    reward             | 0.012075571 |\n",
      "|    std                | 75.5        |\n",
      "|    value_loss         | 3.58e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -191       |\n",
      "|    explained_variance | -325       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | -0.174     |\n",
      "|    reward             | 0.01312879 |\n",
      "|    std                | 80.3       |\n",
      "|    value_loss         | 3.79e-06   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -194        |\n",
      "|    explained_variance | -65.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | -0.348      |\n",
      "|    reward             | 0.016683219 |\n",
      "|    std                | 85.7        |\n",
      "|    value_loss         | 6.32e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -196        |\n",
      "|    explained_variance | -3.51       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | -0.853      |\n",
      "|    reward             | 0.017736673 |\n",
      "|    std                | 91.5        |\n",
      "|    value_loss         | 5.09e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2276619.25\n",
      "Final accumulative portfolio value: 2.27661925\n",
      "Maximum DrawDown: -0.5721588774964298\n",
      "Sharpe ratio: 0.29399951233861416\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -196        |\n",
      "|    explained_variance | -252        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | -5.96       |\n",
      "|    reward             | 0.024030052 |\n",
      "|    std                | 92.9        |\n",
      "|    value_loss         | 0.00147     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -197        |\n",
      "|    explained_variance | -1.08       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 0.68        |\n",
      "|    reward             | 0.017202487 |\n",
      "|    std                | 94.9        |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 388         |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -198        |\n",
      "|    explained_variance | -108        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | 0.018437803 |\n",
      "|    std                | 97.8        |\n",
      "|    value_loss         | 2.95e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 90.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -199       |\n",
      "|    explained_variance | -864       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11399      |\n",
      "|    policy_loss        | 2.32       |\n",
      "|    reward             | 0.01478661 |\n",
      "|    std                | 102        |\n",
      "|    value_loss         | 0.000175   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -201        |\n",
      "|    explained_variance | -10.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | -0.453      |\n",
      "|    reward             | 0.006457679 |\n",
      "|    std                | 106         |\n",
      "|    value_loss         | 1.1e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 476         |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -202        |\n",
      "|    explained_variance | -216        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | 1.53        |\n",
      "|    reward             | 0.007436146 |\n",
      "|    std                | 112         |\n",
      "|    value_loss         | 9.05e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 90.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 506          |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -204         |\n",
      "|    explained_variance | -1.13e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | -1.04        |\n",
      "|    reward             | 0.0116347205 |\n",
      "|    std                | 118          |\n",
      "|    value_loss         | 3.01e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 90.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -206         |\n",
      "|    explained_variance | -17.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | 0.0132578835 |\n",
      "|    std                | 126          |\n",
      "|    value_loss         | 4.55e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -208        |\n",
      "|    explained_variance | -16.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | -0.905      |\n",
      "|    reward             | 0.016319912 |\n",
      "|    std                | 134         |\n",
      "|    value_loss         | 3.07e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.7        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 595         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -211        |\n",
      "|    explained_variance | -168        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | 0.017824382 |\n",
      "|    std                | 143         |\n",
      "|    value_loss         | 5.42e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2277675.0\n",
      "Final accumulative portfolio value: 2.277675\n",
      "Maximum DrawDown: -0.5936158284117923\n",
      "Sharpe ratio: 0.2942272200674074\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 627         |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -211        |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -3.14       |\n",
      "|    reward             | 0.008444121 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 657         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -212        |\n",
      "|    explained_variance | -6.84       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 2.84        |\n",
      "|    reward             | 0.014964647 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 0.000375    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 686         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -213        |\n",
      "|    explained_variance | -6.09       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 2.72        |\n",
      "|    reward             | 0.016483748 |\n",
      "|    std                | 154         |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 716         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -214        |\n",
      "|    explained_variance | -570        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | -0.397      |\n",
      "|    reward             | 0.018919352 |\n",
      "|    std                | 160         |\n",
      "|    value_loss         | 4.31e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 746         |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -216        |\n",
      "|    explained_variance | -0.616      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | 0.0304      |\n",
      "|    reward             | 0.008036937 |\n",
      "|    std                | 167         |\n",
      "|    value_loss         | 3.42e-06    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.03e+03  |\n",
      "|    ep_rew_mean        | 90.9      |\n",
      "| time/                 |           |\n",
      "|    fps                | 16        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 776       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -217      |\n",
      "|    explained_variance | -14.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 1.73      |\n",
      "|    reward             | 0.0079745 |\n",
      "|    std                | 175       |\n",
      "|    value_loss         | 8.16e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 805         |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -219        |\n",
      "|    explained_variance | -6.92       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -0.498      |\n",
      "|    reward             | 0.011617488 |\n",
      "|    std                | 185         |\n",
      "|    value_loss         | 7.91e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 834         |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -221        |\n",
      "|    explained_variance | -43.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | 0.438       |\n",
      "|    reward             | 0.012247552 |\n",
      "|    std                | 197         |\n",
      "|    value_loss         | 1.13e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 864         |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -223        |\n",
      "|    explained_variance | -31.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.015419156 |\n",
      "|    std                | 211         |\n",
      "|    value_loss         | 2.62e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 90.9        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -225        |\n",
      "|    explained_variance | -3.04e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | 0.016162055 |\n",
      "|    std                | 225         |\n",
      "|    value_loss         | 5.1e-05     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2034228.5\n",
      "Final accumulative portfolio value: 2.0342285\n",
      "Maximum DrawDown: -0.5749098229618332\n",
      "Sharpe ratio: 0.269708206141904\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 88.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 926          |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -226         |\n",
      "|    explained_variance | -25.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13099        |\n",
      "|    policy_loss        | -1.12        |\n",
      "|    reward             | 0.0027560315 |\n",
      "|    std                | 230          |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 956         |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -227        |\n",
      "|    explained_variance | -0.0179     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 6.27        |\n",
      "|    reward             | 0.009408586 |\n",
      "|    std                | 235         |\n",
      "|    value_loss         | 0.000814    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 985         |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -228        |\n",
      "|    explained_variance | -29.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | -2.58       |\n",
      "|    reward             | 0.011947823 |\n",
      "|    std                | 243         |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 1015        |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -229        |\n",
      "|    explained_variance | -50.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | 0.917       |\n",
      "|    reward             | 0.012723483 |\n",
      "|    std                | 253         |\n",
      "|    value_loss         | 3.68e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 88.4         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 1044         |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -231         |\n",
      "|    explained_variance | -2.59        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 0.642        |\n",
      "|    reward             | 0.0049596117 |\n",
      "|    std                | 265          |\n",
      "|    value_loss         | 1.71e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 1074        |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -233        |\n",
      "|    explained_variance | -1.71       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -2.18       |\n",
      "|    reward             | 0.007506989 |\n",
      "|    std                | 279         |\n",
      "|    value_loss         | 9.96e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 1104        |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -235        |\n",
      "|    explained_variance | -11         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13699       |\n",
      "|    policy_loss        | -1.73       |\n",
      "|    reward             | 0.011448483 |\n",
      "|    std                | 296         |\n",
      "|    value_loss         | 9.11e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 1135        |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -237        |\n",
      "|    explained_variance | -28         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -3.64       |\n",
      "|    reward             | 0.013498704 |\n",
      "|    std                | 315         |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 1164        |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -239        |\n",
      "|    explained_variance | -11.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.015597512 |\n",
      "|    std                | 336         |\n",
      "|    value_loss         | 2.94e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 88.4        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 1193        |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -241        |\n",
      "|    explained_variance | -209        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.73       |\n",
      "|    reward             | 0.017059553 |\n",
      "|    std                | 357         |\n",
      "|    value_loss         | 1.36e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2169276.5\n",
      "Final accumulative portfolio value: 2.1692765\n",
      "Maximum DrawDown: -0.5651359534156217\n",
      "Sharpe ratio: 0.2838936394979222\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 1226        |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -242        |\n",
      "|    explained_variance | -84.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 2.34        |\n",
      "|    reward             | 0.029840909 |\n",
      "|    std                | 367         |\n",
      "|    value_loss         | 0.00139     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -242        |\n",
      "|    explained_variance | -26.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | 0.391       |\n",
      "|    reward             | 0.007821637 |\n",
      "|    std                | 375         |\n",
      "|    value_loss         | 0.000195    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 84         |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 1285       |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -243       |\n",
      "|    explained_variance | -0.399     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14299      |\n",
      "|    policy_loss        | -0.645     |\n",
      "|    reward             | 0.01652473 |\n",
      "|    std                | 386        |\n",
      "|    value_loss         | 1.57e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 1314        |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -245        |\n",
      "|    explained_variance | -676        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | 3.06        |\n",
      "|    reward             | 0.018692356 |\n",
      "|    std                | 401         |\n",
      "|    value_loss         | 0.000211    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 84           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 1345         |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -246         |\n",
      "|    explained_variance | -17.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | -3.36        |\n",
      "|    reward             | 0.0048198733 |\n",
      "|    std                | 420          |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 84         |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 1375       |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -248       |\n",
      "|    explained_variance | -9.52      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14599      |\n",
      "|    policy_loss        | -0.209     |\n",
      "|    reward             | 0.01114017 |\n",
      "|    std                | 441        |\n",
      "|    value_loss         | 6.79e-06   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 1404        |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -250        |\n",
      "|    explained_variance | -5.06       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 0.696       |\n",
      "|    reward             | 0.010418626 |\n",
      "|    std                | 468         |\n",
      "|    value_loss         | 8.95e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 84           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 1434         |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -252         |\n",
      "|    explained_variance | -70.2        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14799        |\n",
      "|    policy_loss        | 0.848        |\n",
      "|    reward             | 0.0128127085 |\n",
      "|    std                | 498          |\n",
      "|    value_loss         | 2.35e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 1463        |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -254        |\n",
      "|    explained_variance | -254        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -0.904      |\n",
      "|    reward             | 0.015563681 |\n",
      "|    std                | 531         |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 84         |\n",
      "| time/                 |            |\n",
      "|    fps                | 16         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 1493       |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -256       |\n",
      "|    explained_variance | -5.3       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14999      |\n",
      "|    policy_loss        | 0.0333     |\n",
      "|    reward             | 0.01621791 |\n",
      "|    std                | 565        |\n",
      "|    value_loss         | 1.83e-06   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2082474.375\n",
      "Final accumulative portfolio value: 2.082474375\n",
      "Maximum DrawDown: -0.5586475931620719\n",
      "Sharpe ratio: 0.2746743274914682\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 1524        |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -257        |\n",
      "|    explained_variance | -0.522      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 2.9         |\n",
      "|    reward             | 0.010335232 |\n",
      "|    std                | 584         |\n",
      "|    value_loss         | 0.000243    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 84.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 1554          |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -258          |\n",
      "|    explained_variance | -17.6         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15199         |\n",
      "|    policy_loss        | 8.72          |\n",
      "|    reward             | -0.0041370713 |\n",
      "|    std                | 597           |\n",
      "|    value_loss         | 0.00232       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 1584        |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -259        |\n",
      "|    explained_variance | -1.12       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 1.79        |\n",
      "|    reward             | 0.011141106 |\n",
      "|    std                | 614         |\n",
      "|    value_loss         | 5.45e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 1614        |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -260        |\n",
      "|    explained_variance | -12.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | 0.343       |\n",
      "|    reward             | 0.011793596 |\n",
      "|    std                | 638         |\n",
      "|    value_loss         | 4.03e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 84.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 1644          |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -261          |\n",
      "|    explained_variance | -31.7         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15499         |\n",
      "|    policy_loss        | 7.36          |\n",
      "|    reward             | 0.00013499465 |\n",
      "|    std                | 668           |\n",
      "|    value_loss         | 0.000887      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 84.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 1673         |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -263         |\n",
      "|    explained_variance | -115         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | -0.68        |\n",
      "|    reward             | 0.0071584545 |\n",
      "|    std                | 698          |\n",
      "|    value_loss         | 8.35e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 1703        |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -265        |\n",
      "|    explained_variance | -0.284      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | 0.008314834 |\n",
      "|    std                | 737         |\n",
      "|    value_loss         | 5.3e-06     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 1732        |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -267        |\n",
      "|    explained_variance | -10.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | 0.0479      |\n",
      "|    reward             | 0.012378644 |\n",
      "|    std                | 782         |\n",
      "|    value_loss         | 1.18e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 1761        |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -269        |\n",
      "|    explained_variance | -84.7       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.014682907 |\n",
      "|    std                | 833         |\n",
      "|    value_loss         | 4.62e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 84.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 1792        |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -271        |\n",
      "|    explained_variance | -6.96       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | 0.015271461 |\n",
      "|    std                | 887         |\n",
      "|    value_loss         | 5.28e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2061427.125\n",
      "Final accumulative portfolio value: 2.061427125\n",
      "Maximum DrawDown: -0.6225924859852112\n",
      "Sharpe ratio: 0.27277499042320225\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 1823        |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -272        |\n",
      "|    explained_variance | -4.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | -3.79       |\n",
      "|    reward             | 0.027942339 |\n",
      "|    std                | 913         |\n",
      "|    value_loss         | 0.00061     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 80           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 1853         |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -272         |\n",
      "|    explained_variance | -0.558       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | 0.282        |\n",
      "|    reward             | 0.0064326557 |\n",
      "|    std                | 932          |\n",
      "|    value_loss         | 4.71e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 1882        |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -273        |\n",
      "|    explained_variance | -4.83       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | 4.2         |\n",
      "|    reward             | 0.015046683 |\n",
      "|    std                | 959         |\n",
      "|    value_loss         | 0.000288    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 1912        |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -275        |\n",
      "|    explained_variance | -81         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | 2.12        |\n",
      "|    reward             | 0.018082589 |\n",
      "|    std                | 997         |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 80           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 1942         |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -276         |\n",
      "|    explained_variance | -3.17        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | 8.76         |\n",
      "|    reward             | 0.0028179598 |\n",
      "|    std                | 1.04e+03     |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 1972        |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -278        |\n",
      "|    explained_variance | -14         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | 0.010913325 |\n",
      "|    std                | 1.1e+03     |\n",
      "|    value_loss         | 5.36e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 2001        |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -280        |\n",
      "|    explained_variance | -50         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 0.221       |\n",
      "|    reward             | 0.010531843 |\n",
      "|    std                | 1.16e+03    |\n",
      "|    value_loss         | 4.51e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 2030        |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -282        |\n",
      "|    explained_variance | -12.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | -3.94       |\n",
      "|    reward             | 0.015310999 |\n",
      "|    std                | 1.23e+03    |\n",
      "|    value_loss         | 0.000295    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 2060        |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -284        |\n",
      "|    explained_variance | -2.67       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | 0.719       |\n",
      "|    reward             | 0.016096437 |\n",
      "|    std                | 1.31e+03    |\n",
      "|    value_loss         | 9.89e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 80          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 2090        |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -286        |\n",
      "|    explained_variance | -106        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.017097613 |\n",
      "|    std                | 1.4e+03     |\n",
      "|    value_loss         | 3.37e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 2287199.25\n",
      "Final accumulative portfolio value: 2.28719925\n",
      "Maximum DrawDown: -0.5858327317342367\n",
      "Sharpe ratio: 0.29527630072075706\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 81            |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 2122          |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -287          |\n",
      "|    explained_variance | -1.21         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | -50.3         |\n",
      "|    reward             | -0.0056800144 |\n",
      "|    std                | 1.44e+03      |\n",
      "|    value_loss         | 0.0352        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 2154         |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -287         |\n",
      "|    explained_variance | -71          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | -0.012334182 |\n",
      "|    std                | 1.47e+03     |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 2180        |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -288        |\n",
      "|    explained_variance | -242        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 0.429       |\n",
      "|    reward             | 0.006214049 |\n",
      "|    std                | 1.51e+03    |\n",
      "|    value_loss         | 6.13e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 2206        |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -289        |\n",
      "|    explained_variance | -3.31       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -0.027      |\n",
      "|    reward             | 0.009458327 |\n",
      "|    std                | 1.57e+03    |\n",
      "|    value_loss         | 1.03e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 2232         |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -291         |\n",
      "|    explained_variance | -1.01e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | 6.12         |\n",
      "|    reward             | -0.005419009 |\n",
      "|    std                | 1.64e+03     |\n",
      "|    value_loss         | 0.000854     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 81           |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 2258         |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -292         |\n",
      "|    explained_variance | -120         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | -0.687       |\n",
      "|    reward             | 0.0061887815 |\n",
      "|    std                | 1.71e+03     |\n",
      "|    value_loss         | 1.05e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 2284        |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -294        |\n",
      "|    explained_variance | -26.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 1.99        |\n",
      "|    reward             | 0.004932857 |\n",
      "|    std                | 1.8e+03     |\n",
      "|    value_loss         | 4.94e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 2311        |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -296        |\n",
      "|    explained_variance | -11.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 0.329       |\n",
      "|    reward             | 0.010420652 |\n",
      "|    std                | 1.91e+03    |\n",
      "|    value_loss         | 2.43e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 2337        |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -298        |\n",
      "|    explained_variance | -23         |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 0.848       |\n",
      "|    reward             | 0.011274523 |\n",
      "|    std                | 2.04e+03    |\n",
      "|    value_loss         | 9.44e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 81          |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 2365        |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -300        |\n",
      "|    explained_variance | -2.14       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 2.41        |\n",
      "|    reward             | 0.012366712 |\n",
      "|    std                | 2.17e+03    |\n",
      "|    value_loss         | 8.76e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1660540.125\n",
      "Final accumulative portfolio value: 1.660540125\n",
      "Maximum DrawDown: -0.6260439980970964\n",
      "Sharpe ratio: 0.22537489678595457\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 2398        |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -301        |\n",
      "|    explained_variance | -2.91       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | 4.64        |\n",
      "|    reward             | 0.025580296 |\n",
      "|    std                | 2.25e+03    |\n",
      "|    value_loss         | 0.00379     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 77.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 2427         |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -302         |\n",
      "|    explained_variance | -2.4         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | -5.34        |\n",
      "|    reward             | -0.006349998 |\n",
      "|    std                | 2.3e+03      |\n",
      "|    value_loss         | 0.000598     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 2456        |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -303        |\n",
      "|    explained_variance | -452        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 0.228       |\n",
      "|    reward             | 0.014635575 |\n",
      "|    std                | 2.36e+03    |\n",
      "|    value_loss         | 6.18e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 2484        |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -304        |\n",
      "|    explained_variance | -20.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 3.75        |\n",
      "|    reward             | 0.013949909 |\n",
      "|    std                | 2.44e+03    |\n",
      "|    value_loss         | 0.000163    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 5.03e+03      |\n",
      "|    ep_rew_mean        | 77.1          |\n",
      "| time/                 |               |\n",
      "|    fps                | 16            |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 2513          |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -306          |\n",
      "|    explained_variance | -194          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18499         |\n",
      "|    policy_loss        | -2.56         |\n",
      "|    reward             | -0.0021891233 |\n",
      "|    std                | 2.56e+03      |\n",
      "|    value_loss         | 0.000131      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 2539        |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -307        |\n",
      "|    explained_variance | -5.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | 1.8         |\n",
      "|    reward             | 0.007424471 |\n",
      "|    std                | 2.68e+03    |\n",
      "|    value_loss         | 6.32e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 77.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 16           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 2565         |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -309         |\n",
      "|    explained_variance | -182         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | 0.718        |\n",
      "|    reward             | 0.0066487696 |\n",
      "|    std                | 2.84e+03     |\n",
      "|    value_loss         | 8.3e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 2592        |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -311        |\n",
      "|    explained_variance | -27.2       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -1.95       |\n",
      "|    reward             | 0.012287887 |\n",
      "|    std                | 3.02e+03    |\n",
      "|    value_loss         | 4.13e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 77.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 16          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 2618        |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -313        |\n",
      "|    explained_variance | -1.81       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | -1.31       |\n",
      "|    reward             | 0.012885142 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 1.89e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 5.03e+03     |\n",
      "|    ep_rew_mean        | 77.1         |\n",
      "| time/                 |              |\n",
      "|    fps                | 17           |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 2644         |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -315         |\n",
      "|    explained_variance | -1.21        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | 0.392        |\n",
      "|    reward             | 0.0125205945 |\n",
      "|    std                | 3.43e+03     |\n",
      "|    value_loss         | 1.11e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1845978.625\n",
      "Final accumulative portfolio value: 1.845978625\n",
      "Maximum DrawDown: -0.6027297628000186\n",
      "Sharpe ratio: 0.2484124810094984\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 76.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 2675       |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -317       |\n",
      "|    explained_variance | -0.882     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19099      |\n",
      "|    policy_loss        | -31.1      |\n",
      "|    reward             | 0.04066863 |\n",
      "|    std                | 3.55e+03   |\n",
      "|    value_loss         | 0.0116     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 2703        |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -317        |\n",
      "|    explained_variance | -357        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | -1.09       |\n",
      "|    reward             | 0.012344282 |\n",
      "|    std                | 3.61e+03    |\n",
      "|    value_loss         | 0.000153    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 2731        |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -318        |\n",
      "|    explained_variance | -4.75       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | -3.18       |\n",
      "|    reward             | 0.022134349 |\n",
      "|    std                | 3.7e+03     |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 2759        |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -319        |\n",
      "|    explained_variance | -143        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -3.93       |\n",
      "|    reward             | 0.023751164 |\n",
      "|    std                | 3.83e+03    |\n",
      "|    value_loss         | 0.000287    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 2786        |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -320        |\n",
      "|    explained_variance | -16.6       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -3.69       |\n",
      "|    reward             | 0.003915902 |\n",
      "|    std                | 3.99e+03    |\n",
      "|    value_loss         | 0.000223    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 2813        |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -322        |\n",
      "|    explained_variance | -0.117      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | 0.015253111 |\n",
      "|    std                | 4.19e+03    |\n",
      "|    value_loss         | 2.72e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 2841        |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -324        |\n",
      "|    explained_variance | -10.8       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | 0.242       |\n",
      "|    reward             | 0.012556187 |\n",
      "|    std                | 4.43e+03    |\n",
      "|    value_loss         | 3.87e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.03e+03   |\n",
      "|    ep_rew_mean        | 76.6       |\n",
      "| time/                 |            |\n",
      "|    fps                | 17         |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 2868       |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -326       |\n",
      "|    explained_variance | -94.2      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19799      |\n",
      "|    policy_loss        | -1.41      |\n",
      "|    reward             | 0.01784734 |\n",
      "|    std                | 4.71e+03   |\n",
      "|    value_loss         | 3.02e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 2896        |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -328        |\n",
      "|    explained_variance | -14.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -3.41       |\n",
      "|    reward             | 0.017770156 |\n",
      "|    std                | 5.01e+03    |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 5.03e+03    |\n",
      "|    ep_rew_mean        | 76.6        |\n",
      "| time/                 |             |\n",
      "|    fps                | 17          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 2926        |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -330        |\n",
      "|    explained_variance | -13.5       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -4.72       |\n",
      "|    reward             | 0.018835388 |\n",
      "|    std                | 5.33e+03    |\n",
      "|    value_loss         | 0.000236    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:1000000\n",
      "Final portfolio value: 1677477.125\n",
      "Final accumulative portfolio value: 1.677477125\n",
      "Maximum DrawDown: -0.3289536310985478\n",
      "Sharpe ratio: 0.5724007073931922\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "recession_result_dax_sortino = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_2010_2024',reward_sortino=True)\n",
    "recession_result_dax = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_return_2010_2024')\n",
    "recession_result_dax_sharpe = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_sharpe_2010_2024',reward_sharpe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [recession_result_dax_sortino,recession_result_dax,recession_result_dax_sharpe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "with plt.style.context('science','ieee'):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i,item in enumerate(results): \n",
    "            plt.plot(item[0]['test'][0].get('date'),((item[0]['test'][0].get('account').pct_change()+ 1 ).cumprod())-1,label=str(item[0]['name']).upper())\n",
    "    plt.legend()\n",
    "    plt.title('NASDAQ')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added user defined features\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2000-01-01'\n",
    "TRAIN_END_DATE = '2020-01-01'\n",
    "TEST_START_DATE = '2020-01-01'\n",
    "TEST_END_DATE = '2024-10-01'\n",
    "\n",
    "INDICATORS = [\n",
    "    \"close_5_ema\",\n",
    "]\n",
    "fe = FeatureEngineer(use_technical_indicator=False,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature =True)\n",
    "\n",
    "processed = fe.preprocess_data(df_hsi)\n",
    "processed = processed.fillna(0)\n",
    "processed= processed.replace(np.inf,0)\n",
    "train_data= data_split(processed, DATA_START_DATE, TRAIN_END_DATE)\n",
    "test_data = data_split(processed, TEST_START_DATE, TEST_END_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recession_result_dax_sortino = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_2020_2024_hsi',reward_sortino=True)\n",
    "recession_result_dax = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_return_2020_2024_hsi')\n",
    "recession_result_dax_sharpe = benchmark(train_data,test_data,50_000,5,['close','return'],INDICATORS,save=True,tag='nasdaq_recession_sharpe_2020_2024_hsi',reward_sharpe=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
